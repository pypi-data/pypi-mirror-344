"""
Module containing features to detect and filter emojis and special Unicode characters.
Designed to protect against malicious content hiding via special characters.
"""

import re
import unicodedata
from typing import Dict, List, Tuple, Pattern, Union, Set, Optional, Any

# Unicode ranges for emojis
EMOJI_PATTERN = re.compile(
    "["
    "\U0001F600-\U0001F64F"  # emoticons
    "\U0001F300-\U0001F5FF"  # symbols & pictograms
    "\U0001F680-\U0001F6FF"  # transport & symbols
    "\U0001F700-\U0001F77F"  # alchemical symbols
    "\U0001F780-\U0001F7FF"  # geometric symbols
    "\U0001F800-\U0001F8FF"  # supplemental symbols
    "\U0001F900-\U0001F9FF"  # supplemental symbols and pictograms
    "\U0001FA00-\U0001FA6F"  # game symbols
    "\U0001FA70-\U0001FAFF"  # supplemental symbols
    "\U00002702-\U000027B0"  # dingbats
    "\U000024C2-\U0001F251" 
    "]+"
)

# Special characters and homoglyphs that can be used for obfuscation
HOMOGLYPHS: Dict[str, List[str]] = {
    'a': ['Ð°', 'ï½', 'â“', 'ðš', 'ð‘Ž', 'ð’‚', 'ð“ª', 'ð”ž', 'ð•’', 'ð–†', 'ð–º', 'ð—®', 'ð˜¢', 'ð™–', 'ðšŠ', 'É‘'],
    'b': ['b', 'ï½‚', 'â“‘', 'ð›', 'ð‘', 'ð’ƒ', 'ð“«', 'ð”Ÿ', 'ð•“', 'ð–‡', 'ð–»', 'ð—¯', 'ð˜£', 'ð™—', 'ðš‹'],
    'c': ['Ñ', 'ï½ƒ', 'â“’', 'ðœ', 'ð‘', 'ð’„', 'ð“¬', 'ð” ', 'ð•”', 'ð–ˆ', 'ð–¼', 'ð—°', 'ð˜¤', 'ð™˜', 'ðšŒ'],
    'd': ['â…¾', 'ï½„', 'â““', 'ð', 'ð‘‘', 'ð’…', 'ð“­', 'ð”¡', 'ð••', 'ð–‰', 'ð–½', 'ð—±', 'ð˜¥', 'ð™™', 'ðš'],
    'e': ['Ðµ', 'ï½…', 'â“”', 'ðž', 'ð‘’', 'ð’†', 'ð“®', 'ð”¢', 'ð•–', 'ð–Š', 'ð–¾', 'ð—²', 'ð˜¦', 'ð™š', 'ðšŽ'],
    'f': ['ï½†', 'â“•', 'ðŸ', 'ð‘“', 'ð’‡', 'ð“¯', 'ð”£', 'ð•—', 'ð–‹', 'ð–¿', 'ð—³', 'ð˜§', 'ð™›', 'ðš'],
    'g': ['ï½‡', 'â“–', 'ð ', 'ð‘”', 'ð’ˆ', 'ð“°', 'ð”¤', 'ð•˜', 'ð–Œ', 'ð—€', 'ð—´', 'ð˜¨', 'ð™œ', 'ðš'],
    'h': ['Ò»', 'ï½ˆ', 'â“—', 'ð¡', 'ð’‰', 'ð“±', 'ð”¥', 'ð•™', 'ð–', 'ð—', 'ð—µ', 'ð˜©', 'ð™', 'ðš‘'],
    'i': ['Ñ–', 'ï½‰', 'â“˜', 'ð¢', 'ð‘–', 'ð’Š', 'ð“²', 'ð”¦', 'ð•š', 'ð–Ž', 'ð—‚', 'ð—¶', 'ð˜ª', 'ð™ž', 'ðš’'],
    'j': ['Ñ˜', 'ï½Š', 'â“™', 'ð£', 'ð‘—', 'ð’‹', 'ð“³', 'ð”§', 'ð•›', 'ð–', 'ð—ƒ', 'ð—·', 'ð˜«', 'ð™Ÿ', 'ðš“'],
    'k': ['ï½‹', 'â“š', 'ð¤', 'ð‘˜', 'ð’Œ', 'ð“´', 'ð”¨', 'ð•œ', 'ð–', 'ð—„', 'ð—¸', 'ð˜¬', 'ð™ ', 'ðš”'],
    'l': ['â…¼', 'ï½Œ', 'â“›', 'ð¥', 'ð‘™', 'ð’', 'ð“µ', 'ð”©', 'ð•', 'ð–‘', 'ð—…', 'ð—¹', 'ð˜­', 'ð™¡', 'ðš•'],
    'm': ['ï½', 'â“œ', 'ð¦', 'ð‘š', 'ð’Ž', 'ð“¶', 'ð”ª', 'ð•ž', 'ð–’', 'ð—†', 'ð—º', 'ð˜®', 'ð™¢', 'ðš–'],
    'n': ['ï½Ž', 'â“', 'ð§', 'ð‘›', 'ð’', 'ð“·', 'ð”«', 'ð•Ÿ', 'ð–“', 'ð—‡', 'ð—»', 'ð˜¯', 'ð™£', 'ðš—'],
    'o': ['Ð¾', 'ï½', 'â“ž', 'ð¨', 'ð‘œ', 'ð’', 'ð“¸', 'ð”¬', 'ð• ', 'ð–”', 'ð—ˆ', 'ð—¼', 'ð˜°', 'ð™¤', 'ðš˜'],
    'p': ['Ñ€', 'ï½', 'â“Ÿ', 'ð©', 'ð‘', 'ð’‘', 'ð“¹', 'ð”­', 'ð•¡', 'ð–•', 'ð—‰', 'ð—½', 'ð˜±', 'ð™¥', 'ðš™'],
    'q': ['ï½‘', 'â“ ', 'ðª', 'ð‘ž', 'ð’’', 'ð“º', 'ð”®', 'ð•¢', 'ð––', 'ð—Š', 'ð—¾', 'ð˜²', 'ð™¦', 'ðšš'],
    'r': ['ï½’', 'â“¡', 'ð«', 'ð‘Ÿ', 'ð’“', 'ð“»', 'ð”¯', 'ð•£', 'ð–—', 'ð—‹', 'ð—¿', 'ð˜³', 'ð™§', 'ðš›'],
    's': ['Ñ•', 'ï½“', 'â“¢', 'ð¬', 'ð‘ ', 'ð’”', 'ð“¼', 'ð”°', 'ð•¤', 'ð–˜', 'ð—Œ', 'ð˜€', 'ð˜´', 'ð™¨', 'ðšœ'],
    't': ['ð–™', 'ï½”', 'â“£', 'ð­', 'ð‘¡', 'ð’•', 'ð“½', 'ð”±', 'ð•¥', 'ð–™', 'ð—', 'ð˜', 'ð˜µ', 'ð™©', 'ðš'],
    'u': ['Õ½', 'ï½•', 'â“¤', 'ð®', 'ð‘¢', 'ð’–', 'ð“¾', 'ð”²', 'ð•¦', 'ð–š', 'ð—Ž', 'ð˜‚', 'ð˜¶', 'ð™ª', 'ðšž'],
    'v': ['ï½–', 'â“¥', 'ð¯', 'ð‘£', 'ð’—', 'ð“¿', 'ð”³', 'ð•§', 'ð–›', 'ð—', 'ð˜ƒ', 'ð˜·', 'ð™«', 'ðšŸ'],
    'w': ['Ô', 'ï½—', 'â“¦', 'ð°', 'ð‘¤', 'ð’˜', 'ð”€', 'ð”´', 'ð•¨', 'ð–œ', 'ð—', 'ð˜„', 'ð˜¸', 'ð™¬', 'ðš '],
    'x': ['Ñ…', 'ï½˜', 'â“§', 'ð±', 'ð‘¥', 'ð’™', 'ð”', 'ð”µ', 'ð•©', 'ð–', 'ð—‘', 'ð˜…', 'ð˜¹', 'ð™­', 'ðš¡'],
    'y': ['Ñƒ', 'ï½™', 'â“¨', 'ð²', 'ð‘¦', 'ð’š', 'ð”‚', 'ð”¶', 'ð•ª', 'ð–ž', 'ð—’', 'ð˜†', 'ð˜º', 'ð™®', 'ðš¢'],
    'z': ['ï½š', 'â“©', 'ð³', 'ð‘§', 'ð’›', 'ð”ƒ', 'ð”·', 'ð•«', 'ð–Ÿ', 'ð—“', 'ð˜‡', 'ð˜»', 'ð™¯', 'ðš£']
}

# Build an inverted dictionary for quick lookup
INVERSE_HOMOGLYPHS: Dict[str, str] = {}
for standard, variants in HOMOGLYPHS.items():
    for variant in variants:
        INVERSE_HOMOGLYPHS[variant] = standard

def detect_emojis(text: str) -> List[str]:
    """
    Detects emojis in text.
    
    This function identifies all emoji characters in the input text.
    
    Args:
        text: Text to analyze
        
    Returns:
        List of emojis found in the text. Empty list if no emojis are found
        or if the input is empty.
    """
    if not text:
        return []
    
    return EMOJI_PATTERN.findall(text)

def normalize_homoglyphs(text: str) -> str:
    """
    Normalizes Unicode characters that resemble standard ASCII characters.
    
    This function replaces homoglyphs (visually similar characters) with their
    standard ASCII equivalents to prevent obfuscation attacks.
    
    Args:
        text: Text to normalize
        
    Returns:
        Normalized text with homoglyphs replaced by their standard equivalents
    """
    if not text:
        return text
    
    result = ""
    for char in text:
        if char in INVERSE_HOMOGLYPHS:
            result += INVERSE_HOMOGLYPHS[char]
        else:
            result += char
    
    return result

def remove_emojis(text: str) -> str:
    """
    Removes all emojis from text.
    
    Args:
        text: Text from which to remove emojis
        
    Returns:
        Text with all emojis removed
    """
    if not text:
        return text
    
    return EMOJI_PATTERN.sub('', text)

def replace_emojis_with_description(text: str) -> str:
    """
    Replaces emojis with [EMOJI].
    
    This function substitutes all emoji characters with a standard token to
    maintain text structure while removing potentially problematic characters.
    
    Args:
        text: Text in which to replace emojis
        
    Returns:
        Text with emojis replaced by [EMOJI] tokens
    """
    if not text:
        return text
    
    return EMOJI_PATTERN.sub('[EMOJI]', text)

def check_for_obfuscation(text: str) -> Dict[str, List[str]]:
    """
    Checks if a text uses unusual or suspicious Unicode characters that could indicate
    an attempt at obfuscation or bypassing filters.
    
    This function examines text for various techniques often used to hide malicious content,
    such as homoglyphs, invisible characters, and unusual Unicode symbols.
    
    Args:
        text: Text to check
        
    Returns:
        Dictionary with detected obfuscation types and their corresponding characters.
        Returns an empty dictionary if no obfuscation is detected or the input is empty.
    """
    if not text:
        return {}
    
    results: Dict[str, List[str]] = {}
    
    # Check for emojis
    emojis = detect_emojis(text)
    if emojis:
        results["emojis"] = emojis
    
    # Check for homoglyphs
    detected_homoglyphs: List[str] = []
    for char in text:
        if char in INVERSE_HOMOGLYPHS and char != INVERSE_HOMOGLYPHS[char]:
            detected_homoglyphs.append(char)
    
    if detected_homoglyphs:
        results["homoglyphs"] = detected_homoglyphs
    
    # Check for control characters and other special characters
    control_chars: List[str] = []
    special_chars: List[str] = []
    
    for char in text:
        cat = unicodedata.category(char)
        if cat.startswith('C'):  # Control characters
            control_chars.append(repr(char))
        elif cat == 'Zs' and char != ' ':  # Non-standard spaces
            special_chars.append(repr(char))
        elif cat.startswith('S'):  # Symbols
            if char not in emojis:  # Avoid counting emojis twice
                special_chars.append(char)
    
    if control_chars:
        results["control_chars"] = control_chars
    
    if special_chars:
        results["special_chars"] = special_chars
    
    return results

def sanitize_text_from_obfuscation(text: str, replace_emojis: bool = True) -> str:
    """
    Sanitizes text by normalizing or removing all forms of obfuscation.
    
    This function handles multiple types of text obfuscation techniques:
    - Normalizes homoglyphs to their standard ASCII equivalents
    - Handles emojis by replacing or removing them
    - Standardizes spaces and control characters
    
    Args:
        text: Text to sanitize
        replace_emojis: If True, replaces emojis with [EMOJI], otherwise removes them
        
    Returns:
        Sanitized text with obfuscation techniques mitigated
    """
    if not text:
        return text
    
    # Normalize homoglyphs
    text = normalize_homoglyphs(text)
    
    # Handle emojis
    if replace_emojis:
        text = replace_emojis_with_description(text)
    else:
        text = remove_emojis(text)
    
    # Normalize spaces and control characters
    normalized_chars: List[str] = []
    for char in text:
        cat = unicodedata.category(char)
        if cat.startswith('C'):  # Control characters
            normalized_chars.append(' ')
        elif cat == 'Zs':  # All types of spaces become standard spaces
            normalized_chars.append(' ')
        else:
            normalized_chars.append(char)
    
    return ''.join(normalized_chars)

def contains_zalgo(text: str) -> bool:
    """
    Checks if text contains zalgo characters (combining characters).
    
    Zalgo text uses many combining Unicode characters to create a distorted,
    glitchy appearance that can bypass content filters.
    
    Args:
        text: Text to check
        
    Returns:
        True if the text contains zalgo characters, False otherwise
    """
    if not text:
        return False
    
    combining_chars_count = 0
    for char in text:
        if unicodedata.combining(char) > 0:
            combining_chars_count += 1
    
    # If more than 5 combining characters, it's probably zalgo
    return combining_chars_count > 5

def remove_zalgo(text: str) -> str:
    """
    Removes zalgo (combining characters) from text.
    
    This function removes combining characters that are often used to create
    glitchy, distorted text that might bypass content filters.
    
    Args:
        text: Text from which to remove zalgo characters
        
    Returns:
        Text with zalgo characters removed
    """
    if not text:
        return text
    
    normalized_chars: List[str] = []
    for char in text:
        if unicodedata.combining(char) == 0:
            normalized_chars.append(char)
    
    return ''.join(normalized_chars) 