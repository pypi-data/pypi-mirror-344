"""
API Layer Module

This module implements the API layer for the quantum-AI platform, providing
interfaces for external systems to interact with the platform's quantum and AI
capabilities. It serves as the main entry point for programmatic access to
the platform's features.

Key components:
- RESTful API endpoints for quantum computation requests
- GraphQL interface for complex quantum-AI queries
- WebSocket connections for real-time quantum simulation monitoring
- Authentication and authorization middleware
- Rate limiting and request validation
- API versioning and documentation

This module is designed following API-first principles and provides
comprehensive documentation through OpenAPI specifications.
"""

from flask import Blueprint, request, jsonify, current_app
from .probability_engine import calculate_probability, generate_random_statement, estimate_confidence, process_query as preprocess_query
from flask_cors import CORS  # Added for CORS support
from werkzeug.middleware.proxy_fix import ProxyFix
from .nlp_processor import NLPProcessor, NLPProcessorError
import random
import logging
import datetime
# from flask_talisman import Talisman  # Commented out for development
from flask_limiter import Limiter
from flask_limiter.util import get_remote_address
import werkzeug.exceptions
import time
from collections import defaultdict
from typing import Dict, Any, Tuple, Optional
from qiskit import QuantumCircuit
import json
from datetime import datetime
import numpy as np
from flask_limiter.errors import RateLimitExceeded
import uuid  # add import for UUID generation
from quantum_finance.quantum_ai.core.measurement_result import QuantumMeasurementResult
from quantum_finance.quantum_ai.predictors.ai_quantum_predictor import AiQuantumPredictor
from quantum_finance.quantum_ai.datatypes.uncertainty_metrics import UncertaintyMetrics
from quantum_finance.quantum_ai.datatypes.circuit_metadata import CircuitMetadata

# Configure logging
logging.basicConfig(level=logging.INFO, 
                    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# Create blueprint
api = Blueprint('api', __name__)

# Initialize limiter
limiter = Limiter(
    key_func=get_remote_address,
    default_limits=["200 per day", "50 per hour"]
)

# Enable CORS for all routes
CORS(api, resources={r"/api/*": {"origins": "*"}}, supports_credentials=True)

# Talisman configuration commented out for development
# Talisman(
#     api,
#     content_security_policy=None,
#     force_https=False,
#     strict_transport_security=False,
#     session_cookie_secure=False
# )

# Initialize NLP processor
try:
    nlp_processor = NLPProcessor()
    logger.info("NLP Processor initialized successfully")
except Exception as e:
    logger.error(f"Failed to initialize NLP Processor: {str(e)}")
    nlp_processor = None

# Rate limiting configuration
RATE_LIMIT_WINDOW = 60  # seconds
RATE_LIMIT_MAX_REQUESTS = 50
request_counts: Dict[str, list] = defaultdict(list)

# In-memory storage for quantum circuits
circuits = {}

def is_rate_limited(ip: str) -> bool:
    """Check if the request should be rate limited."""
    now = time.time()
    request_times = request_counts[ip]
    
    # Remove old requests outside the window
    while request_times and request_times[0] < now - RATE_LIMIT_WINDOW:
        request_times.pop(0)
    
    # Check if under limit
    if len(request_times) >= RATE_LIMIT_MAX_REQUESTS:
        return True
    
    # Add current request
    request_times.append(now)
    return False

def init_app(app):
    """Initialize the blueprint with the Flask app"""
    # Enable CORS for all routes
    CORS(app, resources={r"/api/*": {"origins": "*"}}, supports_credentials=True)
    
    # Register the blueprint
    app.register_blueprint(api, url_prefix='/api')
    
    return limiter

@api.before_request
def log_request_info():
    """Log details of each request"""
    logger.info(f"Request: {request.method} {request.path} from {request.remote_addr}")
    logger.info(f"Headers: {request.headers}")
    if request.is_json:
        logger.info(f"JSON Body: {request.get_json()}")

@api.after_request
def after_request(response):
    """Add CORS headers to each response"""
    response.headers.add('Access-Control-Allow-Origin', '*')
    response.headers.add('Access-Control-Allow-Headers', 'Content-Type,Authorization')
    response.headers.add('Access-Control-Allow-Methods', 'GET,POST,OPTIONS')
    
    logger.info(f"Response: {response.status_code} - {response.headers}")
    if response.status_code >= 400:
        logger.error(f"Error response {response.status_code}: {response.data if hasattr(response, 'data') else 'No data'}")
    
    return response

# Helper for standardized error responses
# Ensures all error responses include required contract fields
# The 'error' field must contain the specific error message (e.g., 'Query is required')
# The 'message' field can be a general or supporting message

def make_error_response(error, message, status_code=400, category="Error", processor_status="error"):
    return jsonify({
        'response': {
            'error': error,  # Specific error message for contract compliance
            'message': message,  # General/supporting message
            'category': category,
            'timestamp': datetime.now().isoformat(),
            'processor_status': processor_status
        }
    }), status_code

@api.errorhandler(404)
def not_found_error(error):
    """Handle 404 Not Found errors. Contract: All error responses must be wrapped in 'response' key and include required fields."""
    return make_error_response('The requested resource does not exist', 'Not Found', 404)

@api.errorhandler(405)
def method_not_allowed_error(error):
    """Handle 405 Method Not Allowed errors. Contract: All error responses must be wrapped in 'response' key and include required fields."""
    return make_error_response(f'The method {request.method} is not allowed for this endpoint', 'Method Not Allowed', 405)

@api.errorhandler(Exception)
def handle_exception(error):
    """Handle all other exceptions. Contract: All error responses must be wrapped in 'response' key and include required fields."""
    if isinstance(error, werkzeug.exceptions.BadRequest):
        return make_error_response(str(error), 'Invalid request', 400)
    logger.error(f"Unhandled exception: {str(error)}", exc_info=True)
    return make_error_response('An unexpected error occurred', 'Internal server error', 500)

@api.route('/health', methods=['GET'])
def health_check():
    """Health check endpoint."""
    try:
        return jsonify({
            'status': 'healthy',
            'service': 'quantum-ai-api',
            'version': '1.0.0',
            'timestamp': datetime.now().isoformat()
        })
    except Exception as e:
        logger.error(f"Error in health check: {str(e)}")
        return jsonify({
            'error': 'Health check failed',
            'message': str(e)
        }), 500

# Add catch-all route for 404s
@api.route('/<path:path>', methods=['GET', 'POST', 'PUT', 'DELETE', 'PATCH'])
def catch_all(path):
    """Catch-all route to handle non-existent endpoints."""
    # Check if the path exists but method is not allowed
    for rule in current_app.url_map.iter_rules():
        if rule.rule == f'/api/v1/{path}':
            return jsonify({
                'error': 'Method Not Allowed',
                'message': f'The method {request.method} is not allowed for this endpoint'
            }), 405
    
    # If path doesn't exist, return 404
    return jsonify({
        'error': 'Not Found',
        'message': f'The endpoint /{path} does not exist'
    }), 404

@api.route('/query', methods=['POST'])
# @limiter.limit("10 per minute")  # Disabled for testing, restore for production
def handle_query():
    """Handle natural language queries"""
    try:
        data = request.get_json()
        if not data or 'query' not in data:
            return make_error_response('Request must include a query', 'Invalid request', 400)
            
        query = data['query']
        probability = calculate_probability(query)
        response = f"There is a {probability:.2f}% chance that: {query}"
        return jsonify({
            'response': response,
            'probability': probability,
            'query': query
        })
    except Exception as e:
        logger.error(f"Error processing query: {str(e)}", exc_info=True)
        return make_error_response(str(e), 'Processing error', 500)

@api.route('/random', methods=['GET'])
def handle_random():
    """Generate random quantum states."""
    try:
        # Check rate limit
        ip = request.remote_addr or "0.0.0.0"  # Default to 0.0.0.0 if remote_addr is None
        if is_rate_limited(ip):
            return make_error_response(f'Maximum {RATE_LIMIT_MAX_REQUESTS} requests per {RATE_LIMIT_WINDOW} seconds', 'Rate limit exceeded', 429)
            
        # Generate random statement
        statement, probability = generate_random_statement()
        confidence = estimate_confidence(statement, probability)
        response = {
            'response': f"I'm {probability:.2f}% certain that {statement}",
            'probability': probability,
            'confidence': confidence
        }
        return jsonify(response)
    except Exception as e:
        logger.error(f"Error in random endpoint: {str(e)}")
        return make_error_response(str(e), 'Processing error', 500)

@api.route('/probability', methods=['POST'])
# @limiter.limit("10 per minute")  # Disabled for testing, restore for production
def probability_endpoint():
    """Calculate probability for a given query"""
    try:
        data = request.get_json()
        if not data or 'query' not in data:
            return make_error_response('Request must include a query', 'Invalid request', 400)
            
        query = data['query']
        processed_query = preprocess_query(query)
        probability = calculate_probability(processed_query)
        return jsonify({
            'probability': probability,
            'query': query,
            'processed_query': processed_query
        })
    except Exception as e:
        logger.error(f"Error calculating probability: {str(e)}", exc_info=True)
        return make_error_response(str(e), 'Processing error', 500)

def serialize_circuit(circuit: QuantumCircuit) -> dict:
    """Serialize a Qiskit QuantumCircuit to a JSON-compatible format."""
    gates = []
    try:
        for instruction in circuit.data:
            # Safely get qubit indices, handling cases where index attribute might be missing
            qubit_indices = []
            for i, q in enumerate(instruction.qubits):
                try:
                    # First try to use find_bit to get the index
                    bit = circuit.find_bit(q)
                    if hasattr(bit, 'index'):
                        qubit_indices.append(bit.index)
                    else:
                        # If no index attribute, use the position in the circuit's qubits list
                        qubit_indices.append(circuit.qubits.index(q))
                except (AttributeError, ValueError):
                    # Fallback: use the position in the instruction's qubits list
                    qubit_indices.append(i)
            
            gate_data = {
                'name': instruction.operation.name,
                'params': [],
                'qubits': qubit_indices
            }
            
            # Add parameters if available
            for param in instruction.operation.params:
                # Convert numpy types to Python native types
                if hasattr(param, 'dtype') and np.issubdtype(param.dtype, np.integer):
                    gate_data['params'].append(int(param))
                elif hasattr(param, 'dtype') and np.issubdtype(param.dtype, np.floating):
                    gate_data['params'].append(float(param))
                elif hasattr(param, 'numpy') and callable(getattr(param, 'numpy')):
                    # Handle ParameterExpression by evaluating to a numpy array and then converting
                    gate_data['params'].append(float(param.numpy()))
                elif isinstance(param, complex):
                    gate_data['params'].append({'real': float(param.real), 'imag': float(param.imag)})
                else:
                    # Convert any other type to string to ensure serialization works
                    gate_data['params'].append(str(param))
            
            gates.append(gate_data)
    except Exception as e:
        logger.warning(f"Error during circuit serialization: {str(e)}")
        # Provide minimal circuit information when serialization of instructions fails
        return {
            'num_qubits': getattr(circuit, 'num_qubits', 0),
            'num_clbits': getattr(circuit, 'num_clbits', 0),
            'qubits': list(range(getattr(circuit, 'num_qubits', 0))),
            'operations': [],
            'gates': [],
            'serialization_error': str(e)
        }
    
    # Format matching both our API expectations and the test expectations
    result = {
        'num_qubits': circuit.num_qubits,
        'num_clbits': circuit.num_clbits,
        'gates': gates,
        'qubits': list(range(circuit.num_qubits)),  # Add qubits field for compatibility with tests
        'operations': gates  # Add operations field as alias to gates for compatibility with tests
    }
    
    return result

class CircuitJSONEncoder(json.JSONEncoder):
    """Custom JSON encoder that can handle QuantumCircuit objects and various NumPy types."""
    
    def default(self, obj):
        """Handle encoding of non-standard Python types."""
        try:
            # Handle QuantumCircuit objects
            if isinstance(obj, QuantumCircuit):
                return serialize_circuit(obj)
            
            # Handle numpy arrays
            if isinstance(obj, np.ndarray):
                return obj.tolist()
            
            # Handle numpy data types using concrete types instead of generics
            if hasattr(obj, 'dtype') and np.issubdtype(obj.dtype, np.integer):
                return int(obj)
            if hasattr(obj, 'dtype') and np.issubdtype(obj.dtype, np.floating):
                return float(obj)
            if hasattr(obj, 'dtype') and np.issubdtype(obj.dtype, np.bool_):
                return bool(obj)
                
            # Handle complex numbers
            if isinstance(obj, complex):
                return {'real': float(obj.real), 'imag': float(obj.imag)}

            # Handle sets by converting to lists
            if isinstance(obj, set):
                return list(obj)
                
            # Handle any other numpy types we might have missed
            if hasattr(np, 'dtype') and isinstance(obj, np.dtype):
                return str(obj)
                
            # Handle any Qiskit specific types that aren't already covered
            if 'qiskit' in str(type(obj).__module__):
                # First try to use serialize_circuit with a cast if it's a circuit-like object
                if hasattr(obj, 'to_circuit') and callable(getattr(obj, 'to_circuit')):
                    try:
                        circuit = obj.to_circuit()
                        if isinstance(circuit, QuantumCircuit):
                            return serialize_circuit(circuit)
                    except Exception as circuit_err:
                        logger.debug(f"to_circuit() method failed for {type(obj)}: {str(circuit_err)}")
                        # Continue to alternative methods
                
                # Try to convert to dict if the object has a to_dict method
                if hasattr(obj, 'to_dict') and callable(getattr(obj, 'to_dict')):
                    try:
                        return obj.to_dict()
                    except Exception as dict_err:
                        logger.debug(f"to_dict() method failed for {type(obj)}: {str(dict_err)}")
                        # Continue to alternative methods
                        
                # Handle Parameter and ParameterExpression objects
                if hasattr(obj, 'is_parameterized') and callable(getattr(obj, 'is_parameterized')):
                    if hasattr(obj, 'params') and obj.params:
                        return {"parameter_expression": str(obj), "parameters": [str(p) for p in obj.params]}
                    else:
                        return {"parameter": str(obj)}
                
                # Try to use __dict__ if available to create a dictionary representation
                if hasattr(obj, '__dict__'):
                    clean_dict = {}
                    for key, value in obj.__dict__.items():
                        if not key.startswith('_'):  # Skip private attributes
                            try:
                                # Test if the value is JSON serializable
                                json.dumps(value)
                                clean_dict[key] = value
                            except (TypeError, OverflowError):
                                # If we can't directly serialize, convert to dictionary if possible
                                if hasattr(value, 'to_dict') and callable(getattr(value, 'to_dict')):
                                    try:
                                        clean_dict[key] = value.to_dict()
                                    except Exception:
                                        clean_dict[key] = str(value)
                                else:
                                    clean_dict[key] = str(value)
                    if clean_dict:
                        return clean_dict
                
                # As a last resort, create a meaningful dictionary with type and string representation
                return {
                    "type": type(obj).__name__,
                    "module": type(obj).__module__,
                    "representation": str(obj)
                }
                
            # Let the parent class handle anything else or raise TypeError
            return super().default(obj)
            
        except Exception as e:
            # Catch any unexpected errors in the serialization process
            logger.warning(f"Unexpected error during JSON serialization of type {type(obj)}: {str(e)}")
            
            # Always return a dictionary instead of a string to ensure proper format
            return {
                "type": type(obj).__name__,
                "error": f"Non-serializable object: {str(e)}",
                "representation": str(obj)
            }

def sanitize_for_json(data):
    """
    Recursively sanitize data for JSON serialization.
    
    This function walks through nested dictionaries and lists to ensure all values
    can be safely serialized to JSON. Any unserializable objects are converted to strings.
    
    Args:
        data: Any Python object to be sanitized
        
    Returns:
        A sanitized version of the input data that can be safely JSON serialized
    """
    if isinstance(data, dict):
        return {k: sanitize_for_json(v) for k, v in data.items()}
    elif isinstance(data, list):
        return [sanitize_for_json(item) for item in data]
    elif isinstance(data, tuple):
        return [sanitize_for_json(item) for item in data]
    elif isinstance(data, (str, int, float, bool, type(None))):
        return data
    elif isinstance(data, np.ndarray):
        return data.tolist()
    elif hasattr(data, 'dtype') and np.issubdtype(data.dtype, np.integer):
        return int(data)
    elif hasattr(data, 'dtype') and np.issubdtype(data.dtype, np.floating):
        return float(data)
    elif hasattr(data, 'dtype') and np.issubdtype(data.dtype, np.bool_):
        return bool(data)
    elif isinstance(data, complex):
        return {'real': float(data.real), 'imag': float(data.imag)}
    elif isinstance(data, set):
        return list(data)
    # Skip QuantumCircuit objects - let the CircuitJSONEncoder handle them
    elif isinstance(data, QuantumCircuit):
        return data  # Return as is for the CircuitJSONEncoder to handle
    # Skip any other Qiskit objects that may have serialization handlers
    elif 'qiskit' in str(type(data).__module__):
        return data  # Return as is for the CircuitJSONEncoder to handle
    else:
        # Last resort: convert to string
        try:
            return str(data)
        except:
            return f"<Unserializable object of type {type(data).__name__}>"

@api.route('/nlp', methods=['POST'])
# @limiter.limit("10 per minute")  # Disabled for testing, restore for production
def nlp_processing():
    """
    Process natural language queries.
    Contract: All error responses must be wrapped in 'response' key and include required fields.
    - For empty or missing query: error message must include both 'Invalid request' and 'Query is required' (for test compatibility and clarity).
    - For NLPProcessorError and other exceptions: error message must be propagated into the 'error' field.
    - See tests/integration/test_nlp_api_endpoint.py for contract source of truth.
    """
    try:
        if not request.is_json:
            # Contract: error must include 'Invalid request' for non-JSON
            return make_error_response('Invalid request: Request must be JSON', 'Invalid request', 400)

        data = request.get_json()
        if data is None:
            # Contract: error must include 'Invalid request' for empty JSON
            return make_error_response('Invalid request: Empty JSON body', 'Invalid request', 400)
            
        query = data.get('query')
        if not query:
            # Contract: error must include both 'Invalid request' and 'Query is required'
            return make_error_response('Invalid request: Query is required', 'Invalid request', 400)

        logger.info(f"Processing NLP query: {query}...")
        
        # Ensure NLP processor is initialized
        global nlp_processor
        if nlp_processor is None:
            # Try to reinitialize the NLP processor if it was not initialized successfully before
            try:
                nlp_processor = NLPProcessor()
                logger.info("NLP Processor reinitialized successfully")
            except Exception as e:
                logger.error(f"Failed to reinitialize NLP Processor: {str(e)}")
                return make_error_response(f"Server configuration error: {str(e)}", 'Server configuration error', 500)
        
        try:    
            result = nlp_processor.process_query(query)
            logger.info(f"Successfully processed NLP query. Category: {result.get('category', 'Unknown')}")

            # First sanitize the result to ensure it can be serialized,
            # but preserving QuantumCircuit objects for proper handling
            sanitized_result = sanitize_for_json(result) if result is not None else {}
            
            # --- CONTRACT CLARIFICATION: April 2025 ---
            # Per integration test and docs/knowledge_base/quantum/performance_optimization.md,
            # the API must return a dict with a 'response' key, and if present, 'circuit' must be nested under 'response'.
            # This aligns with the integration test as the source of truth for contract compliance.
            response_payload = {}
            if isinstance(sanitized_result, dict) and 'circuit' in sanitized_result:
                # Move 'circuit' under 'response'
                circuit_val = sanitized_result.pop('circuit')
                sanitized_result['circuit'] = circuit_val
            response_payload['response'] = sanitized_result
            try:
                response = json.loads(json.dumps(response_payload, cls=CircuitJSONEncoder))
                return jsonify(response)
            except Exception as e:
                logger.error(f"JSON serialization error: {str(e)}", exc_info=True)
                # Fallback to a simplified response if serialization fails
                return make_error_response(f"Could not serialize response: {str(e)}", 'JSON serialization error', 500)
        except NLPProcessorError as e:
            # Contract: propagate NLPProcessorError message into 'error' field
            logger.error(f"NLP processor error: {str(e)}")
            return make_error_response(f"NLP processing error: {str(e)}", 'NLP processing error', 400)
        except Exception as e:
            # Contract: propagate exception message into 'error' field
            logger.error(f"Unexpected error in NLP processing: {str(e)}", exc_info=True)
            return make_error_response(f"Internal server error: {str(e)}", 'Internal server error', 500)
    except Exception as e:
        # Contract: propagate exception message into 'error' field
        logger.error(f"Unhandled exception in NLP processing: {str(e)}", exc_info=True)
        return make_error_response(f"Internal server error: {str(e)}", 'Internal server error', 500)

# Special debug endpoints for troubleshooting
@api.route('/debug/echo', methods=['POST'])
def debug_echo():
    """Debug echo endpoint that returns the received data."""
    try:
        # Log request details
        logger.info(f"Debug echo received: {request.get_json()}")
        
        # Echo the request data back with some metadata
        response_data = {
            'echo': request.get_json(),
            'timestamp': datetime.now().isoformat(),
            'status': 'ok'
        }
        
        return jsonify(response_data)
    except Exception as e:
        # Log the error
        logger.error(f"Error in debug echo: {str(e)}", exc_info=True)
        
        # Return error response
        return jsonify({
            'status': 'error',
            'error': str(e)
        }), 500

@api.route('/debug/cors', methods=['GET', 'POST', 'OPTIONS'])
def debug_cors():
    """Special endpoint to debug CORS issues"""
    if request.method == 'OPTIONS':
        # Handle preflight request
        response = jsonify({'status': 'preflight_ok'})
        response.headers.add('Access-Control-Allow-Origin', '*')
        response.headers.add('Access-Control-Allow-Headers', 'Content-Type')
        response.headers.add('Access-Control-Allow-Methods', 'GET,POST,OPTIONS')
        return response
        
    return jsonify({
        'status': 'ok',
        'cors_test': 'passed',
        'method': request.method,
        'headers': dict(request.headers),
        'origin': request.headers.get('Origin', 'No origin header')
    })

@api.route('/suggestions', methods=['GET'])
def get_suggestions():
    """Return a list of suggested queries for the user"""
    suggestions = [
        "What is the probability of rolling a 6 on a fair die?",
        "If I flip a coin 10 times, what's the chance of getting exactly 5 heads?",
        "What's the probability of drawing an ace from a standard deck?",
        "What are the odds of winning a lottery with 1 in 14 million chance three times in a row?",
        "What's the probability of getting a royal flush in poker?"
    ]
    return jsonify({'suggestions': suggestions})

@api.route('/nlp/debug', methods=['GET'])
def nlp_debug():
    """Debug endpoint for checking NLP component status."""
    try:
        # Check if NLP processor is available
        global nlp_processor
        if nlp_processor is None:
            # Try to reinitialize the NLP processor 
            try:
                nlp_processor = NLPProcessor()
                logger.info("NLP Processor reinitialized successfully during debug check")
            except Exception as e:
                logger.error(f"Failed to reinitialize NLP Processor during debug check: {str(e)}")
            
        # Get processor status
        # Add check here: Ensure nlp_processor is not None before proceeding
        if nlp_processor is None:
            logger.error("NLP Processor is None even after reinitialization attempt in debug check.")
            return jsonify({
                "status": "error",
                "error": "NLP processor could not be initialized.",
                "nlp_processor": {
                    "initialized": False,
                    "timestamp": datetime.now().isoformat(),
                    "backend_version": "1.0.0"
                }
            }), 500
            
        try:
            test_result = nlp_processor.process_query("test quantum circuit")
            # Sanitize the test result to ensure it can be serialized
            sanitized_test_result = sanitize_for_json(test_result) if test_result is not None else {}
            
            status = {
                "initialized": getattr(nlp_processor, 'initialized', False),
                "timestamp": datetime.now().isoformat(),
                "backend_version": "1.0.0",
                "test_query_result": sanitized_test_result
            }
            
            return jsonify({
                "status": "ok",
                "nlp_processor": status
            })
        except NLPProcessorError as e:
            logger.error(f"NLP processor error during debug check: {str(e)}")
            return jsonify({
                "status": "error",
                "error": f"NLP processor error: {str(e)}",
                "nlp_processor": {
                    "initialized": getattr(nlp_processor, 'initialized', False),
                    "timestamp": datetime.now().isoformat(),
                    "backend_version": "1.0.0"
                }
            }), 500
            
    except Exception as e:
        logger.error(f"NLP debug endpoint error: {str(e)}", exc_info=True)
        return jsonify({
            "status": "error",
            "error": f"Debug endpoint error: {str(e)}"
        }), 500

# ---------------------------------------------------------------------------------
# GLOBAL ERROR HANDLER FOR RATELIMITEXCEEDED (429 Too Many Requests)
# Ensures contract compliance: all fields nested under 'response' key.
# See integration tests and docs/knowledge_base.md for rationale.
# ---------------------------------------------------------------------------------
@api.errorhandler(RateLimitExceeded)
def handle_rate_limit_exceeded(e):
    # Compose contract-compliant error response
    response = {
        "response": {
            "category": "Error",
            "error": str(e),
            "message": "Too many requests. Please try again later.",
            "processor_status": "error",
            "timestamp": datetime.now().isoformat()
        }
    }
    return jsonify(response), 429

@api.route('/', methods=['GET'])
def root():
    """Root endpoint returning a welcome message"""
    return jsonify({"message": "Welcome to the Quantum Computing API"})

@api.route('/circuit', methods=['POST'])
def create_circuit():
    """Create a new quantum circuit with a specified number of qubits"""
    data = request.get_json() or {}
    num_qubits = data.get('num_qubits')
    if not isinstance(num_qubits, int) or num_qubits < 1:
        return make_error_response('Invalid num_qubits', 'num_qubits must be a positive integer', 400)
    circuit_id = str(uuid.uuid4())
    circuits[circuit_id] = {'num_qubits': num_qubits, 'gates': []}
    return jsonify({'circuit_id': circuit_id})

@api.route('/circuit/<circuit_id>/gate', methods=['POST'])
def add_gate(circuit_id):
    """Add a gate to an existing circuit"""
    if circuit_id not in circuits:
        return not_found_error(werkzeug.exceptions.NotFound())
    data = request.get_json() or {}
    gate = data.get('gate')
    qubit = data.get('qubit')
    allowed_gates = {'H', 'X', 'Y', 'Z', 'CX'}
    if gate not in allowed_gates or not isinstance(qubit, int) or qubit < 0 or qubit >= circuits[circuit_id]['num_qubits']:
        return make_error_response('Invalid gate or qubit', 'Unsupported gate or qubit index', 400)
    circuits[circuit_id]['gates'].append({'gate': gate, 'qubit': qubit})
    return jsonify({'message': 'Gate added successfully'})

@api.route('/circuit/<circuit_id>/measure', methods=['GET'])
def measure_circuit(circuit_id):
    """Measure a circuit, returning random results based on qubit count"""
    if circuit_id not in circuits:
        return not_found_error(werkzeug.exceptions.NotFound())
    num_qubits = circuits[circuit_id]['num_qubits']
    # Simple simulation: random bit for each qubit
    result = [random.choice([0, 1]) for _ in range(num_qubits)]
    return jsonify({'result': result})

@api.route('/predict', methods=['POST'])
@limiter.limit("50 per minute")  # Rate limit for prediction endpoint
def predict():
    """Generate quantum-enhanced predictions with uncertainty estimates.
    
    Expected request format:
    {
        "quantum_measurements": {
            "counts": {                # Required: Measurement counts by bitstring
                "00": 100,
                "01": 200,
                "10": 300,
                "11": 400
            },
            "metadata": {              # Required: Circuit metadata
                "num_qubits": 2,
                "circuit_depth": 10,
                "circuit_id": "test_circuit",
                "measurement_basis": "Z"
            },
            "uncertainty": {           # Optional: Uncertainty metrics
                "total_uncertainty": float,
                "quantum_uncertainty": float,
                "classical_uncertainty": float,
                "shot_noise": float,
                "gate_error_estimate": float
            },
            "shots": 1000             # Optional: Number of measurement shots
        },
        "config": {                   # Optional configuration
            "include_uncertainty": bool,
            "mc_samples": int,
            "uncertainty_method": str
        }
    }

    Returns:
    {
        "prediction": {
            "value": float,      # The predicted value
            "uncertainty": float, # Uncertainty estimate (if requested)
            "timestamp": str,    # ISO format timestamp
            "metadata": {...}    # Additional prediction metadata
        }
    }
    """
    try:
        # Validate request
        if not request.is_json:
            return make_error_response(
                "Invalid request format", 
                "Request must be JSON", 
                400
            )

        data = request.get_json()
        
        # Extract and validate quantum measurements
        if "quantum_measurements" not in data:
            return make_error_response(
                "Missing quantum_measurements", 
                "Request must include quantum_measurements object", 
                400
            )

        measurements = data["quantum_measurements"]
        
        # Validate required fields
        required_fields = {
            "counts": dict,
            "metadata": dict
        }
        for field, expected_type in required_fields.items():
            if field not in measurements:
                return make_error_response(
                    f"Missing {field}",
                    f"quantum_measurements must include {field}",
                    400
                )
            if not isinstance(measurements[field], expected_type):
                return make_error_response(
                    f"Invalid {field} type",
                    f"{field} must be a {expected_type.__name__}",
                    400
                )

        # Extract configuration
        config = data.get("config", {})
        include_uncertainty = config.get("include_uncertainty", True)
        mc_samples = config.get("mc_samples", 30)
        
        # Create measurement result object
        try:
            # Convert metadata dict to CircuitMetadata
            metadata = CircuitMetadata(**measurements["metadata"])
            
            # Create uncertainty metrics if provided
            uncertainty = None
            if "uncertainty" in measurements:
                uncertainty = UncertaintyMetrics(**measurements["uncertainty"])
            
            # Create measurement result
            measurement_result = QuantumMeasurementResult(
                counts=measurements["counts"],
                metadata=metadata,
                uncertainty=uncertainty,
                shots=measurements.get("shots", 1024)
            )
        except Exception as e:
            return make_error_response(
                "Invalid measurement data",
                str(e),
                400
            )

        # Get or create predictor instance
        predictor = current_app.config.get('quantum_predictor')
        if predictor is None:
            # Create a new predictor if none exists
            predictor = AiQuantumPredictor(
                model=None,  # Will use fallback behavior
                uncertainty_aware=True
            )
            current_app.config['quantum_predictor'] = predictor

        # Generate prediction
        prediction, uncertainty = predictor.predict(
            quantum_result=measurement_result,
            include_uncertainty=include_uncertainty,
            mc_samples=mc_samples
        )

        # Format response
        response = {
            "prediction": {
                "value": float(prediction.flatten()[0]),
                "uncertainty": float(uncertainty.flatten()[0]) if include_uncertainty else None,
                "timestamp": datetime.now().isoformat(),
                "metadata": {
                    "mc_samples": mc_samples if include_uncertainty else None,
                    "model_version": "1.0.0",  # You'd want to get this from your model
                    "num_qubits": metadata.num_qubits,
                    "circuit_depth": metadata.circuit_depth
                }
            }
        }

        return jsonify(response)

    except Exception as e:
        logger.error(f"Prediction error: {str(e)}", exc_info=True)
        return make_error_response(
            "Prediction failed",
            str(e),
            500
        )

if __name__ == '__main__':
    # In Docker, we need to listen on 0.0.0.0 to be accessible from outside the container
    from flask import Flask
    app = Flask(__name__)
    app.register_blueprint(api)
    app.run(debug=False, host='0.0.0.0', port=5004)