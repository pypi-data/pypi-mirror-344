{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import rtsvg\n",
    "rt = rtsvg.RACETrack()\n",
    "from xwords import XWords, XWordsSolver\n",
    "import copy\n",
    "import os\n",
    "_dir_    = '../../../data/crossword_puzzle_screenshots/'\n",
    "_files_  = os.listdir(_dir_)\n",
    "entries_file    = None\n",
    "geometries_file = None\n",
    "blockers_file   = None\n",
    "answers_file    = None\n",
    "for _file_ in _files_:\n",
    "    if   'entries'    in _file_: entries_file    = _dir_ + _file_\n",
    "    elif 'geometries' in _file_: geometries_file = _dir_ + _file_\n",
    "    elif 'blockers'   in _file_: blockers_file   = _dir_ + _file_\n",
    "    elif 'answers'    in _file_: answers_file    = _dir_ + _file_\n",
    "xwords = XWords(rt, entries_file, geometries_file, blockers_file, answers_file)\n",
    "results_lu = {}\n",
    "xwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import importlib.util\n",
    "import inspect\n",
    "def getClassesFromFile(file_path):\n",
    "    classes = []\n",
    "    module_name = os.path.splitext(os.path.basename(file_path))[0]\n",
    "    spec        = importlib.util.spec_from_file_location(module_name, file_path)\n",
    "    module      = importlib.util.module_from_spec(spec)\n",
    "    spec.loader.exec_module(module)\n",
    "    for name, obj in inspect.getmembers(module):\n",
    "        if inspect.isclass(obj) and obj.__module__ == module.__name__: classes.append(obj)\n",
    "    return classes\n",
    "#models = ['gemma3:1b', 'gemma3:27b'] # ['gemma3:1b', 'gemma3:4b', 'phi4', 'qwq', 'gemma3:27b', 'llama3.2', 'granite3.1-dense', 'qwen2.5:14b', 'deepseek-r1:32b']\n",
    "models = ['exaone-deep','cogito:3b','cogito:32b','deepcoder:1.5b','deepcoder','llama3.2:1b',\n",
    "          'deepseek-r1:8b','deepseek-r1:7b','deepseek-r1:1.5b','gemma3:1b','gemma3:4b',\n",
    "          'gemma3:12b','llama3.2-vision:11b','gemma3:27b','qwq',\n",
    "          'phi4-mini','openthinker:32b','deepseek-r1:32b','granite3.1-dense',\n",
    "          'llama3.2','phi4','qwen2.5:14b','deepseek-r1:14b',]\n",
    "for _model_ in models:\n",
    "    print(_model_)\n",
    "    for _filename_ in os.listdir():\n",
    "        if _filename_.endswith('.py') == False: continue\n",
    "        for _class_ in getClassesFromFile(_filename_):\n",
    "            if issubclass(_class_, XWordsSolver):\n",
    "                if _class_.__name__ not in results_lu: results_lu[_class_.__name__] = {}\n",
    "                print(_class_)\n",
    "                if _model_ in results_lu[_class_.__name__]: continue\n",
    "                xwords_copy = copy.deepcopy(xwords)\n",
    "                _instance_ = _class_(xwords=xwords_copy, model=_model_)\n",
    "                answer_lu, request_stats, num_of_llm_requests = _instance_.solve()\n",
    "                char_level_acc = xwords_copy.characterLevelAccuracy()\n",
    "                results_lu[_class_.__name__][_model_] = (answer_lu, request_stats, num_of_llm_requests, char_level_acc, xwords_copy)\n",
    "                print(f'\\n{_class_.__name__} {_model_} {char_level_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_tiles_ = []\n",
    "for _algo_ in results_lu.keys():\n",
    "    for _model_ in models:\n",
    "        if _model_ not in results_lu[_algo_]: _xwords_ = copy.deepcopy(xwords)\n",
    "        else:                                 _xwords_ = results_lu[_algo_][_model_][4]\n",
    "        _tiles_.append(_xwords_.smallMultipleSVG())\n",
    "rt.table(_tiles_, per_row=len(models), spacer=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "_df_answers_ = {'algorithm':[], 'model':[], 'clue_number':[], 'orientation':[], 'answer':[]}\n",
    "_df_results_ = {'algorithm':[], 'model':[], 'char_level_accuracy':[], 'num_of_llm_requests':[], 'time':[], 'prompt_tokens':[], 'output_tokens':[]}\n",
    "for _algo_ in results_lu.keys():\n",
    "    for _model_ in results_lu[_algo_].keys():\n",
    "        _tuple_ = results_lu[_algo_][_model_]\n",
    "        _time_sum_, _prompt_sum_, _output_sum_ = 0.0, 0, 0\n",
    "        for x in _tuple_[1]:\n",
    "            _time_sum_   += x[2]\n",
    "            _prompt_sum_ += x[3]\n",
    "            _output_sum_ += x[4]\n",
    "        _num_of_llm_requests_ = _tuple_[2]\n",
    "        _char_level_accuracy_ = _tuple_[3]\n",
    "        for _clue_ in _tuple_[0].keys():\n",
    "            _df_answers_['algorithm'].append(_algo_)\n",
    "            _df_answers_['model'].append(_model_)\n",
    "            _df_answers_['clue_number'].append(_clue_[0])\n",
    "            _df_answers_['orientation'].append(_clue_[1])\n",
    "            _df_answers_['answer'].append(_tuple_[0][_clue_])\n",
    "        _df_results_['algorithm'].append(_algo_)\n",
    "        _df_results_['model'].append(_model_)\n",
    "        _df_results_['char_level_accuracy'].append(_char_level_accuracy_)\n",
    "        _df_results_['num_of_llm_requests'].append(_num_of_llm_requests_)\n",
    "        _df_results_['time'].append(_time_sum_)\n",
    "        _df_results_['prompt_tokens'].append(_prompt_sum_)\n",
    "        _df_results_['output_tokens'].append(_output_sum_)\n",
    "df_answers = pd.DataFrame(_df_answers_)\n",
    "df_results = pd.DataFrame(_df_results_)\n",
    "#df_answers.to_parquet(_dir_ + '20250412b_xwords_answers.parquet')\n",
    "#df_results.to_parquet(_dir_ + '20250412b_xwords_results.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parms = {'color_by':'model', 'w':384, 'h':384}\n",
    "rt.tile([rt.xy(df_results, x_field='time', y_field='char_level_accuracy', dot_size='large', **parms),\n",
    "         rt.histogram(df_results, bin_by='algorithm', count_by='char_level_accuracy', h=384, w=256),\n",
    "         rt.histogram(df_results, bin_by='model',     count_by='char_level_accuracy', **parms)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
