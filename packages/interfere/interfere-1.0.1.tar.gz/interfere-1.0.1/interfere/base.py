"""This file is home to all abstract base classes in the interfere package. Most functionality in interfere is designed around interactions between these three objects.

Classes:
    DynamicModel: This is the base class for all models in the interfere.
        dynamics submodule. Inheriting classes must implement a _simulate() 
        method and an __init__() method. See interfere.dynamics.base for 
        several examples.
    ExogIntervention: The base class for exogenous interventions. Inheriting 
        classes should implement a __call__() method. See interfere.
        interventions for examples. 
    ForecastMethod: Implements the base class for the forecasting method. 
        Subclasses must implement _fit(), _predict(), _get_test_params(), _get_optuna_params(). See interfere._methods for examples. 

Notes:
    Arg Handling: Most of the error handling is done in the base classes in 
        order to avoid doing heavy error handling in every custom subclass.
        Additionally, the interfer package is structured to do optional argument
        handling in the base classes to guarantee that a minimum of the 
        variables passed to abstract methods are empty. This is done so that 
        inhereted subclasses can assume that most of the arguments to _simulate 
        or _predict() etc. are non null. This is not always possible (i.e. for 
        exog time series) but an effort was made to comply with this heuristic.
    Non-Exogenous Interventions: Interventions that interact with the 
        endogenous state of the dynamic system are possible, and relevant. (As 
        an example consider an intervention that acts differently depending on 
        the state of the system.) This kind of intervention is compatible with 
        parts of the interfere API, but challenging to integrate with most 
        forecasting methods because they are built around the idea of exogenous 
        input. The interfere.dynamics.generative_forecasters module is an 
        interesting look at a possible way to wrap forecasters in a recursive 
        prediction structure that would enable non-exogenous interventions. 
        Something to think about for a future date.
"""
from abc import ABC, abstractmethod
from typing import Any, Dict, Callable, List, Optional, Union
from warnings import warn

import numpy as np
import pandas as pd
from sklearn.base import BaseEstimator

from .utils import copy_doc

# Default range for random number generation.
DEFAULT_RANGE = np.random.default_rng()


class DynamicModel(ABC):
    """Abstract base class for dynamic models.
    
    Any dynamic model that implements an appropriate `simulate` method
    can be used for dynamic counterfactual analysis. 
    """


    def __init__(
        self,
        dim: int, 
        measurement_noise_std: Optional[np.ndarray] = None,
        sigma: Optional[Union[float, np.ndarray]] = None
    ):
        """Initializes a DynamicModel instance.

        Args:
            dim: The number of dimensions in the multivariate time series
                generated by the dynamic model.
            measurement_noise_std (ndarray): None, or a vector with shape (n,)
                where each entry corresponds to the standard deviation of the
                measurement noise for that particular dimension of the dynamic
                model. For example, if the dynamic model had two variables x1
                and x2 and `measurement_noise_std = [1, 10]`, then
                independent gaussian noise with standard deviation 1 and 10
                will be added to x1 and x2 respectively at each point in time.
            sigma (float or ndarray): The stochastic noise parameter. Can be a
                float, a 1D matrix or a 2D matrix. Dimension must match
                dimension of model.
        """
        self.dim = dim
        self.measurement_noise_std = measurement_noise_std
        self.sigma = self.build_stochastic_noise_matrix(sigma, dim)


    def simulate(
        self,
        t: np.ndarray,
        prior_states: np.ndarray,
        prior_t: Optional[np.ndarray] = None,
        intervention: Optional[Callable[[np.ndarray, float], np.ndarray]]= None,
        rng: np.random.mtrand.RandomState = DEFAULT_RANGE,
        **kwargs
    ) -> np.ndarray:
        """Runs a simulation of the dynamic model.

        Args:
            t (ndarray): A (n,) array of the time points where the   
                dynamic model will be simulated. The first entry of `t` must
                equal the last entry of `prior_t`. If `prior_t` is None, then
                the values of `prior_t` will be assumed to be evenly spaced time
                values ending with the first entry of `t`. If `t` does not
                contain evenly spaced time values, then the inference of
                `prior_t` will throw an error.
            prior_states (ndarray): A (m,) or (p, m) array of the initial
                condition or the prior states of the system.
            prior_t (ndarray): A time array with shape (p,) corresponding to the
                rows of `prior_states`. The last entry of `prior_t` must equal
                the first entry of `t`. If `prior_t` is None, then
                the values of `prior_t` will be assumed to be evenly spaced time
                values ending with the first entry of `t`. If `t` does not
                contain evenly spaced time values, then the inference of
                `prior_t` will throw an error.
            intervention (callable): A function that accepts (1) a vector of the
                current state of the dynamic model and (2) the current time. It should return a modified state. The function will be used in the
                following way. If the dynamic model without the intervention can be described 
                as
                
                x(t+dt) = F(x(t))
                
                where dt is the timestep size, x(t) is the trajectory, and F is
                the function that uses the current state to compute the state at
                the next timestep. Then the intervention function will be used
                to simulate the system

                    z(t+dt) = F(g(z(t), t), t)
                    x_do(t) = g(z(t), t)

                where x_do is the trajectory of the intervened system and g is 
                the intervention function.
            rng (RandomState): A numpy random state for reproducibility. (Uses 
                numpy's mtrand random number generator by default.)

        Returns:
            X (ndarray): An (n, m) array containing a realization of the   
                trajectory of the m dimensional system corresponding to the n
                times in `t`. The first row of X contains the last row of 
                `prior_states`.
        """
        # Must provide at least one unseen simulation time.
        if len(t) < 2:
            raise ValueError(f"len(t) = {len(t)} but at least two time points must be provided to simulate.")
        
        # Reshape prior_states to ensure they are 2D
        prior_states = np.reshape(prior_states, (-1, prior_states.shape[-1]))
        prior_obs, _ = prior_states.shape     

        if prior_t is not None:
            p_prior_t, = prior_t.shape

            if p_prior_t != prior_obs:
                raise ValueError(f"The length of `prior_t` ({p_prior_t}) must "
                    f"be equal to the number of rows ({prior_obs}) in prior_states. "
                )
            
            if not np.isclose(prior_t[-1], t[0]):
                raise ValueError(f"The last prior time, `prior_t[-1] "
                    f"= {prior_t[-1]}` must equal the first simulation time "
                    f"`t[0] = {t[0]}`."
                )
            
        else:
            # No prior times provided. We infer prior times.
            dt = t[1] - t[0]
            if not np.allclose(np.diff(t) - dt, 0.0):
                raise ValueError(
                    "Attempted to infer `prior_t` but `t` does not "
                    "have evenly spaced time points. Use evenly spaced `t` or "
                    "pass `prior_t` explicitly."
                )

            start_time = t[0]
            # Evenly spaced prior times ending at the start of t.
            prior_t = np.arange(-prior_obs + 1, 1) * dt + start_time

        return self._simulate(
            t, prior_states, prior_t, intervention, rng, **kwargs)
                

            
    

    def add_measurement_noise(
        self,
        X: np.ndarray,
        rng: np.random.mtrand.RandomState = DEFAULT_RANGE,
    ):
        """Adds independent gaussian noise to the array X.

        Only adds noise if self.measurement_noise_std is not None.

        Adds gaussian noise to each column. Equivalent to
            X[i, j] += normal() * stdevs[j]
        For all i and j.

        Args:
            X (ndarray): An (m, n) matrix that is interpreted to be a  
                realization of an n dimensional stochastic multivariate timeseries.
            measurement_noise_std (ndarray): An (n,) array that contains the
                standard deviations of the gaussian noise that will be added to
                each of the columns.
            rng: A numpy random state for reproducibility. (Uses numpy's mtrand 
                random number generator by default.)

        Returns:
            Xhat (ndarray): An (m, n) matrix that is equivalent to X + normally
                normally distributed noise.
        """
        if self.measurement_noise_std is None:
            return X
        
        return X + rng.standard_normal(X.shape) * self.measurement_noise_std
    

    def build_stochastic_noise_matrix(
        self,
        sigma: Union[float, np.ndarray],
        dim: int
    ) -> np.ndarray:
        """Helper function that creates a fixed noise rescaling matrix.

        If sigma is a float, returns a diagonal matrix with sigma on diagonal.
        If sigma is a 1D array, returns a diagonal matrix with diagonal equal to
        sigma. If sigma is a 2D array, checks dimension and returns sigma.

        Args:
            sigma (float or ndarray): The stochastic noise parameter. Can be a
                float, a 1D matrix or a 2D matrix. Dimension must match
                dimension of model.
            dim (int): The desired dimension of the noise matrix.

        Returns:
            A numpy array with shape (dim, dim).
        """
        # If sigma is a float, make a diagnonal matrix.
        if isinstance(sigma, (float, int)):
            return np.eye(dim) * sigma
        
        # If sigma is a 1D array, check dimension and put it on the diagonal.
        elif isinstance(sigma, np.ndarray) and len(sigma.shape) == 1:

            if sigma.shape[0] != dim:
                raise ValueError(
                    f"The stochastic noise parameter for {type(self).__name__} "
                    f"was the incorrect size: `sigma.shape = {sigma.shape}`. "
                    f"Pass a float or `sigma` with shape ({dim},) or "
                    "({dim}, {dim}).")
            
            return np.diag(sigma)
        
        elif isinstance(sigma, np.ndarray) and len(sigma.shape) == 2:
            if sigma.shape != (dim, dim):
                raise ValueError(
                    f"The stochastic noise parameter for {type(self).__name__} "
                    f"was the incorrect size: `sigma.shape = {sigma.shape}`. "
                    f"Pass a float or `sigma` with shape ({dim},) or "
                    "({dim}, {dim}).")
            return sigma
        
        if sigma is None:
            return np.zeros((dim, dim))
        else:
            raise ValueError(
                f"The stochastic noise parameter for {type(self).__name__}"
                " must be a float or a 1 or 2 dimensional numpy array."
            )
    

    @abstractmethod
    @copy_doc(simulate)
    def _simulate(
        self,
        t: np.ndarray,
        prior_states: np.ndarray,
        prior_t: Optional[np.ndarray] = None,
        intervention: Optional[Callable[[np.ndarray, float], np.ndarray]]= None,
        rng: np.random.mtrand.RandomState = DEFAULT_RANGE,
        **kwargs
    ) -> np.ndarray:
        raise NotImplementedError


class Intervention(ABC):
    """Abstract intervention class"""
    
    @abstractmethod
    def __call__():
        raise NotImplementedError
    

class ExogIntervention(Intervention):
    """A class describing an exogeneous intervention on a system.
    
    In an exogeneous intervention, some of the signals are treated as
    though they were under exogenous control.

    This class must contain the indexes of the signals that are being
    controled exogenously and must also contain a mechanism for computing
    the intervened signal from the non intervened signal. (i.e. replacing
    values with the exogenous values.)
    """
    def __init__(self, iv_idxs: List[int]):
        self.iv_idxs = iv_idxs
    
    def split_exog(self, X: np.ndarray):
        """Splits exogeneous columns from endogenous.

        Args:
            X (ndarray, dimension (m, n)): An array where rows are observations
                and columns are variables.
        """
        if len(X.shape) != 2:
            raise ValueError(
                f"Array must be two dimensional.\n\tX.shape = {X.shape}"
            )
        
        _, n = X.shape
        X_idxs = np.arange(n + 1)

        if not set(self.iv_idxs).issubset(X_idxs):
            raise ValueError((
                "Some intervention indexes are too big for input array:"
                f"\n\t Intervention indexes = {self.iv_idxs}"
                f"\n\t Input array shape = {X.shape}"
            ))

        if self.iv_idxs:
            exog_X = X[..., self.iv_idxs]
            endo_X = np.delete(X, self.iv_idxs, axis=-1)

            # Check for empty arrays.
            if endo_X.shape[1] == 0:
                endo_X = None

            if exog_X.shape[1] == 0:
                exog_X = None
                
            return endo_X, exog_X
        
        else:
            return X, None
    

    def combine_exog(self, endo_X: np.ndarray, exog_X: np.ndarray):
        """Recombines endogenous and endogenous signals.
        
        Args:
            endo_X (ndarray): A 2D array of endogenous signals with shape 
                (m, n_endo). Rows are observations and columns are variables.
            exog_X (ndarray): A 2D array of exogenous signals with shape 
                (m, n_exog). Rows are observations and columns are variables.
        """
        if (endo_X is None) and (exog_X is None):
            raise ValueError("Both endo_X and exog_X are None.")
    
        if exog_X is None:
            if self.iv_idxs:
                raise ValueError(
                    "Exogenous states was None but intervention expects "
                    "exogenous states."
                )
            return endo_X
        
        elif not self.iv_idxs:
                raise ValueError(
                    "Exogenous states provided but intervention does not expect"
                    " exogenous states"
                )
        
        if endo_X is None:
            max_idx = max(self.iv_idxs)
            all_idx = np.arange(max_idx + 1)
            extra_idx = set(self.iv_idxs).symmetric_difference(all_idx)
            if extra_idx:
                raise ValueError(
                    "Endogenous states was None but intervention expects "
                    "endogenous states."
                )
            return exog_X
        
        m_endo, n_endo = endo_X.shape
        m_exog, n_exog = exog_X.shape

        if m_exog != m_endo:
            raise ValueError(
                "Endogenous and exogenous arrays must have the same number of "
                f"rows. \nNum endog rows = {m_endo} Num exog rows = {m_endo}"
            )
        
        if n_exog != len(self.iv_idxs):
            raise ValueError(
                "Wrong number of exogenous signals passed to intervention. "
                f"Expected {len(self.iv_idxs)} received {m_exog}.")
        
        n = n_endo + n_exog
        X = np.zeros((m_endo, n))
        X[:, self.iv_idxs] = exog_X
        endo_idxs = [i for i in range(n) if i not in self.iv_idxs]
        X[:, endo_idxs] = endo_X
        return X
    

    def eval_at_times(self, t: np.ndarray):
        """Produces exogeneous signals only at the time values in t.

        Args:
            t (np.ndarray): A 1D array of time points

        Returns:
            exog_X_do (np.ndarray): An (m, ) or (m, p) array where `m = len(t)` 
                and `p = len(self.intervened_idx)`. Contains the values of the
                exogenous signal at the time points in `t`. The order of the
                columns corresponds to the order of indexes in 
                `self.intervened_idx`.
        """
        if len(self.iv_idxs) == 0:
            return None

        # Exogeneous interventions do not depend on x so we can use a dummy var.
        dummy_x = np.zeros(np.max(self.iv_idxs) + 1)

        # The size of the dummy variable only needs to be as big as the max
        # intervened index and self.split_exog will still work.
        # This is done to avoid the need for an additional argument containing
        # the dimension of the system.

        # Apply intervention to all dummy states.
        X_do = np.vstack([
            self.__call__(dummy_x, ti) for ti in t
        ])

        # Use split_exog to return only exogenous states.
        _, exog_X_do = self.split_exog(X_do)
        return exog_X_do

    def __call__(self, x: np.ndarray, t: float):
        """A perfect intervention on multiple variables.

        Args:
            x (ndarray): In the context of this package, x represents
                the current state of a dynamic model.
            t: (ndarray): In the context of this package, t represents
                the current time in a dynamic model.
        
        Returns:
            x_do (ndarray): In the context of this package, x_do represents
                the state of the dynamic model after the intervention is applied.
        """
        raise NotImplementedError()


class ForecastMethod(BaseEstimator):
    """Base class for interfere inference methods."""

    # Class attribute to determine if the method was fit to data.
    is_fit = False


    def simulate(
        self,
        t: np.ndarray,
        prior_states: np.ndarray,
        prior_t: Optional[np.ndarray] = None,
        intervention:  Optional[ExogIntervention] = None,
        rng: np.random.mtrand.RandomState = DEFAULT_RANGE
    ) -> np.ndarray:
        """Simulates a the intervention response with a fitted method.

        Args:
            t: A (m,) array of times to simulate.
            prior_states: A (p, n + k) array of endogenous and exogenous
                signals. Rows are observations corresponding to
                `t` and columns are variables. The k exogenous
                variable indexes are contained in `intervention.iv_idxs`
            intervention: An interfere.ExogIntervention.
            prior_t: Optional (p,) array of times corresponding to
                historic observations. Defaults to equally spaced points
                immediately prior to `t`. Assumes that the last
                row of `prior_states` corresponds to the initial condition,
                the state of the system at time `t = t[0]`.
            rng: Numpy random state.

        Returns:
            simulated_states: A (m, n + k) array of simulated exogenous and
                endogenous signals. The k exogenous variable indexes are
                contained in `intervention.iv_idxs`.
        """
        if intervention is not None:
            (prior_endog_states, 
             prior_exog_states) = intervention.split_exog(prior_states)
            prediction_exog = intervention.eval_at_times(t)

        else:
            prior_endog_states = prior_states
            prior_exog_states = None
            prediction_exog = None

        endo_pred = self.predict(
            t,
            prior_endog_states,
            prior_exog_states=prior_exog_states,
            prior_t=prior_t,
            prediction_exog=prediction_exog,
            rng=rng
        )

        simulated_states = endo_pred

        # Optionally intervention to combine exogeneous and endogenous.
        if intervention is not None:
            simulated_states = intervention.combine_exog(
                endo_pred, prediction_exog)
    
        return simulated_states


    def fit(
        self,
        t: np.ndarray,
        endog_states: np.ndarray,
        exog_states: np.ndarray = None,
    ):
        """Fits the method using the passed data.
        
        Args:
            t: An (m,) array of time points.
            endog_states: An (m, n) array of endogenous signals. Rows are observations and columns are variables. Each
                row corresponds to the times in `t`.
            exog_states: An (m, k) array of exogenous signals. Rows are
                observations and columns are variables. Each row corresponds to
                the times in `t`.
        """
        if len(t.shape) != 1:
            raise ValueError(
                f"The `t` arg to {str(type(self).__name__)}.fit() is not 1D.")
        
        if len(endog_states.shape) != 2:
            raise ValueError(
                f"The `endog_states` arg to {str(type(self).__name__)}.fit() is"
                " not 2D"
            )
        
        m, = t.shape
        m_endog, endog_dim = endog_states.shape
        exog_dim = None

        if m != m_endog:
            raise ValueError(
                f"The arguments `t` and `endog_states` for "
                f"{str(type(self).__name__)}.fit() have incompatible shapes: \n"
                f"\tt.shape = {t.shape}\n"
                f"\tendog_states.shape = {endog_states.shape}"
            )
        
        if exog_states is not None:
            if len(exog_states.shape) != 2:
                raise ValueError(
                    f"The `exog_states` arg to {str(type(self).__name__)}.fit() is"
                    " not 2D"
                )
        
            m_exog, exog_dim = exog_states.shape
            if m != m_exog:

                raise ValueError(
                    f"The arguments `t` and `exog_states` for "
                    f"{str(type(self).__name__)}.fit() have incompatible "
                    "shapes: \n"
                    f"t.shape = {t.shape}\n"
                    f"exog_states.shape = {exog_states.shape}"
                )

        
        # Make sure no Pandas DataFrames are passed in.
        if any([
            isinstance(x, pd.DataFrame) 
            for x in [endog_states, t, exog_states]
        ]):
            raise ValueError("Interfere inference methods do not accept " "DataFrames. Use DataFrame.values and DataFrame.index")
        
        # Make sure time points are monotonic.
        if np.any(np.diff(t) <= 0):
            raise ValueError(
                f"Time points passed to {str(type(self).__name__)}.fit must be "
                "strictly increasing."
            )
        
        self.timestep_of_fit = None
        self.endog_dim_of_fit = endog_dim
        self.exog_dim_of_fit = exog_dim

        # Store timestep size if time points are evenly spaced.
        dt = t[1] - t[0]
        if np.allclose(np.diff(t), dt):
            self.timestep_of_fit = dt

        self._fit(t, endog_states, exog_states)
        self.is_fit = True
        return self
    

    def predict(
        self,
        t: np.ndarray,
        prior_endog_states: np.ndarray,
        prior_exog_states: Optional[np.ndarray] = None,
        prior_t: Optional[np.ndarray] = None,
        prediction_exog: Optional[np.ndarray] = None,
        prediction_max: float = 1e9,
        rng: np.random.RandomState = DEFAULT_RANGE,
    ) -> np.ndarray:
        """Runs a simulation of the dynamics of a fitted forcasting method.

       Note: Must call `self.fit(...)` before calling `self.predict`.

        Args:
            t (ndarray): An array of the time points with shape (m,) for the
                method to simulate.
            prior_endog_states (ndarray): Aa array of historic observations of
                the n ENDOGENOUS signals with shape  (p, n). Rows represent 
                observations and columns represent variables This is used as the
                initial condition data or lagged initial conditions. It is NOT
                used to fit the method. If `prior_t` is not provided and
                `t` contains equally spaced points, the `prior_endog_states` are
                assumed to  have occured at equally spaced points prior to `t`.
                Additionally, the last row of `prior_endog_states` must
                be an observation that  occured at the time `t[0]`. When
                `prior_t` is provided it is assumed that the rows of
                `prior_endog_states` were observed at the times contained in
                `prior_t`.
            prior_exog_states: An optional array of historic observations of the
                k EXOGENOUS signals with shape (p, k). Rows contain observations
                and columns contain variables. This is used for the
                initial condition data and lag information. It is NOT used to
                fit the method. If `prior_t` is not provided and
                `t` contains equally spaced points, the `prior_exog_states` are
                assumed to  have occured at equally spaced points prior to `t`.
                Additionally, the last row of `prior_enxog_states` must
                be an observation that  occured at the time `t[0]`. When `prior_t` is provided it is assumed
                that the rows of `prior_endog_states` were observed at the times
                contained in `prior_t`.
            prior_t (ndarray): An optional array with shape (p,) of times
                corresponding to the rows of `prior_endog_states` and `prior_exog_states`. If `prior_t` is not provided and `t`
                contains equally spaced points, then `prior_t` is assumed
                to contain occured at equally spaced points prior to `t`
            prediction_exog: An optional (m, k) array of exogenous signals
                corresponding to the times in `t`. Rows are observations and
                columns are variables.
            prediction_max: A threshold for predicted endogeneous values
                to prevent overflow in predictions. All predictions larger in
                magnitude will be set equal to `prediction_max`.
            rng: An optional numpy random state for reproducibility. (Uses 
                numpy's mtrand random number generator by default.)

        Returns:
            X_sim: A (m, n) array of containing a multivariate time series. The
            rows are observations correstponding to entries in `time_points` and
            the columns correspod to the endogenous variables in the forecasting
            method. 
        """
        if not self.is_fit:
            raise ValueError("Call self.fit(...) before self.predict(...).")
        
        if len(t.shape) != 1:
            raise ValueError(
                f"The `t` arg to {str(type(self).__name__)}.predict is not 1D.")
                
        if any([
            isinstance(x, pd.DataFrame) 
            for x in [t, prior_endog_states, prior_exog_states, prior_t, prediction_exog]
        ]):
            raise ValueError(
                "Interfere inference methods do not accept "
                "DataFrames. Use DataFrame.values and DataFrame.index"
            )
        
        # Make sure time points are monotonic.
        if np.any(np.diff(t) <= 0):
            raise ValueError(
                f"Time points passed to the {str(type(self).__name__)}.predict "
                "`t` argument must be strictly increasing."
            )
        
        if np.any(prior_endog_states > prediction_max):
            raise ValueError(
                f"Historic endogenous contains values "
                "({np.max(prior_endog_states)}"
                " that are larger than" 
                f" `prediction_max = {prediction_max}`, the "
                "prediction threshold."
                "Increase `prediction_max` in order to simulate these values."
            )
        
        # Reshape prior_endog_states if it was 1D.
        if len(prior_endog_states.shape) == 1:
            prior_endog_states = np.reshape(prior_endog_states, (1, -1))

        # Gather array shapes
        orig_num_prior_endog, k = prior_endog_states.shape
        (m,) = t.shape 

        if len(t) < 2:
            raise ValueError(
                f" For {str(type(self).__name__)}.predict, the first timestep "
                "in `t` is assumed to be the current time, and correspond to "
                "the last row "
                "of `prior_endog_states`, the `t` argument must have at least "
                "two time values."
            )
        
        if self.exog_dim_of_fit is not None and prediction_exog is None:
            raise ValueError(
                f"{type(self).__name__} was fit to exogenous data but no "
                "exogenous signals were provided to predict().")

        # Check shape of exogenous signals.
        if prediction_exog is not None:
            m_exog, k_exog = prediction_exog.shape
            if m_exog != m:
                raise ValueError(f"Number of exogenous observations ({m_exog})"
                f" does not match the number of t ({m}).")

        # Compare window size of forecaster with amount of historic data.
        window_size = self.get_window_size()

        if window_size > orig_num_prior_endog:
            warn(str(type(self).__name__) + f" has window size {window_size} but only recieved {orig_num_prior_endog}"
                 " endog observations. Augmenting historic edogenous "
                 "observations with zeros."
            )

            prior_endog_states = np.vstack([
                np.zeros((window_size - orig_num_prior_endog, k)),
                prior_endog_states
            ])
            
        # Check shape of historic exogenous signals.
        if prior_exog_states is not None:
            p_hexog, k_hexog = prior_exog_states.shape

            if p_hexog != orig_num_prior_endog:
                raise ValueError("Arguments `prior_endog_states` and "
                "`prior_exog_states` must have the same number of rows.")
            
            if prediction_exog is not None:
                if k_hexog != k_exog:
                    raise ValueError("The `prior_exog_states` and `exog` arguments"
                    " must have the same number of columns.")
                
            if window_size > p_hexog:
                warn(str(type(self).__name__) + f" has window size {window_size} but only recieved"
                     f" {p_hexog} exog observations. Augmenting historic "
                     "exogenous observations with zeros.")

                prior_exog_states = np.vstack([
                    np.zeros((window_size - p_hexog, k_hexog)),
                    prior_exog_states
                ])

        # Create prior_t assuming equal time step size.
        num_prior_endog, _ = prior_endog_states.shape

        if prior_t is None:
            dt = t[1] - t[0]

            # Check for equally spaced forecast time points.
            if not np.all(np.isclose(np.diff(t), dt)):
                raise ValueError("The `prior_t` argument not provided"
                " AND `t` is not equally spaced. Cannot infer "
                " `prior_t`. Either pass it explicitly or provide "
                " equally spaced time `t`.")
            prior_t = np.arange(-num_prior_endog + 1, 1) * dt + t[0]

        if not np.isclose(prior_t[-1], t[0]):
            raise ValueError(
                f"For {str(type(self).__name__)}.predict, the last prior time, "
                f"prior_t[-1]={prior_t[-1]} must equal the first simulation "
                f"time t[0]={t[0]}."
            )

        num_prior_times, = prior_t.shape

        # If the user provided prior_t and it is greater or equal to
        # num_prior_endog, then we trim it to size.
        if num_prior_times > num_prior_endog:
            warn(f"{str(type(self).__name__)}.predict was passed too many "
                 f"({num_prior_times}) prior time points. Using only the last "
                 f"{num_prior_endog} time points.")
            prior_t = prior_t[-num_prior_endog:]

        # If the user did not pass enough prior_t, check for equally spaced time
        # points and infer.
        if num_prior_times < num_prior_endog:

            # Check if equally spaced.
            warn(
                "Inferring additional `prior_t` values. Assuming `prior_t` has"
                " the same equally spaced timestep size as `t`"
            )
            dt = t[1] - t[0]
            if not np.all(np.isclose(np.diff(prior_t), dt)):

                # When prior_endog_states were not augmented with zeros raise a
                # normal value error. 
                if num_prior_endog == orig_num_prior_endog:
                    raise ValueError(
                        f"{str(type(self).__name__)}.predict was passed {orig_num_prior_endog} "
                        "prior_endog_states but there are only "
                        f"{num_prior_times} entries in `prior_t`."
                    )
                
                # When prior_endog_states were augmented with zeros, give
                # instructions on how to augment.
                if num_prior_endog > orig_num_prior_endog:
                    raise ValueError(
                        f"{str(type(self).__name__)}.predict augmented "
                        "`prior_endog_states` with zeros but `prior_t` was not "
                        "equally spaced so it was not possible to infer "
                        "additional prior times. \n\nTo solve, pass at least "
                        f"({num_prior_endog}) previous time values or use "
                        "equally spaced `prior_t`."
                    )
            extra_prior_t = np.arange(
                num_prior_times - num_prior_endog, 0) * dt + prior_t[0]
            prior_t = np.hstack([extra_prior_t, prior_t])

        if np.any(np.diff(prior_t) <= 0):
            raise ValueError(
                f"Prior time points passed to {str(type(self).__name__)}."
                "predict must be strictly increasing."
            )        

        endog_pred = self._predict(
            t=t,
            prior_endog_states=prior_endog_states,
            prior_exog_states=prior_exog_states,
            prior_t=prior_t,
            prediction_exog=prediction_exog,
            rng=rng
        )

        # Clip predictions at the max prediction.
        endog_pred[np.abs(endog_pred) > prediction_max] = prediction_max

        return endog_pred
    

    def get_window_size(self) -> int:
        """Returns number of previous observations model requires in order to
        make a prediction.
        
        For example, an autoregressive model with four lags needs the four
        previous timesteps in order to make a prediction, but an ODE only needs
        the current observed state.

        This function only exists to maintain flexible compatibility with the
        hyper parameter optimizer. However, at least two
        previous observations are needed in order for the hyper parameter
        optimizer to determine the timestep size. If no previous observations
        are known, simply pad with zeros and supply the appropriate times.

        Because at least two are needed, the default behavior is to require two
        previous observations.
        
        If your model needs more previous observations, overwrite this function.
        The optimizer calls this function after initialization, so the number of
        previous observations needed can depend on interal attributes:

        E.x.
            `return max(self.lags)`
        """
        return 2


    @abstractmethod
    def _fit(
        self,
        t: np.ndarray,
        endog_states: np.ndarray,
        exog_states: np.ndarray = None,
    ):
        """Fits the method using the passed data.
        
        Args:
            t (ndarray): An array of time points with shape (m,).
            endog_states (ndarray): An array of endogenous signals with shape
                (m, n). Rows are  observations and columns are variables. Each
                row corresponds to the times in `t`.
            exog_states (ndarray): An array of exogenous signals with shape  
                (m, k). Rows are observations and columns are variables. Each
                row corresponds to the times in `t`.
        """
        raise NotImplementedError()
    

    @abstractmethod
    def _predict(
        self,
        t: np.ndarray,
        prior_endog_states: np.ndarray,
        prior_exog_states: Optional[np.ndarray] = None,
        prior_t: Optional[np.ndarray] = None,
        prediction_exog: Optional[np.ndarray] = None,
        rng: np.random.RandomState = DEFAULT_RANGE,
    ) -> np.ndarray:
        """Runs a simulation of the dynamics of a fitted forcasting method.

       Note: Must call `self.fit(...)` before calling `self.predict`.

        Args:
            t (ndarray): An array of the time points with shape (m,) for the
                method to simulate.
            prior_endog_states (ndarray): Aa array of historic observations of
                the n endogeneous signals with shape (p, n). Rows represent 
                observations and columns represent variables This is used as the
                initial condition data or time lag information. It is not
                used to fit the method. IMPORTANT: It is assumed that the last
                row in this array was observed at time `t[0]`.
            prior_exog_states: An optional array of historic observations of the
                k exogenous signals with shape (p, k). Rows contain observations
                and columns contain variables. This is used for the
                initial condition data and lag information. It is NOT used to
                fit the method. IMPORTANT: It is assumed that the last
                row in this array was observed at time `t[0]`.
            prior_t (ndarray): An optional array with shape (p,) of times
                corresponding to the rows of `prior_endog_states` and `prior_exog_states`. If `prior_t` is not provided and `t`
                contains equally spaced points, then `prior_t` is assumed
                to contain occured at equally spaced points prior to `t`
            prediction_exog: An optional (m, k) array of exogenous signals
                corresponding to the times in `t`. Rows are observations and
                columns are variables.
            prediction_max: A threshold for predicted endogeneous values
                to prevent overflow in predictions. All predictions larger in
                magnitude will be set equal to `prediction_max`.
            rng: An optional numpy random state for reproducibility. (Uses 
                numpy's mtrand random number generator by default.)

        Returns:
            X_sim: A (m, n) array of containing a multivariate time series. The
            rows are observations correstponding to entries in `time_points` and
            the columns correspod to the endogenous variables in the forecasting
            method.
            
        Notes:
            When `prior_t` is provided it is assumed that the rows of
            `prior_endog_states` and `prior_exog_states` were observed at the
            times contained in `prior_t`.If `prior_t` is not provided and `t`
            contains equally spaced points, then `prior_endog_states` and
            `prior_exog_states` are assumed to have occured at equally spaced
            times before `t[0]`. Additionally, the last rows of
            `prior_endog_states` and `prior_exog_states` must be an observation
            that  occured at the time `t[0]`.
        """
        raise NotImplementedError()
    
    @staticmethod
    @abstractmethod
    def get_test_params() -> Dict[str, Any]:
        """Returns initialization parameters for testing. 
        
        Should be condusive to fast test cases."""
        raise NotImplementedError
    
    
    @staticmethod
    @abstractmethod
    def _get_optuna_params(trial, max_lags=None, max_horizon=None, **kwargs) -> Dict[str, Any]:
        """Define hyperparameter search space for this forecasting method using Optuna.
        
        This method is used by the hyperparameter optimization framework to determine
        which parameters to tune for the forecasting method. It should return a dictionary 
        mapping parameter names to Optuna parameter suggestions.
        
        Args:
            trial: An Optuna trial object that provides methods for hyperparameter suggestions
                such as suggest_float, suggest_int, suggest_categorical.
            max_lags: Maximum number of lag periods (previous observations) that can be 
                    considered. This is typically determined by the cross-validation 
                    framework based on the available data. For autoregressive methods,
                    this constrains how many past observations can be used.
            max_horizon: Maximum prediction horizon (future steps) that can be forecasted.
                        This is typically determined by the cross-validation framework
                        and constrains how far into the future the method should predict.
            **kwargs: Additional keyword arguments that may be passed by the hyperparameter
                    optimization framework. Subclasses can accept additional parameters
                    specific to their implementation needs.
        
        Returns:
            Dict[str, Any]: A dictionary mapping parameter names to their values,
                            which will be passed to the forecasting method's __init__
                            method during hyperparameter optimization.
        
        Example:
            ```python
            @staticmethod
            def _get_optuna_params(trial, max_lags=20, **kwargs):
                return {
                    "lag": trial.suggest_int("lag", 1, max_lags),
                    "alpha": trial.suggest_float("alpha", 0.01, 1.0),
                    "regularization": trial.suggest_categorical(
                        "regularization", ["l1", "l2", "elasticnet"])
                }
            ```
        """
        raise NotImplementedError()