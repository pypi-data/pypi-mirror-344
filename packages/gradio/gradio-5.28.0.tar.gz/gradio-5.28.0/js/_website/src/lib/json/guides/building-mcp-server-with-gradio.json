{"guide": {"name": "building-mcp-server-with-gradio", "category": "other-tutorials", "pretty_category": "Other Tutorials", "guide_index": null, "absolute_index": 66, "pretty_name": "Building Mcp Server With Gradio", "content": "# Building an MCP Server with Gradio\n\n\n\nIn this guide, we will describe how to launch your Gradio app so that it functions as an MCP Server.\n\nPunchline: it's as simple as setting `mcp_server=True` in `.launch()`. \n\n### Prerequisites\n\nIf not already installed, please install Gradio with the MCP extra:\n\n```bash\npip install gradio[mcp]\n```\n\nThis will install the necessary dependencies, including the `mcp` package. Also, you will need a LLM application that supports tool calling using the MCP protocol, such as Claude Desktop, Cursor, or Cline (these are known as \"MCP Clients\").\n\n## What is an MCP Server?\n\nAn MCP (Model Control Protocol) server is a standardized way to expose tools so that they can be used by  LLMs. A tool can provide an LLM functionality that it does not have natively, such as the ability to generate images or calculate the prime factors of a number. \n\n## Example: Counting Letters in a Word\n\nLLMs are famously not great at counting the number of letters in a word (e.g. the number of \"r\"-s in \"strawberry\"). But what if we equip them with a tool to help? Let's start by writing a simple Gradio app that counts the number of letters in a word or phrase:\n\n```python\nimport gradio as gr\n\ndef letter_counter(word, letter):\n    \"\"\"\n    Count the number of occurrences of a letter in a word or text.\n\n    Args:\n        word (str): The input text to search through\n        letter (str): The letter to search for\n\n    Returns:\n        str: A message indicating how many times the letter appears\n    \"\"\"\n    word = word.lower()\n    letter = letter.lower()\n    count = word.count(letter)\n    return count\n\ndemo = gr.Interface(\n    fn=letter_counter,\n    inputs=[\"textbox\", \"textbox\"],\n    outputs=\"number\",\n    title=\"Letter Counter\",\n    description=\"Enter text and a letter to count how many times the letter appears in the text.\"\n)\n\nif __name__ == \"__main__\":\n    demo.launch(mcp_server=True)\n\n```\n\nNotice that we have set `mcp_server=True` in `.launch()`. This is all that's needed for your Gradio app to serve as an MCP server! Now, when you run this app, it will:\n\n1. Start the regular Gradio web interface\n2. Start the MCP server\n3. Print the MCP server URL in the console\n\nThe MCP server will be accessible at:\n```\nhttp://your-server:port/gradio_api/mcp/sse\n```\n\nGradio automatically converts the `letter_counter` function into an MCP tool that can be used by LLMs. The docstring of the function of the function will be used to generate the description of the tool and its parameters. \n\nAll you need to do is add this URL endpoint to your MCP Client (e.g. Claude Desktop, Cursor, or Cline), which typically means pasting this config in the settings:\n\n```\n{\n  \"mcpServers\": {\n    \"gradio\": {\n      \"url\": \"http://your-server:port/gradio_api/mcp/sse\"\n    }\n  }\n}\n```\n\n(By the way, you can find the exact config to copy-paste by going to the \"View API\" link in the footer of your Gradio app, and then clicking on \"MCP\").\n\n## Key features of the Gradio <> MCP Integration\n\n1. **Tool Conversion**: Each API endpoint in your Gradio app is automatically converted into an MCP tool with a corresponding name, description, and input schema. To view the tools and schemas, visit http://your-server:port/gradio_api/mcp/schema or go to the \"View API\" link in the footer of your Gradio app, and then click on \"MCP\".\n\n\n2. **Environment variable support**. There are two ways to enable the MCP server functionality:\n\n*  Using the `mcp_server` parameter, as shown above:\n   ```python\n   demo.launch(mcp_server=True)\n   ```\n\n* Using environment variables:\n   ```bash\n   export GRADIO_MCP_SERVER=True\n   ```\n\n3. **File Handling**: The server automatically handles file data conversions, including:\n   - Converting base64-encoded strings to file data\n   - Processing image files and returning them in the correct format\n   - Managing temporary file storage\n\n    It is **strongly** recommended that input images and files be passed as full URLs (\"http://...\" or \"https:/...\") as MCP Clients do not always handle local files correctly.\n\n\n4. **Hosted MCP Servers on \udb40\udc20\ud83e\udd17 Spaces**: You can publish your Gradio application for free on Hugging Face Spaces, which will allow you to have a free hosted MCP server. Here's an example of such a Space: https://huggingface.co/spaces/abidlabs/mcp-tools. Notice that you can add this config to your MCP Client to start using the tools from this Space immediately:\n\n```\n{\n  \"mcpServers\": {\n    \"gradio\": {\n      \"url\": \"https://abidlabs-mcp-tools.hf.space/gradio_api/mcp/sse\"\n    }\n  }\n}\n```\n\n<video src=\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/gradio-guides/mcp_guide1.mp4\" style=\"width:100%\" controls preload> </video>\n\n\n## Custom MCP Servers\n\nFor a more fine-grained control, you might want to manually create an MCP Server that interfaces with hosted Gradio apps. This approach is useful when you want to:\n\n- Choose specific endpoints within a larger Gradio app to serve as tools\n- Customize how your tools are presented to LLMs (e.g. change the schema or description)\n- Start the Gradio app MCP server when a tool is called (if you are running multiple Gradio apps locally and want to save memory / GPU)\n- Use a different MCP protocol than SSE\n\nThis is very doable thanks to the [Gradio Python Client](https://www.gradio.app/guides/getting-started-with-the-python-client) and the [MCP Python SDK](https://github.com/modelcontextprotocol/python-sdk). Here's an example of creating a custom MCP server that connects to various Gradio apps hosted on [HuggingFace Spaces](https://huggingface.co/spaces) using the `stdio` protocol:\n\n```python\nfrom mcp.server.fastmcp import FastMCP\nfrom gradio_client import Client\nimport sys\nimport io\nimport json \n\n# Initialize FastMCP server\nmcp = FastMCP(\"gradio-spaces\")\n\n# Dictionary to store Gradio clients\nclients = {}\n\ndef get_client(space_id: str) -> Client:\n    \"\"\"Get or create a Gradio client for the specified space.\"\"\"\n    if space_id not in clients:\n        clients[space_id] = Client(space_id)\n    return clients[space_id]\n\n\n@mcp.tool()\nasync def generate_image(prompt: str, space_id: str = \"ysharma/SanaSprint\") -> str:\n    \"\"\"Generate an image using Flux.\n    \n    Args:\n        prompt: Text prompt describing the image to generate\n        space_id: HuggingFace Space ID to use \n    \"\"\"\n    client = get_client(space_id)\n    result = client.predict(\n            prompt=prompt,\n            model_size=\"1.6B\",\n            seed=0,\n            randomize_seed=True,\n            width=1024,\n            height=1024,\n            guidance_scale=4.5,\n            num_inference_steps=2,\n            api_name=\"/infer\"\n    )\n    return result\n\n\n@mcp.tool()\nasync def run_dia_tts(prompt: str, space_id: str = \"ysharma/Dia-1.6B\") -> str:\n    \"\"\"Text-to-Speech Synthesis.\n    \n    Args:\n        prompt: Text prompt describing the conversation between speakers S1, S2\n        space_id: HuggingFace Space ID to use \n    \"\"\"\n    client = get_client(space_id)\n    result = client.predict(\n            text_input=f\"\"\"{prompt}\"\"\",\n            audio_prompt_input=None, \n            max_new_tokens=3072,\n            cfg_scale=3,\n            temperature=1.3,\n            top_p=0.95,\n            cfg_filter_top_k=30,\n            speed_factor=0.94,\n            api_name=\"/generate_audio\"\n    )\n    return result\n\n\nif __name__ == \"__main__\":\n    # Ensure stdout uses UTF-8 encoding\n    import sys\n    import io\n    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')\n    \n    # Initialize and run the server\n    mcp.run(transport='stdio')\n\n```\n\nThis server exposes two tools:\n1. `run_dia_tts` - Generates a conversation for the given transcript in the form of `[S1]first-sentence. [S2]second-sentence. [S1]...`\n2. `generate_image` - Generates images using a fast text-to-image model\n\nTo use this MCP Server with Claude Desktop (as MCP Client):\n\n1. Save the code to a file (e.g., `gradio_mcp_server.py`)\n2. Install the required dependencies: `pip install mcp gradio-client`\n3. Configure Claude Desktop to use your server by editing the configuration file at `~/Library/Application Support/Claude/claude_desktop_config.json` (macOS) or `%APPDATA%\\Claude\\claude_desktop_config.json` (Windows):\n\n```json\n{\n    \"mcpServers\": {\n        \"gradio-spaces\": {\n            \"command\": \"python\",\n            \"args\": [\n                \"/absolute/path/to/gradio_mcp_server.py\"\n            ]\n        }\n    }\n}\n```\n\n4. Restart Claude Desktop\n\nNow, when you ask Claude about generating an image or transcribing audio, it can use your Gradio-powered tools to accomplish these tasks.\n\n\n", "tags": ["MCP", "TOOL", "LLM", "SERVER"], "spaces": [], "url": "/guides/building-mcp-server-with-gradio/", "contributor": null}}