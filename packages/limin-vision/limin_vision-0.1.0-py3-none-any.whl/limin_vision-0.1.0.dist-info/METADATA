Metadata-Version: 2.4
Name: limin-vision
Version: 0.1.0
Summary: A Python library for working with vision models.
Author-email: Titanom Solutions <infrastructure@titanom.com>
Requires-Python: >=3.10
Description-Content-Type: text/markdown
Requires-Dist: limin==0.7.1

# limin-vision

A Python library for working with vision models.

## Installation

Install the library using pip:

```bash
pip install limin-vision
```

## Usage

After you've installed the library, you can use it by importing the `limin_vision` module and calling the functions you need.
You will also need to provide an API key for your API either by running `export OPENAI_API_KEY=$YOUR_API_KEY` or by creating an `.env` file in the root directory of your project and adding the following line:

```
OPENAI_API_KEY=$YOUR_API_KEY
```

Here is an example of how to use the library:

```python
import asyncio
from limin_vision import process_image_from_url

async def main():
    url = "https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg"
    result = await process_image_from_url(url)
    print(result)

if __name__ == "__main__":
    asyncio.run(main())
```

You can pass additional parameters to the `process_image_from_url` function to customize the model configuration and prompt:

```python
await process_image_from_url(
    url,
    model_configuration=ModelConfiguration(
        model="gpt-4o",
        temperature=1.0
    ),
    prompt="What's in this image?",
    detail="high",
)
```

You can find the full example in [`examples/process_from_url.py`](examples/process_from_url.py).

Alternatively, you can process an image from a local file by calling `process_image_from_file` instead of `process_image_from_url`.

```python
from limin_vision import process_image_from_file

async def main():
    result = await process_image_from_file("image.png")
    print(result)

if __name__ == "__main__":
    asyncio.run(main())
```

Just like with `process_image_from_url`, you can pass additional parameters to the `process_image_from_file` function to customize the model configuration and prompt:

```python
await process_image_from_file(
    "image.png",
    model_configuration=ModelConfiguration(
        model="gpt-4o",
        temperature=1.0
    ),
    prompt="What's in this image?",
    detail="high",
)
```

You can find the full example in [`examples/process_from_file.py`](examples/process_from_file.py).
