[
  {
    "moduleName": "default",
    "title": "Basics",
    "type": "image",
    "templates": [
      {
        "name": "default",
        "title": "Image Generation",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Generate images from text descriptions."
      },
      {
        "name": "image2image",
        "title": "Image to Image",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Transform existing images using text prompts.",
        "tutorialUrl": "https://comfyanonymous.github.io/ComfyUI_examples/img2img/"
      },
      {
        "name": "lora",
        "title": "Lora",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Apply LoRA models for specialized styles or subjects.",
        "tutorialUrl": "https://comfyanonymous.github.io/ComfyUI_examples/lora/"
      },
      {
        "name": "inpaint_example",
        "title": "Inpaint",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Edit specific parts of images seamlessly.",
        "thumbnailVariant": "compareSlider",
        "tutorialUrl": "https://comfyanonymous.github.io/ComfyUI_examples/inpaint/"
      },
      {
        "name": "inpain_model_outpainting",
        "title": "Outpaint",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Extend images beyond their original boundaries.",
        "thumbnailVariant": "compareSlider",
        "tutorialUrl": "https://comfyanonymous.github.io/ComfyUI_examples/inpaint/#outpainting"
      },
      {
        "name": "embedding_example",
        "title": "Embedding",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Use textual inversion for consistent styles.",
        "tutorialUrl": "https://comfyanonymous.github.io/ComfyUI_examples/textual_inversion_embeddings/"
      },
      {
        "name": "gligen_textbox_example",
        "title": "Gligen Textbox",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Specify the location and size of objects.",
        "tutorialUrl": "https://comfyanonymous.github.io/ComfyUI_examples/gligen/"
      },
      {
        "name": "lora_multiple",
        "title": "Lora Multiple",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Combine multiple LoRA models for unique results.",
        "tutorialUrl": "https://comfyanonymous.github.io/ComfyUI_examples/lora/"
      }
    ]
  },
  {
    "moduleName": "default",
    "title": "Flux",
    "type": "image",
    "templates": [
      {
        "name": "flux_dev_checkpoint_example",
        "title": "Flux Dev",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Create images using Flux development models.",
        "tutorialUrl": "https://comfyanonymous.github.io/ComfyUI_examples/flux/#flux-dev-1"
      },
      {
        "name": "flux_schnell",
        "title": "Flux Schnell",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Generate images quickly with Flux Schnell.",
        "tutorialUrl": "https://comfyanonymous.github.io/ComfyUI_examples/flux/#flux-schnell-1"
      },
      {
        "name": "flux_fill_inpaint_example",
        "title": "Flux Inpaint",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Fill in missing parts of images.",
        "thumbnailVariant": "compareSlider",
        "tutorialUrl": "https://comfyanonymous.github.io/ComfyUI_examples/flux/#fill-inpainting-model"
      },
      {
        "name": "flux_fill_outpaint_example",
        "title": "Flux Outpaint",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Extend images using Flux outpainting.",
        "thumbnailVariant": "compareSlider",
        "tutorialUrl": "https://comfyanonymous.github.io/ComfyUI_examples/flux/#fill-inpainting-model"
      },
      {
        "name": "flux_canny_model_example",
        "title": "Flux Canny Model",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Generate images from edge detection.",
        "thumbnailVariant": "hoverDissolve",
        "tutorialUrl": "https://comfyanonymous.github.io/ComfyUI_examples/flux/#canny-and-depth"
      },
      {
        "name": "flux_depth_lora_example",
        "title": "Flux Depth Lora",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Create images with depth-aware LoRA.",
        "thumbnailVariant": "hoverDissolve",
        "tutorialUrl": "https://comfyanonymous.github.io/ComfyUI_examples/flux/#canny-and-depth"
      },
      {
        "name": "flux_redux_model_example",
        "title": "Flux Redux Model",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Transfer style from a reference image to guide image generation with Flux.",
        "tutorialUrl": "https://comfyanonymous.github.io/ComfyUI_examples/flux/#redux"
      }
    ]
  },
  {
    "moduleName": "default",
    "title": "Image",
    "type": "image",
    "templates": [
      {
        "name": "hidream_i1_dev",
        "title": "HiDream I1 Dev",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Generate images with HiDream I1 Dev."
      },
      {
        "name": "hidream_i1_fast",
        "title": "HiDream I1 Fast",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Generate images quickly with HiDream I1."
      },
      {
        "name": "hidream_i1_full",
        "title": "HiDream I1 Full",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Generate images with HiDream I1."
      },
      {
        "name": "hidream_e1_full",
        "title": "HiDream E1 Full",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "thumbnailVariant": "compareSlider",
        "description": "Edit images with HiDream E1."
      },
      {
        "name": "sd3.5_simple_example",
        "title": "SD3.5 Simple",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Generate images with SD 3.5.",
        "tutorialUrl": "https://comfyanonymous.github.io/ComfyUI_examples/sd3/#sd35"
      },
      {
        "name": "sd3.5_large_canny_controlnet_example",
        "title": "SD3.5 Large Canny ControlNet",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Use edge detection to guide image generation with SD 3.5.",
        "thumbnailVariant": "hoverDissolve",
        "tutorialUrl": "https://comfyanonymous.github.io/ComfyUI_examples/sd3/#sd35-controlnets"
      },
      {
        "name": "sd3.5_large_depth",
        "title": "SD3.5 Large Depth",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Create depth-aware images with SD 3.5.",
        "thumbnailVariant": "hoverDissolve",
        "tutorialUrl": "https://comfyanonymous.github.io/ComfyUI_examples/sd3/#sd35-controlnets"
      },
      {
        "name": "sd3.5_large_blur",
        "title": "SD3.5 Large Blur",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Generate images from blurred reference images with SD 3.5.",
        "thumbnailVariant": "hoverDissolve",
        "tutorialUrl": "https://comfyanonymous.github.io/ComfyUI_examples/sd3/#sd35-controlnets"
      },
      {
        "name": "sdxl_simple_example",
        "title": "SDXL Simple",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Create high-quality images with SDXL.",
        "tutorialUrl": "https://comfyanonymous.github.io/ComfyUI_examples/sdxl/"
      },
      {
        "name": "sdxl_refiner_prompt_example",
        "title": "SDXL Refiner Prompt",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Enhance SDXL outputs with refiners.",
        "tutorialUrl": "https://comfyanonymous.github.io/ComfyUI_examples/sdxl/"
      },
      {
        "name": "sdxl_revision_text_prompts",
        "title": "SDXL Revision Text Prompts",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Transfer concepts from reference images to guide image generation with SDXL.",
        "tutorialUrl": "https://comfyanonymous.github.io/ComfyUI_examples/sdxl/#revision"
      },
      {
        "name": "sdxl_revision_zero_positive",
        "title": "SDXL Revision Zero Positive",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Add text prompts alongside reference images to guide image generation with SDXL.",
        "tutorialUrl": "https://comfyanonymous.github.io/ComfyUI_examples/sdxl/#revision"
      },
      {
        "name": "sdxlturbo_example",
        "title": "SDXL Turbo",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Generate images in a single step with SDXL Turbo.",
        "tutorialUrl": "https://comfyanonymous.github.io/ComfyUI_examples/sdturbo/"
      }
    ]
  },
  {
    "moduleName": "default",
    "title": "Video",
    "type": "video",
    "templates": [
      {
        "name": "text_to_video_wan",
        "title": "Wan 2.1 Text to Video",
        "description": "Quickly Generate videos from text descriptions.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tutorialUrl": "https://comfyanonymous.github.io/ComfyUI_examples/wan/#text-to-video"
      },
      {
        "name": "image_to_video_wan",
        "title": "Wan 2.1 Image to Video",
        "description": "Quickly Generate videos from images.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tutorialUrl": "https://comfyanonymous.github.io/ComfyUI_examples/wan/#image-to-video"
      },
      {
        "name": "wan2.1_fun_inp",
        "title": "Wan 2.1 Inpainting",
        "description": "Create videos from start and end frames.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tutorialUrl": "https://docs.comfy.org/tutorials/video/wan/fun-inp"
      },
      {
        "name": "wan2.1_fun_control",
        "title": "Wan 2.1 ControlNet",
        "description": "Guide video generation with pose, depth, edge controls and more.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "thumbnailVariant": "hoverDissolve",
        "tutorialUrl": "https://docs.comfy.org/tutorials/video/wan/fun-control"
      },
      {
        "name": "wan2.1_flf2v_720_f16",
        "title": "Wan 2.1 FLF2V 720p F16",
        "description": "Generate video through controlling the first and last frames.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tutorialUrl": "https://docs.comfy.org/tutorials/video/wan/wan-flf"
      },
      {
        "name": "ltxv_text_to_video",
        "title": "LTXV Text to Video",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Generate videos from text descriptions.",
        "tutorialUrl": "https://comfyanonymous.github.io/ComfyUI_examples/ltxv/#text-to-video"
      },
      {
        "name": "ltxv_image_to_video",
        "title": "LTXV Image to Video",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Convert still images into videos.",
        "tutorialUrl": "https://comfyanonymous.github.io/ComfyUI_examples/ltxv/#image-to-video"
      },
      {
        "name": "mochi_text_to_video_example",
        "title": "Mochi Text to Video",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Create videos with Mochi model.",
        "tutorialUrl": "https://comfyanonymous.github.io/ComfyUI_examples/mochi/"
      },
      {
        "name": "hunyuan_video_text_to_video",
        "title": "Hunyuan Video Text to Video",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Generate videos using Hunyuan model.",
        "tutorialUrl": "https://comfyanonymous.github.io/ComfyUI_examples/hunyuan_video/"
      },
      {
        "name": "image_to_video",
        "title": "SVD Image to Video",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Transform images into animated videos.",
        "tutorialUrl": "https://comfyanonymous.github.io/ComfyUI_examples/video/#image-to-video"
      },
      {
        "name": "txt_to_image_to_video",
        "title": "SVD Text to Image to Video",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Generate images from text and then convert them into videos.",
        "tutorialUrl": "https://comfyanonymous.github.io/ComfyUI_examples/video/#image-to-video"
      }
    ]
  },
  {
    "moduleName": "default",
    "title": "Image API",
    "type": "image",
    "templates": [
      {
        "name": "api_gpt_image_1_t2i",
        "title": "Text to Image with GPT Image 1",
        "description": "Use GPT Image 1 API to generate images from text descriptions.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tutorialUrl": "https://docs.comfy.org/tutorials/api-nodes/openai/gpt-image-1"
      },
      {
        "name": "api_gpt_image_1_i2i",
        "title": "Image to Image with GPT Image 1",
        "description": "Use GPT Image 1 API to generate images from images.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "thumbnailVariant": "compareSlider",
        "tutorialUrl": "https://docs.comfy.org/tutorials/api-nodes/openai/gpt-image-1"
      },
      {
        "name": "api_gpt_image_1_inpaint",
        "title": "Inpaint with GPT Image 1",
        "description": "Use GPT Image 1 API to inpaint images.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "thumbnailVariant": "compareSlider",
        "tutorialUrl": "https://docs.comfy.org/tutorials/api-nodes/openai/gpt-image-1"
      },
      {
        "name": "api_gpt_image_1_multi_inputs",
        "title": "Multi Inputs with GPT Image 1",
        "description": "Use GPT Image 1 API with multiple inputs to generate images.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "thumbnailVariant": "compareSlider",
        "tutorialUrl": "https://docs.comfy.org/tutorials/api-nodes/openai/gpt-image-1"
      },
      {
        "name": "dall-e-2-t2i",
        "title": "Text to Image with Dall-E 2",
        "description": "Use Dall-E 2 API to generate images from text descriptions.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tutorialUrl": "https://docs.comfy.org/tutorials/api-nodes/openai/dall-e-2"
      },
      {
        "name": "dall-e-2-inpaint",
        "title": "Inpaint with Dall-E 2",
        "description": "Use Dall-E 2 API to inpaint images.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "thumbnailVariant": "compareSlider",
        "tutorialUrl": "https://docs.comfy.org/tutorials/api-nodes/openai/dall-e-2"
      },
      {
        "name": "dall-e-3-t2i",
        "title": "Text to Image with Dall-E 3",
        "description": "Use Dall-E 3 API to generate images from text descriptions.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "tutorialUrl": "https://docs.comfy.org/tutorials/api-nodes/openai/dall-e-3"
      },
      {
        "name": "api_bfl_flux_pro_t2i",
        "title": "Text to Image with BFL Flux Pro",
        "description": "Use BFL Flux Pro API to generate images from text descriptions.",
        "mediaType": "image",
        "mediaSubtype": "webp"
      },
      {
        "name": "api_stability_sd3_t2i",
        "title": "Text to Image with Stability SD3",
        "description": "Use Stability SD3 API to generate images from text descriptions.",
        "mediaType": "image",
        "mediaSubtype": "webp"
      },
      {
        "name": "api_ideogram_v3_t2i",
        "title": "Text to Image with Ideogram V3",
        "description": "Use Ideogram V3 API to generate images from text descriptions.",
        "mediaType": "image",
        "mediaSubtype": "webp"
      },
      {
        "name": "api_luma_photon_i2i",
        "title": "Image to Image with Luma Photon",
        "description": "Use Luma Photon API to generate images from images.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "thumbnailVariant": "compareSlider"
      },
      {
        "name": "api_luma_photon_style_ref",
        "title": "Style Reference with Luma Photon",
        "description": "Use Luma Photon API to generate images from style references.",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "thumbnailVariant": "compareSlider"
      },
      {
        "name": "api_recraft_image_gen_with_color_control",
        "title": "Image Generation with Color Control",
        "description": "Use Recraft API to generate images with color control.",
        "mediaType": "image",
        "mediaSubtype": "webp"
      },
      {
        "name": "api_recraft_image_gen_with_style_control",
        "title": "Image Generation with Style Control",
        "description": "Use Recraft API to generate images with style control.",
        "mediaType": "image",
        "mediaSubtype": "webp"
      },
      {
        "name": "api_recraft_vector_gen",
        "title": "Vector Generation",
        "description": "Use Recraft API to generate vector images.",
        "mediaType": "image",
        "mediaSubtype": "webp"
      }
    ]
  },
  {
    "moduleName": "default",
    "title": "Video API",
    "type": "video",
    "templates": [
      {
        "name": "api_luma_i2v",
        "title": "Image to Video with Luma",
        "description": "Use Luma Photon API to generate videos from images.",
        "mediaType": "image",
        "mediaSubtype": "webp"
      },
      {
        "name": "api_kling_i2v",
        "title": "Image to Video with Kling",
        "description": "Use Kling API to generate videos from images.",
        "mediaType": "image",
        "mediaSubtype": "webp"
      },
      {
        "name": "api_google_veo2_i2v",
        "title": "Image to Video with Google VEo2",
        "description": "Use Google VEo2 API to generate videos from images.",
        "mediaType": "image",
        "mediaSubtype": "webp"
      },
      {
        "name": "api_minimax_i2v",
        "title": "Image to Video with Minimax",
        "description": "Use Minimax API to generate videos from images.",
        "mediaType": "image",
        "mediaSubtype": "webp"
      },
      {
        "name": "api_pika_scene",
        "title": "Generate videos from scene images using Pika API",
        "description": "Use Pika API to generate videos from scene images.",
        "mediaType": "image",
        "mediaSubtype": "webp"
      },
      {
        "name": "api_pixverse_t2v_template_i2v",
        "title": "Text to Video with Pixverse Template",
        "description": "Use Pixverse API to generate videos from text descriptions using Pixverse template.",
        "mediaType": "image",
        "mediaSubtype": "webp"
      },
      {
        "name": "api_pixverse_t2v",
        "title": "Text to Video with Pixverse",
        "description": "Use Pixverse API to generate videos from text descriptions.",
        "mediaType": "image",
        "mediaSubtype": "webp"
      }
    ]
  },
  {
    "moduleName": "default",
    "title": "Upscaling",
    "type": "image",
    "templates": [
      {
        "name": "hiresfix_latent_workflow",
        "title": "Upscale",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Enhance image quality in latent space.",
        "thumbnailVariant": "zoomHover",
        "tutorialUrl": "https://comfyanonymous.github.io/ComfyUI_examples/2_pass_txt2img/"
      },
      {
        "name": "esrgan_example",
        "title": "ESRGAN",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Use upscale models to enhance image quality.",
        "thumbnailVariant": "zoomHover",
        "tutorialUrl": "https://comfyanonymous.github.io/ComfyUI_examples/upscale_models/"
      },
      {
        "name": "hiresfix_esrgan_workflow",
        "title": "HiresFix ESRGAN Workflow",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Use upscale models during intermediate steps.",
        "thumbnailVariant": "zoomHover",
        "tutorialUrl": "https://comfyanonymous.github.io/ComfyUI_examples/2_pass_txt2img/#non-latent-upscaling"
      },
      {
        "name": "latent_upscale_different_prompt_model",
        "title": "Latent Upscale Different Prompt Model",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Upscale and change prompt across passes.",
        "thumbnailVariant": "zoomHover",
        "tutorialUrl": "https://comfyanonymous.github.io/ComfyUI_examples/2_pass_txt2img/#more-examples"
      }
    ]
  },
  {
    "moduleName": "default",
    "title": "ControlNet",
    "type": "image",
    "templates": [
      {
        "name": "controlnet_example",
        "title": "Scribble ControlNet",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Control image generation with reference images.",
        "thumbnailVariant": "hoverDissolve",
        "tutorialUrl": "https://comfyanonymous.github.io/ComfyUI_examples/controlnet/"
      },
      {
        "name": "2_pass_pose_worship",
        "title": "Pose ControlNet 2 Pass",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Generate images from pose references.",
        "thumbnailVariant": "hoverDissolve",
        "tutorialUrl": "https://comfyanonymous.github.io/ComfyUI_examples/controlnet/#pose-controlnet"
      },
      {
        "name": "depth_controlnet",
        "title": "Depth ControlNet",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Create images with depth-aware generation.",
        "thumbnailVariant": "hoverDissolve",
        "tutorialUrl": "https://comfyanonymous.github.io/ComfyUI_examples/controlnet/#t2i-adapter-vs-controlnets"
      },
      {
        "name": "depth_t2i_adapter",
        "title": "Depth T2I Adapter",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Quickly generate depth-aware images with a T2I adapter.",
        "thumbnailVariant": "hoverDissolve",
        "tutorialUrl": "https://comfyanonymous.github.io/ComfyUI_examples/controlnet/#t2i-adapter-vs-controlnets"
      },
      {
        "name": "mixing_controlnets",
        "title": "Mixing ControlNets",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Combine multiple ControlNet models together.",
        "thumbnailVariant": "hoverDissolve",
        "tutorialUrl": "https://comfyanonymous.github.io/ComfyUI_examples/controlnet/#mixing-controlnets"
      }
    ]
  },
  {
    "moduleName": "default",
    "title": "Area Composition",
    "type": "image",
    "templates": [
      {
        "name": "area_composition",
        "title": "Area Composition",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Control image composition with areas.",
        "tutorialUrl": "https://comfyanonymous.github.io/ComfyUI_examples/area_composition/"
      },
      {
        "name": "area_composition_reversed",
        "title": "Area Composition Reversed",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Reverse area composition workflow.",
        "tutorialUrl": "https://comfyanonymous.github.io/ComfyUI_examples/area_composition/"
      },
      {
        "name": "area_composition_square_area_for_subject",
        "title": "Area Composition Square Area for Subject",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Create consistent subject placement.",
        "tutorialUrl": "https://comfyanonymous.github.io/ComfyUI_examples/area_composition/#increasing-consistency-of-images-with-area-composition"
      }
    ]
  },
  {
    "moduleName": "default",
    "title": "3D",
    "type": "3d",
    "templates": [
      {
        "name": "hunyuan3d-non-multiview-train",
        "title": "Hunyuan3D 2.0",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Use Hunyuan3D 2.0 to generate models from a single view.",
        "tutorialUrl": ""
      },
      {
        "name": "hunyuan-3d-multiview-elf",
        "title": "Hunyuan3D 2.0 MV",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": " Use Hunyuan3D 2mv to generate models from multiple views.",
        "tutorialUrl": "",
        "thumbnailVariant": "compareSlider"
      },
      {
        "name": "hunyuan-3d-turbo",
        "title": "Hunyuan3D 2.0 MV Turbo",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Use Hunyuan3D 2mv turbo to generate models from multiple views.",
        "tutorialUrl": "",
        "thumbnailVariant": "compareSlider"
      },
      {
        "name": "stable_zero123_example",
        "title": "Stable Zero123",
        "mediaType": "image",
        "mediaSubtype": "webp",
        "description": "Generate 3D views from single images.",
        "tutorialUrl": "https://comfyanonymous.github.io/ComfyUI_examples/3d/"
      }
    ]
  },
  {
    "moduleName": "default",
    "title": "Audio",
    "type": "audio",
    "templates": [
      {
        "name": "stable_audio_example",
        "title": "Stable Audio",
        "mediaType": "audio",
        "mediaSubtype": "mp3",
        "description": "Generate audio from text descriptions.",
        "tutorialUrl": "https://comfyanonymous.github.io/ComfyUI_examples/audio/"
      }
    ]
  }
]
