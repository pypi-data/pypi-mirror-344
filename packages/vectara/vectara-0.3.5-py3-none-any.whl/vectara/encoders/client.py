# This file was auto-generated by Fern from our API Definition.

import typing

from ..core.client_wrapper import AsyncClientWrapper, SyncClientWrapper
from ..core.pagination import AsyncPager, SyncPager
from ..core.request_options import RequestOptions
from ..types.encoder import Encoder
from ..types.remote_auth import RemoteAuth
from .raw_client import AsyncRawEncodersClient, RawEncodersClient

# this is used as the default value for optional parameters
OMIT = typing.cast(typing.Any, ...)


class EncodersClient:
    def __init__(self, *, client_wrapper: SyncClientWrapper):
        self._raw_client = RawEncodersClient(client_wrapper=client_wrapper)

    @property
    def with_raw_response(self) -> RawEncodersClient:
        """
        Retrieves a raw implementation of this client that returns raw responses.

        Returns
        -------
        RawEncodersClient
        """
        return self._raw_client

    def list(
        self,
        *,
        filter: typing.Optional[str] = None,
        limit: typing.Optional[int] = None,
        page_key: typing.Optional[str] = None,
        request_timeout: typing.Optional[int] = None,
        request_timeout_millis: typing.Optional[int] = None,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> SyncPager[Encoder]:
        """
        Encoders are used to store and retrieve from a corpus.

        Parameters
        ----------
        filter : typing.Optional[str]
            A regular expression against encoder names and descriptions.

        limit : typing.Optional[int]
            The maximum number of results to return in the list.

        page_key : typing.Optional[str]
            Used to retrieve the next page of encoders after the limit has been reached.

        request_timeout : typing.Optional[int]
            The API will make a best effort to complete the request in the specified seconds or time out.

        request_timeout_millis : typing.Optional[int]
            The API will make a best effort to complete the request in the specified milliseconds or time out.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        SyncPager[Encoder]
            List of encoders.

        Examples
        --------
        from vectara import Vectara
        client = Vectara(api_key="YOUR_API_KEY", client_id="YOUR_CLIENT_ID", client_secret="YOUR_CLIENT_SECRET", )
        response = client.encoders.list(filter='vectara.*', )
        for item in response:
            yield item
        # alternatively, you can paginate page-by-page
        for page in response.iter_pages():
            yield page
        """
        response = self._raw_client.list(
            filter=filter,
            limit=limit,
            page_key=page_key,
            request_timeout=request_timeout,
            request_timeout_millis=request_timeout_millis,
            request_options=request_options,
        )
        return response.data

    def create(
        self,
        *,
        name: str,
        description: str,
        uri: str,
        model: str,
        request_timeout: typing.Optional[int] = None,
        request_timeout_millis: typing.Optional[int] = None,
        output_dimensions: typing.Optional[int] = OMIT,
        auth: typing.Optional[RemoteAuth] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> Encoder:
        """
        Create a new encoder.

        Parameters
        ----------
        name : str
            A unique name for the encoder

        description : str
            A description of what this encoder does

        uri : str
            The URI endpoint for the embedding API (can be OpenAI or any compatible embedding API endpoint)

        model : str
            The model name to use for embeddings

        request_timeout : typing.Optional[int]
            The API will make a best effort to complete the request in the specified seconds or time out.

        request_timeout_millis : typing.Optional[int]
            The API will make a best effort to complete the request in the specified milliseconds or time out.

        output_dimensions : typing.Optional[int]
            The number of dimensions in the output embedding vector. If provided and the model supports truncation,
            the response will be truncated to this number of dimensions.

        auth : typing.Optional[RemoteAuth]

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        Encoder
            The encoder has been created

        Examples
        --------
        from vectara import Vectara
        client = Vectara(api_key="YOUR_API_KEY", client_id="YOUR_CLIENT_ID", client_secret="YOUR_CLIENT_SECRET", )
        client.encoders.create(name='openai-text-encoder', description='description', uri='https://api.openai.com/v1/embeddings', model='text-embedding-ada-002', )
        """
        response = self._raw_client.create(
            name=name,
            description=description,
            uri=uri,
            model=model,
            request_timeout=request_timeout,
            request_timeout_millis=request_timeout_millis,
            output_dimensions=output_dimensions,
            auth=auth,
            request_options=request_options,
        )
        return response.data


class AsyncEncodersClient:
    def __init__(self, *, client_wrapper: AsyncClientWrapper):
        self._raw_client = AsyncRawEncodersClient(client_wrapper=client_wrapper)

    @property
    def with_raw_response(self) -> AsyncRawEncodersClient:
        """
        Retrieves a raw implementation of this client that returns raw responses.

        Returns
        -------
        AsyncRawEncodersClient
        """
        return self._raw_client

    async def list(
        self,
        *,
        filter: typing.Optional[str] = None,
        limit: typing.Optional[int] = None,
        page_key: typing.Optional[str] = None,
        request_timeout: typing.Optional[int] = None,
        request_timeout_millis: typing.Optional[int] = None,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> AsyncPager[Encoder]:
        """
        Encoders are used to store and retrieve from a corpus.

        Parameters
        ----------
        filter : typing.Optional[str]
            A regular expression against encoder names and descriptions.

        limit : typing.Optional[int]
            The maximum number of results to return in the list.

        page_key : typing.Optional[str]
            Used to retrieve the next page of encoders after the limit has been reached.

        request_timeout : typing.Optional[int]
            The API will make a best effort to complete the request in the specified seconds or time out.

        request_timeout_millis : typing.Optional[int]
            The API will make a best effort to complete the request in the specified milliseconds or time out.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        AsyncPager[Encoder]
            List of encoders.

        Examples
        --------
        from vectara import AsyncVectara
        import asyncio
        client = AsyncVectara(api_key="YOUR_API_KEY", client_id="YOUR_CLIENT_ID", client_secret="YOUR_CLIENT_SECRET", )
        async def main() -> None:
            response = await client.encoders.list(filter='vectara.*', )
            async for item in response:
                yield item

            # alternatively, you can paginate page-by-page
            async for page in response.iter_pages():
                yield page
        asyncio.run(main())
        """
        response = await self._raw_client.list(
            filter=filter,
            limit=limit,
            page_key=page_key,
            request_timeout=request_timeout,
            request_timeout_millis=request_timeout_millis,
            request_options=request_options,
        )
        return response.data

    async def create(
        self,
        *,
        name: str,
        description: str,
        uri: str,
        model: str,
        request_timeout: typing.Optional[int] = None,
        request_timeout_millis: typing.Optional[int] = None,
        output_dimensions: typing.Optional[int] = OMIT,
        auth: typing.Optional[RemoteAuth] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> Encoder:
        """
        Create a new encoder.

        Parameters
        ----------
        name : str
            A unique name for the encoder

        description : str
            A description of what this encoder does

        uri : str
            The URI endpoint for the embedding API (can be OpenAI or any compatible embedding API endpoint)

        model : str
            The model name to use for embeddings

        request_timeout : typing.Optional[int]
            The API will make a best effort to complete the request in the specified seconds or time out.

        request_timeout_millis : typing.Optional[int]
            The API will make a best effort to complete the request in the specified milliseconds or time out.

        output_dimensions : typing.Optional[int]
            The number of dimensions in the output embedding vector. If provided and the model supports truncation,
            the response will be truncated to this number of dimensions.

        auth : typing.Optional[RemoteAuth]

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        Encoder
            The encoder has been created

        Examples
        --------
        from vectara import AsyncVectara
        import asyncio
        client = AsyncVectara(api_key="YOUR_API_KEY", client_id="YOUR_CLIENT_ID", client_secret="YOUR_CLIENT_SECRET", )
        async def main() -> None:
            await client.encoders.create(name='openai-text-encoder', description='description', uri='https://api.openai.com/v1/embeddings', model='text-embedding-ada-002', )
        asyncio.run(main())
        """
        response = await self._raw_client.create(
            name=name,
            description=description,
            uri=uri,
            model=model,
            request_timeout=request_timeout,
            request_timeout_millis=request_timeout_millis,
            output_dimensions=output_dimensions,
            auth=auth,
            request_options=request_options,
        )
        return response.data
