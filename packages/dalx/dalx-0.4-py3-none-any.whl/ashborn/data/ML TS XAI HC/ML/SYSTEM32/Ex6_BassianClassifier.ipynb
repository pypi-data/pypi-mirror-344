{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7327c24-ed64-4b50-9eb9-42f1ca544cd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import datasets\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Load dataset\n",
    "win = datasets.load_wine()\n",
    "X = win.data\n",
    "y = win.target\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "# Train model\n",
    "gnb = GaussianNB().fit(X_train, y_train)\n",
    "gnb_predictions = gnb.predict(X_test)\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, gnb_predictions)\n",
    "#labels = win.target_names\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "            xticklabels=[0,1,2], yticklabels=[0,1,2])\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.title(\"Confusion Matrix for Gaussian Naive Bayes (Wine Dataset)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "219554ad-622f-4428-aa10-35f5b6bbafcb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on module sklearn.naive_bayes in sklearn:\n",
      "\n",
      "NAME\n",
      "    sklearn.naive_bayes - Naive Bayes algorithms.\n",
      "\n",
      "DESCRIPTION\n",
      "    These are supervised learning methods based on applying Bayes' theorem with strong\n",
      "    (naive) feature independence assumptions.\n",
      "\n",
      "CLASSES\n",
      "    _BaseDiscreteNB(_BaseNB)\n",
      "        BernoulliNB\n",
      "        CategoricalNB\n",
      "        ComplementNB\n",
      "        MultinomialNB\n",
      "    _BaseNB(sklearn.base.ClassifierMixin, sklearn.base.BaseEstimator)\n",
      "        GaussianNB\n",
      "    \n",
      "    class BernoulliNB(_BaseDiscreteNB)\n",
      "     |  BernoulliNB(*, alpha=1.0, force_alpha=True, binarize=0.0, fit_prior=True, class_prior=None)\n",
      "     |  \n",
      "     |  Naive Bayes classifier for multivariate Bernoulli models.\n",
      "     |  \n",
      "     |  Like MultinomialNB, this classifier is suitable for discrete data. The\n",
      "     |  difference is that while MultinomialNB works with occurrence counts,\n",
      "     |  BernoulliNB is designed for binary/boolean features.\n",
      "     |  \n",
      "     |  Read more in the :ref:`User Guide <bernoulli_naive_bayes>`.\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  alpha : float or array-like of shape (n_features,), default=1.0\n",
      "     |      Additive (Laplace/Lidstone) smoothing parameter\n",
      "     |      (set alpha=0 and force_alpha=True, for no smoothing).\n",
      "     |  \n",
      "     |  force_alpha : bool, default=True\n",
      "     |      If False and alpha is less than 1e-10, it will set alpha to\n",
      "     |      1e-10. If True, alpha will remain unchanged. This may cause\n",
      "     |      numerical errors if alpha is too close to 0.\n",
      "     |  \n",
      "     |      .. versionadded:: 1.2\n",
      "     |      .. versionchanged:: 1.4\n",
      "     |         The default value of `force_alpha` changed to `True`.\n",
      "     |  \n",
      "     |  binarize : float or None, default=0.0\n",
      "     |      Threshold for binarizing (mapping to booleans) of sample features.\n",
      "     |      If None, input is presumed to already consist of binary vectors.\n",
      "     |  \n",
      "     |  fit_prior : bool, default=True\n",
      "     |      Whether to learn class prior probabilities or not.\n",
      "     |      If false, a uniform prior will be used.\n",
      "     |  \n",
      "     |  class_prior : array-like of shape (n_classes,), default=None\n",
      "     |      Prior probabilities of the classes. If specified, the priors are not\n",
      "     |      adjusted according to the data.\n",
      "     |  \n",
      "     |  Attributes\n",
      "     |  ----------\n",
      "     |  class_count_ : ndarray of shape (n_classes,)\n",
      "     |      Number of samples encountered for each class during fitting. This\n",
      "     |      value is weighted by the sample weight when provided.\n",
      "     |  \n",
      "     |  class_log_prior_ : ndarray of shape (n_classes,)\n",
      "     |      Log probability of each class (smoothed).\n",
      "     |  \n",
      "     |  classes_ : ndarray of shape (n_classes,)\n",
      "     |      Class labels known to the classifier\n",
      "     |  \n",
      "     |  feature_count_ : ndarray of shape (n_classes, n_features)\n",
      "     |      Number of samples encountered for each (class, feature)\n",
      "     |      during fitting. This value is weighted by the sample weight when\n",
      "     |      provided.\n",
      "     |  \n",
      "     |  feature_log_prob_ : ndarray of shape (n_classes, n_features)\n",
      "     |      Empirical log probability of features given a class, P(x_i|y).\n",
      "     |  \n",
      "     |  n_features_in_ : int\n",
      "     |      Number of features seen during :term:`fit`.\n",
      "     |  \n",
      "     |      .. versionadded:: 0.24\n",
      "     |  \n",
      "     |  feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
      "     |      Names of features seen during :term:`fit`. Defined only when `X`\n",
      "     |      has feature names that are all strings.\n",
      "     |  \n",
      "     |      .. versionadded:: 1.0\n",
      "     |  \n",
      "     |  See Also\n",
      "     |  --------\n",
      "     |  CategoricalNB : Naive Bayes classifier for categorical features.\n",
      "     |  ComplementNB : The Complement Naive Bayes classifier\n",
      "     |      described in Rennie et al. (2003).\n",
      "     |  GaussianNB : Gaussian Naive Bayes (GaussianNB).\n",
      "     |  MultinomialNB : Naive Bayes classifier for multinomial models.\n",
      "     |  \n",
      "     |  References\n",
      "     |  ----------\n",
      "     |  C.D. Manning, P. Raghavan and H. Schuetze (2008). Introduction to\n",
      "     |  Information Retrieval. Cambridge University Press, pp. 234-265.\n",
      "     |  https://nlp.stanford.edu/IR-book/html/htmledition/the-bernoulli-model-1.html\n",
      "     |  \n",
      "     |  A. McCallum and K. Nigam (1998). A comparison of event models for naive\n",
      "     |  Bayes text classification. Proc. AAAI/ICML-98 Workshop on Learning for\n",
      "     |  Text Categorization, pp. 41-48.\n",
      "     |  \n",
      "     |  V. Metsis, I. Androutsopoulos and G. Paliouras (2006). Spam filtering with\n",
      "     |  naive Bayes -- Which naive Bayes? 3rd Conf. on Email and Anti-Spam (CEAS).\n",
      "     |  \n",
      "     |  Examples\n",
      "     |  --------\n",
      "     |  >>> import numpy as np\n",
      "     |  >>> rng = np.random.RandomState(1)\n",
      "     |  >>> X = rng.randint(5, size=(6, 100))\n",
      "     |  >>> Y = np.array([1, 2, 3, 4, 4, 5])\n",
      "     |  >>> from sklearn.naive_bayes import BernoulliNB\n",
      "     |  >>> clf = BernoulliNB()\n",
      "     |  >>> clf.fit(X, Y)\n",
      "     |  BernoulliNB()\n",
      "     |  >>> print(clf.predict(X[2:3]))\n",
      "     |  [3]\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      BernoulliNB\n",
      "     |      _BaseDiscreteNB\n",
      "     |      _BaseNB\n",
      "     |      sklearn.base.ClassifierMixin\n",
      "     |      sklearn.base.BaseEstimator\n",
      "     |      sklearn.utils._estimator_html_repr._HTMLDocumentationLinkMixin\n",
      "     |      sklearn.utils._metadata_requests._MetadataRequester\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, *, alpha=1.0, force_alpha=True, binarize=0.0, fit_prior=True, class_prior=None)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  set_fit_request(self: sklearn.naive_bayes.BernoulliNB, *, sample_weight: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.naive_bayes.BernoulliNB\n",
      "     |      Request metadata passed to the ``fit`` method.\n",
      "     |      \n",
      "     |      Note that this method is only relevant if\n",
      "     |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
      "     |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |      \n",
      "     |      The options for each parameter are:\n",
      "     |      \n",
      "     |      - ``True``: metadata is requested, and passed to ``fit`` if provided. The request is ignored if metadata is not provided.\n",
      "     |      \n",
      "     |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``fit``.\n",
      "     |      \n",
      "     |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
      "     |      \n",
      "     |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
      "     |      \n",
      "     |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
      "     |      existing request. This allows you to change the request for some\n",
      "     |      parameters and not others.\n",
      "     |      \n",
      "     |      .. versionadded:: 1.3\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |          This method is only relevant if this estimator is used as a\n",
      "     |          sub-estimator of a meta-estimator, e.g. used inside a\n",
      "     |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      sample_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``sample_weight`` parameter in ``fit``.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          The updated object.\n",
      "     |  \n",
      "     |  set_partial_fit_request(self: sklearn.naive_bayes.BernoulliNB, *, classes: Union[bool, NoneType, str] = '$UNCHANGED$', sample_weight: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.naive_bayes.BernoulliNB\n",
      "     |      Request metadata passed to the ``partial_fit`` method.\n",
      "     |      \n",
      "     |      Note that this method is only relevant if\n",
      "     |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
      "     |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |      \n",
      "     |      The options for each parameter are:\n",
      "     |      \n",
      "     |      - ``True``: metadata is requested, and passed to ``partial_fit`` if provided. The request is ignored if metadata is not provided.\n",
      "     |      \n",
      "     |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``partial_fit``.\n",
      "     |      \n",
      "     |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
      "     |      \n",
      "     |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
      "     |      \n",
      "     |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
      "     |      existing request. This allows you to change the request for some\n",
      "     |      parameters and not others.\n",
      "     |      \n",
      "     |      .. versionadded:: 1.3\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |          This method is only relevant if this estimator is used as a\n",
      "     |          sub-estimator of a meta-estimator, e.g. used inside a\n",
      "     |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      classes : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``classes`` parameter in ``partial_fit``.\n",
      "     |      \n",
      "     |      sample_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``sample_weight`` parameter in ``partial_fit``.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          The updated object.\n",
      "     |  \n",
      "     |  set_score_request(self: sklearn.naive_bayes.BernoulliNB, *, sample_weight: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.naive_bayes.BernoulliNB\n",
      "     |      Request metadata passed to the ``score`` method.\n",
      "     |      \n",
      "     |      Note that this method is only relevant if\n",
      "     |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
      "     |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |      \n",
      "     |      The options for each parameter are:\n",
      "     |      \n",
      "     |      - ``True``: metadata is requested, and passed to ``score`` if provided. The request is ignored if metadata is not provided.\n",
      "     |      \n",
      "     |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``score``.\n",
      "     |      \n",
      "     |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
      "     |      \n",
      "     |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
      "     |      \n",
      "     |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
      "     |      existing request. This allows you to change the request for some\n",
      "     |      parameters and not others.\n",
      "     |      \n",
      "     |      .. versionadded:: 1.3\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |          This method is only relevant if this estimator is used as a\n",
      "     |          sub-estimator of a meta-estimator, e.g. used inside a\n",
      "     |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      sample_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``sample_weight`` parameter in ``score``.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          The updated object.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  __annotations__ = {'_parameter_constraints': <class 'dict'>}\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from _BaseDiscreteNB:\n",
      "     |  \n",
      "     |  __sklearn_tags__(self)\n",
      "     |  \n",
      "     |  fit(self, X, y, sample_weight=None)\n",
      "     |      Fit Naive Bayes classifier according to X, y.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      "     |          Training vectors, where `n_samples` is the number of samples and\n",
      "     |          `n_features` is the number of features.\n",
      "     |      \n",
      "     |      y : array-like of shape (n_samples,)\n",
      "     |          Target values.\n",
      "     |      \n",
      "     |      sample_weight : array-like of shape (n_samples,), default=None\n",
      "     |          Weights applied to individual samples (1. for unweighted).\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          Returns the instance itself.\n",
      "     |  \n",
      "     |  partial_fit(self, X, y, classes=None, sample_weight=None)\n",
      "     |      Incremental fit on a batch of samples.\n",
      "     |      \n",
      "     |      This method is expected to be called several times consecutively\n",
      "     |      on different chunks of a dataset so as to implement out-of-core\n",
      "     |      or online learning.\n",
      "     |      \n",
      "     |      This is especially useful when the whole dataset is too big to fit in\n",
      "     |      memory at once.\n",
      "     |      \n",
      "     |      This method has some performance overhead hence it is better to call\n",
      "     |      partial_fit on chunks of data that are as large as possible\n",
      "     |      (as long as fitting in the memory budget) to hide the overhead.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      "     |          Training vectors, where `n_samples` is the number of samples and\n",
      "     |          `n_features` is the number of features.\n",
      "     |      \n",
      "     |      y : array-like of shape (n_samples,)\n",
      "     |          Target values.\n",
      "     |      \n",
      "     |      classes : array-like of shape (n_classes,), default=None\n",
      "     |          List of all the classes that can possibly appear in the y vector.\n",
      "     |      \n",
      "     |          Must be provided at the first call to partial_fit, can be omitted\n",
      "     |          in subsequent calls.\n",
      "     |      \n",
      "     |      sample_weight : array-like of shape (n_samples,), default=None\n",
      "     |          Weights applied to individual samples (1. for unweighted).\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          Returns the instance itself.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from _BaseNB:\n",
      "     |  \n",
      "     |  predict(self, X)\n",
      "     |      Perform classification on an array of test vectors X.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like of shape (n_samples, n_features)\n",
      "     |          The input samples.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      C : ndarray of shape (n_samples,)\n",
      "     |          Predicted target values for X.\n",
      "     |  \n",
      "     |  predict_joint_log_proba(self, X)\n",
      "     |      Return joint log probability estimates for the test vector X.\n",
      "     |      \n",
      "     |      For each row x of X and class y, the joint log probability is given by\n",
      "     |      ``log P(x, y) = log P(y) + log P(x|y),``\n",
      "     |      where ``log P(y)`` is the class prior probability and ``log P(x|y)`` is\n",
      "     |      the class-conditional probability.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like of shape (n_samples, n_features)\n",
      "     |          The input samples.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      C : ndarray of shape (n_samples, n_classes)\n",
      "     |          Returns the joint log-probability of the samples for each class in\n",
      "     |          the model. The columns correspond to the classes in sorted\n",
      "     |          order, as they appear in the attribute :term:`classes_`.\n",
      "     |  \n",
      "     |  predict_log_proba(self, X)\n",
      "     |      Return log-probability estimates for the test vector X.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like of shape (n_samples, n_features)\n",
      "     |          The input samples.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      C : array-like of shape (n_samples, n_classes)\n",
      "     |          Returns the log-probability of the samples for each class in\n",
      "     |          the model. The columns correspond to the classes in sorted\n",
      "     |          order, as they appear in the attribute :term:`classes_`.\n",
      "     |  \n",
      "     |  predict_proba(self, X)\n",
      "     |      Return probability estimates for the test vector X.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like of shape (n_samples, n_features)\n",
      "     |          The input samples.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      C : array-like of shape (n_samples, n_classes)\n",
      "     |          Returns the probability of the samples for each class in\n",
      "     |          the model. The columns correspond to the classes in sorted\n",
      "     |          order, as they appear in the attribute :term:`classes_`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.base.ClassifierMixin:\n",
      "     |  \n",
      "     |  score(self, X, y, sample_weight=None)\n",
      "     |      Return the mean accuracy on the given test data and labels.\n",
      "     |      \n",
      "     |      In multi-label classification, this is the subset accuracy\n",
      "     |      which is a harsh metric since you require for each sample that\n",
      "     |      each label set be correctly predicted.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like of shape (n_samples, n_features)\n",
      "     |          Test samples.\n",
      "     |      \n",
      "     |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      "     |          True labels for `X`.\n",
      "     |      \n",
      "     |      sample_weight : array-like of shape (n_samples,), default=None\n",
      "     |          Sample weights.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      score : float\n",
      "     |          Mean accuracy of ``self.predict(X)`` w.r.t. `y`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from sklearn.base.ClassifierMixin:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.base.BaseEstimator:\n",
      "     |  \n",
      "     |  __getstate__(self)\n",
      "     |  \n",
      "     |  __repr__(self, N_CHAR_MAX=700)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __setstate__(self, state)\n",
      "     |  \n",
      "     |  __sklearn_clone__(self)\n",
      "     |  \n",
      "     |  get_params(self, deep=True)\n",
      "     |      Get parameters for this estimator.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      deep : bool, default=True\n",
      "     |          If True, will return the parameters for this estimator and\n",
      "     |          contained subobjects that are estimators.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      params : dict\n",
      "     |          Parameter names mapped to their values.\n",
      "     |  \n",
      "     |  set_params(self, **params)\n",
      "     |      Set the parameters of this estimator.\n",
      "     |      \n",
      "     |      The method works on simple estimators as well as on nested objects\n",
      "     |      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n",
      "     |      parameters of the form ``<component>__<parameter>`` so that it's\n",
      "     |      possible to update each component of a nested object.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      **params : dict\n",
      "     |          Estimator parameters.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : estimator instance\n",
      "     |          Estimator instance.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
      "     |  \n",
      "     |  get_metadata_routing(self)\n",
      "     |      Get metadata routing of this object.\n",
      "     |      \n",
      "     |      Please check :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      routing : MetadataRequest\n",
      "     |          A :class:`~sklearn.utils.metadata_routing.MetadataRequest` encapsulating\n",
      "     |          routing information.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
      "     |  \n",
      "     |  __init_subclass__(**kwargs) from abc.ABCMeta\n",
      "     |      Set the ``set_{method}_request`` methods.\n",
      "     |      \n",
      "     |      This uses PEP-487 [1]_ to set the ``set_{method}_request`` methods. It\n",
      "     |      looks for the information available in the set default values which are\n",
      "     |      set using ``__metadata_request__*`` class attributes, or inferred\n",
      "     |      from method signatures.\n",
      "     |      \n",
      "     |      The ``__metadata_request__*`` class attributes are used when a method\n",
      "     |      does not explicitly accept a metadata through its arguments or if the\n",
      "     |      developer would like to specify a request value for those metadata\n",
      "     |      which are different from the default ``None``.\n",
      "     |      \n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      .. [1] https://www.python.org/dev/peps/pep-0487\n",
      "    \n",
      "    class CategoricalNB(_BaseDiscreteNB)\n",
      "     |  CategoricalNB(*, alpha=1.0, force_alpha=True, fit_prior=True, class_prior=None, min_categories=None)\n",
      "     |  \n",
      "     |  Naive Bayes classifier for categorical features.\n",
      "     |  \n",
      "     |  The categorical Naive Bayes classifier is suitable for classification with\n",
      "     |  discrete features that are categorically distributed. The categories of\n",
      "     |  each feature are drawn from a categorical distribution.\n",
      "     |  \n",
      "     |  Read more in the :ref:`User Guide <categorical_naive_bayes>`.\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  alpha : float, default=1.0\n",
      "     |      Additive (Laplace/Lidstone) smoothing parameter\n",
      "     |      (set alpha=0 and force_alpha=True, for no smoothing).\n",
      "     |  \n",
      "     |  force_alpha : bool, default=True\n",
      "     |      If False and alpha is less than 1e-10, it will set alpha to\n",
      "     |      1e-10. If True, alpha will remain unchanged. This may cause\n",
      "     |      numerical errors if alpha is too close to 0.\n",
      "     |  \n",
      "     |      .. versionadded:: 1.2\n",
      "     |      .. versionchanged:: 1.4\n",
      "     |         The default value of `force_alpha` changed to `True`.\n",
      "     |  \n",
      "     |  fit_prior : bool, default=True\n",
      "     |      Whether to learn class prior probabilities or not.\n",
      "     |      If false, a uniform prior will be used.\n",
      "     |  \n",
      "     |  class_prior : array-like of shape (n_classes,), default=None\n",
      "     |      Prior probabilities of the classes. If specified, the priors are not\n",
      "     |      adjusted according to the data.\n",
      "     |  \n",
      "     |  min_categories : int or array-like of shape (n_features,), default=None\n",
      "     |      Minimum number of categories per feature.\n",
      "     |  \n",
      "     |      - integer: Sets the minimum number of categories per feature to\n",
      "     |        `n_categories` for each features.\n",
      "     |      - array-like: shape (n_features,) where `n_categories[i]` holds the\n",
      "     |        minimum number of categories for the ith column of the input.\n",
      "     |      - None (default): Determines the number of categories automatically\n",
      "     |        from the training data.\n",
      "     |  \n",
      "     |      .. versionadded:: 0.24\n",
      "     |  \n",
      "     |  Attributes\n",
      "     |  ----------\n",
      "     |  category_count_ : list of arrays of shape (n_features,)\n",
      "     |      Holds arrays of shape (n_classes, n_categories of respective feature)\n",
      "     |      for each feature. Each array provides the number of samples\n",
      "     |      encountered for each class and category of the specific feature.\n",
      "     |  \n",
      "     |  class_count_ : ndarray of shape (n_classes,)\n",
      "     |      Number of samples encountered for each class during fitting. This\n",
      "     |      value is weighted by the sample weight when provided.\n",
      "     |  \n",
      "     |  class_log_prior_ : ndarray of shape (n_classes,)\n",
      "     |      Smoothed empirical log probability for each class.\n",
      "     |  \n",
      "     |  classes_ : ndarray of shape (n_classes,)\n",
      "     |      Class labels known to the classifier\n",
      "     |  \n",
      "     |  feature_log_prob_ : list of arrays of shape (n_features,)\n",
      "     |      Holds arrays of shape (n_classes, n_categories of respective feature)\n",
      "     |      for each feature. Each array provides the empirical log probability\n",
      "     |      of categories given the respective feature and class, ``P(x_i|y)``.\n",
      "     |  \n",
      "     |  n_features_in_ : int\n",
      "     |      Number of features seen during :term:`fit`.\n",
      "     |  \n",
      "     |      .. versionadded:: 0.24\n",
      "     |  \n",
      "     |  feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
      "     |      Names of features seen during :term:`fit`. Defined only when `X`\n",
      "     |      has feature names that are all strings.\n",
      "     |  \n",
      "     |      .. versionadded:: 1.0\n",
      "     |  \n",
      "     |  n_categories_ : ndarray of shape (n_features,), dtype=np.int64\n",
      "     |      Number of categories for each feature. This value is\n",
      "     |      inferred from the data or set by the minimum number of categories.\n",
      "     |  \n",
      "     |      .. versionadded:: 0.24\n",
      "     |  \n",
      "     |  See Also\n",
      "     |  --------\n",
      "     |  BernoulliNB : Naive Bayes classifier for multivariate Bernoulli models.\n",
      "     |  ComplementNB : Complement Naive Bayes classifier.\n",
      "     |  GaussianNB : Gaussian Naive Bayes.\n",
      "     |  MultinomialNB : Naive Bayes classifier for multinomial models.\n",
      "     |  \n",
      "     |  Examples\n",
      "     |  --------\n",
      "     |  >>> import numpy as np\n",
      "     |  >>> rng = np.random.RandomState(1)\n",
      "     |  >>> X = rng.randint(5, size=(6, 100))\n",
      "     |  >>> y = np.array([1, 2, 3, 4, 5, 6])\n",
      "     |  >>> from sklearn.naive_bayes import CategoricalNB\n",
      "     |  >>> clf = CategoricalNB()\n",
      "     |  >>> clf.fit(X, y)\n",
      "     |  CategoricalNB()\n",
      "     |  >>> print(clf.predict(X[2:3]))\n",
      "     |  [3]\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      CategoricalNB\n",
      "     |      _BaseDiscreteNB\n",
      "     |      _BaseNB\n",
      "     |      sklearn.base.ClassifierMixin\n",
      "     |      sklearn.base.BaseEstimator\n",
      "     |      sklearn.utils._estimator_html_repr._HTMLDocumentationLinkMixin\n",
      "     |      sklearn.utils._metadata_requests._MetadataRequester\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, *, alpha=1.0, force_alpha=True, fit_prior=True, class_prior=None, min_categories=None)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __sklearn_tags__(self)\n",
      "     |  \n",
      "     |  fit(self, X, y, sample_weight=None)\n",
      "     |      Fit Naive Bayes classifier according to X, y.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      "     |          Training vectors, where `n_samples` is the number of samples and\n",
      "     |          `n_features` is the number of features. Here, each feature of X is\n",
      "     |          assumed to be from a different categorical distribution.\n",
      "     |          It is further assumed that all categories of each feature are\n",
      "     |          represented by the numbers 0, ..., n - 1, where n refers to the\n",
      "     |          total number of categories for the given feature. This can, for\n",
      "     |          instance, be achieved with the help of OrdinalEncoder.\n",
      "     |      \n",
      "     |      y : array-like of shape (n_samples,)\n",
      "     |          Target values.\n",
      "     |      \n",
      "     |      sample_weight : array-like of shape (n_samples,), default=None\n",
      "     |          Weights applied to individual samples (1. for unweighted).\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          Returns the instance itself.\n",
      "     |  \n",
      "     |  partial_fit(self, X, y, classes=None, sample_weight=None)\n",
      "     |      Incremental fit on a batch of samples.\n",
      "     |      \n",
      "     |      This method is expected to be called several times consecutively\n",
      "     |      on different chunks of a dataset so as to implement out-of-core\n",
      "     |      or online learning.\n",
      "     |      \n",
      "     |      This is especially useful when the whole dataset is too big to fit in\n",
      "     |      memory at once.\n",
      "     |      \n",
      "     |      This method has some performance overhead hence it is better to call\n",
      "     |      partial_fit on chunks of data that are as large as possible\n",
      "     |      (as long as fitting in the memory budget) to hide the overhead.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      "     |          Training vectors, where `n_samples` is the number of samples and\n",
      "     |          `n_features` is the number of features. Here, each feature of X is\n",
      "     |          assumed to be from a different categorical distribution.\n",
      "     |          It is further assumed that all categories of each feature are\n",
      "     |          represented by the numbers 0, ..., n - 1, where n refers to the\n",
      "     |          total number of categories for the given feature. This can, for\n",
      "     |          instance, be achieved with the help of OrdinalEncoder.\n",
      "     |      \n",
      "     |      y : array-like of shape (n_samples,)\n",
      "     |          Target values.\n",
      "     |      \n",
      "     |      classes : array-like of shape (n_classes,), default=None\n",
      "     |          List of all the classes that can possibly appear in the y vector.\n",
      "     |      \n",
      "     |          Must be provided at the first call to partial_fit, can be omitted\n",
      "     |          in subsequent calls.\n",
      "     |      \n",
      "     |      sample_weight : array-like of shape (n_samples,), default=None\n",
      "     |          Weights applied to individual samples (1. for unweighted).\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          Returns the instance itself.\n",
      "     |  \n",
      "     |  set_fit_request(self: sklearn.naive_bayes.CategoricalNB, *, sample_weight: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.naive_bayes.CategoricalNB\n",
      "     |      Request metadata passed to the ``fit`` method.\n",
      "     |      \n",
      "     |      Note that this method is only relevant if\n",
      "     |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
      "     |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |      \n",
      "     |      The options for each parameter are:\n",
      "     |      \n",
      "     |      - ``True``: metadata is requested, and passed to ``fit`` if provided. The request is ignored if metadata is not provided.\n",
      "     |      \n",
      "     |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``fit``.\n",
      "     |      \n",
      "     |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
      "     |      \n",
      "     |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
      "     |      \n",
      "     |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
      "     |      existing request. This allows you to change the request for some\n",
      "     |      parameters and not others.\n",
      "     |      \n",
      "     |      .. versionadded:: 1.3\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |          This method is only relevant if this estimator is used as a\n",
      "     |          sub-estimator of a meta-estimator, e.g. used inside a\n",
      "     |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      sample_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``sample_weight`` parameter in ``fit``.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          The updated object.\n",
      "     |  \n",
      "     |  set_partial_fit_request(self: sklearn.naive_bayes.CategoricalNB, *, classes: Union[bool, NoneType, str] = '$UNCHANGED$', sample_weight: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.naive_bayes.CategoricalNB\n",
      "     |      Request metadata passed to the ``partial_fit`` method.\n",
      "     |      \n",
      "     |      Note that this method is only relevant if\n",
      "     |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
      "     |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |      \n",
      "     |      The options for each parameter are:\n",
      "     |      \n",
      "     |      - ``True``: metadata is requested, and passed to ``partial_fit`` if provided. The request is ignored if metadata is not provided.\n",
      "     |      \n",
      "     |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``partial_fit``.\n",
      "     |      \n",
      "     |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
      "     |      \n",
      "     |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
      "     |      \n",
      "     |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
      "     |      existing request. This allows you to change the request for some\n",
      "     |      parameters and not others.\n",
      "     |      \n",
      "     |      .. versionadded:: 1.3\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |          This method is only relevant if this estimator is used as a\n",
      "     |          sub-estimator of a meta-estimator, e.g. used inside a\n",
      "     |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      classes : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``classes`` parameter in ``partial_fit``.\n",
      "     |      \n",
      "     |      sample_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``sample_weight`` parameter in ``partial_fit``.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          The updated object.\n",
      "     |  \n",
      "     |  set_score_request(self: sklearn.naive_bayes.CategoricalNB, *, sample_weight: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.naive_bayes.CategoricalNB\n",
      "     |      Request metadata passed to the ``score`` method.\n",
      "     |      \n",
      "     |      Note that this method is only relevant if\n",
      "     |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
      "     |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |      \n",
      "     |      The options for each parameter are:\n",
      "     |      \n",
      "     |      - ``True``: metadata is requested, and passed to ``score`` if provided. The request is ignored if metadata is not provided.\n",
      "     |      \n",
      "     |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``score``.\n",
      "     |      \n",
      "     |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
      "     |      \n",
      "     |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
      "     |      \n",
      "     |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
      "     |      existing request. This allows you to change the request for some\n",
      "     |      parameters and not others.\n",
      "     |      \n",
      "     |      .. versionadded:: 1.3\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |          This method is only relevant if this estimator is used as a\n",
      "     |          sub-estimator of a meta-estimator, e.g. used inside a\n",
      "     |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      sample_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``sample_weight`` parameter in ``score``.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          The updated object.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  __annotations__ = {'_parameter_constraints': <class 'dict'>}\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from _BaseNB:\n",
      "     |  \n",
      "     |  predict(self, X)\n",
      "     |      Perform classification on an array of test vectors X.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like of shape (n_samples, n_features)\n",
      "     |          The input samples.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      C : ndarray of shape (n_samples,)\n",
      "     |          Predicted target values for X.\n",
      "     |  \n",
      "     |  predict_joint_log_proba(self, X)\n",
      "     |      Return joint log probability estimates for the test vector X.\n",
      "     |      \n",
      "     |      For each row x of X and class y, the joint log probability is given by\n",
      "     |      ``log P(x, y) = log P(y) + log P(x|y),``\n",
      "     |      where ``log P(y)`` is the class prior probability and ``log P(x|y)`` is\n",
      "     |      the class-conditional probability.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like of shape (n_samples, n_features)\n",
      "     |          The input samples.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      C : ndarray of shape (n_samples, n_classes)\n",
      "     |          Returns the joint log-probability of the samples for each class in\n",
      "     |          the model. The columns correspond to the classes in sorted\n",
      "     |          order, as they appear in the attribute :term:`classes_`.\n",
      "     |  \n",
      "     |  predict_log_proba(self, X)\n",
      "     |      Return log-probability estimates for the test vector X.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like of shape (n_samples, n_features)\n",
      "     |          The input samples.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      C : array-like of shape (n_samples, n_classes)\n",
      "     |          Returns the log-probability of the samples for each class in\n",
      "     |          the model. The columns correspond to the classes in sorted\n",
      "     |          order, as they appear in the attribute :term:`classes_`.\n",
      "     |  \n",
      "     |  predict_proba(self, X)\n",
      "     |      Return probability estimates for the test vector X.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like of shape (n_samples, n_features)\n",
      "     |          The input samples.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      C : array-like of shape (n_samples, n_classes)\n",
      "     |          Returns the probability of the samples for each class in\n",
      "     |          the model. The columns correspond to the classes in sorted\n",
      "     |          order, as they appear in the attribute :term:`classes_`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.base.ClassifierMixin:\n",
      "     |  \n",
      "     |  score(self, X, y, sample_weight=None)\n",
      "     |      Return the mean accuracy on the given test data and labels.\n",
      "     |      \n",
      "     |      In multi-label classification, this is the subset accuracy\n",
      "     |      which is a harsh metric since you require for each sample that\n",
      "     |      each label set be correctly predicted.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like of shape (n_samples, n_features)\n",
      "     |          Test samples.\n",
      "     |      \n",
      "     |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      "     |          True labels for `X`.\n",
      "     |      \n",
      "     |      sample_weight : array-like of shape (n_samples,), default=None\n",
      "     |          Sample weights.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      score : float\n",
      "     |          Mean accuracy of ``self.predict(X)`` w.r.t. `y`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from sklearn.base.ClassifierMixin:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.base.BaseEstimator:\n",
      "     |  \n",
      "     |  __getstate__(self)\n",
      "     |  \n",
      "     |  __repr__(self, N_CHAR_MAX=700)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __setstate__(self, state)\n",
      "     |  \n",
      "     |  __sklearn_clone__(self)\n",
      "     |  \n",
      "     |  get_params(self, deep=True)\n",
      "     |      Get parameters for this estimator.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      deep : bool, default=True\n",
      "     |          If True, will return the parameters for this estimator and\n",
      "     |          contained subobjects that are estimators.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      params : dict\n",
      "     |          Parameter names mapped to their values.\n",
      "     |  \n",
      "     |  set_params(self, **params)\n",
      "     |      Set the parameters of this estimator.\n",
      "     |      \n",
      "     |      The method works on simple estimators as well as on nested objects\n",
      "     |      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n",
      "     |      parameters of the form ``<component>__<parameter>`` so that it's\n",
      "     |      possible to update each component of a nested object.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      **params : dict\n",
      "     |          Estimator parameters.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : estimator instance\n",
      "     |          Estimator instance.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
      "     |  \n",
      "     |  get_metadata_routing(self)\n",
      "     |      Get metadata routing of this object.\n",
      "     |      \n",
      "     |      Please check :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      routing : MetadataRequest\n",
      "     |          A :class:`~sklearn.utils.metadata_routing.MetadataRequest` encapsulating\n",
      "     |          routing information.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
      "     |  \n",
      "     |  __init_subclass__(**kwargs) from abc.ABCMeta\n",
      "     |      Set the ``set_{method}_request`` methods.\n",
      "     |      \n",
      "     |      This uses PEP-487 [1]_ to set the ``set_{method}_request`` methods. It\n",
      "     |      looks for the information available in the set default values which are\n",
      "     |      set using ``__metadata_request__*`` class attributes, or inferred\n",
      "     |      from method signatures.\n",
      "     |      \n",
      "     |      The ``__metadata_request__*`` class attributes are used when a method\n",
      "     |      does not explicitly accept a metadata through its arguments or if the\n",
      "     |      developer would like to specify a request value for those metadata\n",
      "     |      which are different from the default ``None``.\n",
      "     |      \n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      .. [1] https://www.python.org/dev/peps/pep-0487\n",
      "    \n",
      "    class ComplementNB(_BaseDiscreteNB)\n",
      "     |  ComplementNB(*, alpha=1.0, force_alpha=True, fit_prior=True, class_prior=None, norm=False)\n",
      "     |  \n",
      "     |  The Complement Naive Bayes classifier described in Rennie et al. (2003).\n",
      "     |  \n",
      "     |  The Complement Naive Bayes classifier was designed to correct the \"severe\n",
      "     |  assumptions\" made by the standard Multinomial Naive Bayes classifier. It is\n",
      "     |  particularly suited for imbalanced data sets.\n",
      "     |  \n",
      "     |  Read more in the :ref:`User Guide <complement_naive_bayes>`.\n",
      "     |  \n",
      "     |  .. versionadded:: 0.20\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  alpha : float or array-like of shape (n_features,), default=1.0\n",
      "     |      Additive (Laplace/Lidstone) smoothing parameter\n",
      "     |      (set alpha=0 and force_alpha=True, for no smoothing).\n",
      "     |  \n",
      "     |  force_alpha : bool, default=True\n",
      "     |      If False and alpha is less than 1e-10, it will set alpha to\n",
      "     |      1e-10. If True, alpha will remain unchanged. This may cause\n",
      "     |      numerical errors if alpha is too close to 0.\n",
      "     |  \n",
      "     |      .. versionadded:: 1.2\n",
      "     |      .. versionchanged:: 1.4\n",
      "     |         The default value of `force_alpha` changed to `True`.\n",
      "     |  \n",
      "     |  fit_prior : bool, default=True\n",
      "     |      Only used in edge case with a single class in the training set.\n",
      "     |  \n",
      "     |  class_prior : array-like of shape (n_classes,), default=None\n",
      "     |      Prior probabilities of the classes. Not used.\n",
      "     |  \n",
      "     |  norm : bool, default=False\n",
      "     |      Whether or not a second normalization of the weights is performed. The\n",
      "     |      default behavior mirrors the implementations found in Mahout and Weka,\n",
      "     |      which do not follow the full algorithm described in Table 9 of the\n",
      "     |      paper.\n",
      "     |  \n",
      "     |  Attributes\n",
      "     |  ----------\n",
      "     |  class_count_ : ndarray of shape (n_classes,)\n",
      "     |      Number of samples encountered for each class during fitting. This\n",
      "     |      value is weighted by the sample weight when provided.\n",
      "     |  \n",
      "     |  class_log_prior_ : ndarray of shape (n_classes,)\n",
      "     |      Smoothed empirical log probability for each class. Only used in edge\n",
      "     |      case with a single class in the training set.\n",
      "     |  \n",
      "     |  classes_ : ndarray of shape (n_classes,)\n",
      "     |      Class labels known to the classifier\n",
      "     |  \n",
      "     |  feature_all_ : ndarray of shape (n_features,)\n",
      "     |      Number of samples encountered for each feature during fitting. This\n",
      "     |      value is weighted by the sample weight when provided.\n",
      "     |  \n",
      "     |  feature_count_ : ndarray of shape (n_classes, n_features)\n",
      "     |      Number of samples encountered for each (class, feature) during fitting.\n",
      "     |      This value is weighted by the sample weight when provided.\n",
      "     |  \n",
      "     |  feature_log_prob_ : ndarray of shape (n_classes, n_features)\n",
      "     |      Empirical weights for class complements.\n",
      "     |  \n",
      "     |  n_features_in_ : int\n",
      "     |      Number of features seen during :term:`fit`.\n",
      "     |  \n",
      "     |      .. versionadded:: 0.24\n",
      "     |  \n",
      "     |  feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
      "     |      Names of features seen during :term:`fit`. Defined only when `X`\n",
      "     |      has feature names that are all strings.\n",
      "     |  \n",
      "     |      .. versionadded:: 1.0\n",
      "     |  \n",
      "     |  See Also\n",
      "     |  --------\n",
      "     |  BernoulliNB : Naive Bayes classifier for multivariate Bernoulli models.\n",
      "     |  CategoricalNB : Naive Bayes classifier for categorical features.\n",
      "     |  GaussianNB : Gaussian Naive Bayes.\n",
      "     |  MultinomialNB : Naive Bayes classifier for multinomial models.\n",
      "     |  \n",
      "     |  References\n",
      "     |  ----------\n",
      "     |  Rennie, J. D., Shih, L., Teevan, J., & Karger, D. R. (2003).\n",
      "     |  Tackling the poor assumptions of naive bayes text classifiers. In ICML\n",
      "     |  (Vol. 3, pp. 616-623).\n",
      "     |  https://people.csail.mit.edu/jrennie/papers/icml03-nb.pdf\n",
      "     |  \n",
      "     |  Examples\n",
      "     |  --------\n",
      "     |  >>> import numpy as np\n",
      "     |  >>> rng = np.random.RandomState(1)\n",
      "     |  >>> X = rng.randint(5, size=(6, 100))\n",
      "     |  >>> y = np.array([1, 2, 3, 4, 5, 6])\n",
      "     |  >>> from sklearn.naive_bayes import ComplementNB\n",
      "     |  >>> clf = ComplementNB()\n",
      "     |  >>> clf.fit(X, y)\n",
      "     |  ComplementNB()\n",
      "     |  >>> print(clf.predict(X[2:3]))\n",
      "     |  [3]\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      ComplementNB\n",
      "     |      _BaseDiscreteNB\n",
      "     |      _BaseNB\n",
      "     |      sklearn.base.ClassifierMixin\n",
      "     |      sklearn.base.BaseEstimator\n",
      "     |      sklearn.utils._estimator_html_repr._HTMLDocumentationLinkMixin\n",
      "     |      sklearn.utils._metadata_requests._MetadataRequester\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, *, alpha=1.0, force_alpha=True, fit_prior=True, class_prior=None, norm=False)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __sklearn_tags__(self)\n",
      "     |  \n",
      "     |  set_fit_request(self: sklearn.naive_bayes.ComplementNB, *, sample_weight: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.naive_bayes.ComplementNB\n",
      "     |      Request metadata passed to the ``fit`` method.\n",
      "     |      \n",
      "     |      Note that this method is only relevant if\n",
      "     |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
      "     |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |      \n",
      "     |      The options for each parameter are:\n",
      "     |      \n",
      "     |      - ``True``: metadata is requested, and passed to ``fit`` if provided. The request is ignored if metadata is not provided.\n",
      "     |      \n",
      "     |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``fit``.\n",
      "     |      \n",
      "     |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
      "     |      \n",
      "     |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
      "     |      \n",
      "     |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
      "     |      existing request. This allows you to change the request for some\n",
      "     |      parameters and not others.\n",
      "     |      \n",
      "     |      .. versionadded:: 1.3\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |          This method is only relevant if this estimator is used as a\n",
      "     |          sub-estimator of a meta-estimator, e.g. used inside a\n",
      "     |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      sample_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``sample_weight`` parameter in ``fit``.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          The updated object.\n",
      "     |  \n",
      "     |  set_partial_fit_request(self: sklearn.naive_bayes.ComplementNB, *, classes: Union[bool, NoneType, str] = '$UNCHANGED$', sample_weight: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.naive_bayes.ComplementNB\n",
      "     |      Request metadata passed to the ``partial_fit`` method.\n",
      "     |      \n",
      "     |      Note that this method is only relevant if\n",
      "     |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
      "     |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |      \n",
      "     |      The options for each parameter are:\n",
      "     |      \n",
      "     |      - ``True``: metadata is requested, and passed to ``partial_fit`` if provided. The request is ignored if metadata is not provided.\n",
      "     |      \n",
      "     |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``partial_fit``.\n",
      "     |      \n",
      "     |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
      "     |      \n",
      "     |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
      "     |      \n",
      "     |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
      "     |      existing request. This allows you to change the request for some\n",
      "     |      parameters and not others.\n",
      "     |      \n",
      "     |      .. versionadded:: 1.3\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |          This method is only relevant if this estimator is used as a\n",
      "     |          sub-estimator of a meta-estimator, e.g. used inside a\n",
      "     |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      classes : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``classes`` parameter in ``partial_fit``.\n",
      "     |      \n",
      "     |      sample_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``sample_weight`` parameter in ``partial_fit``.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          The updated object.\n",
      "     |  \n",
      "     |  set_score_request(self: sklearn.naive_bayes.ComplementNB, *, sample_weight: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.naive_bayes.ComplementNB\n",
      "     |      Request metadata passed to the ``score`` method.\n",
      "     |      \n",
      "     |      Note that this method is only relevant if\n",
      "     |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
      "     |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |      \n",
      "     |      The options for each parameter are:\n",
      "     |      \n",
      "     |      - ``True``: metadata is requested, and passed to ``score`` if provided. The request is ignored if metadata is not provided.\n",
      "     |      \n",
      "     |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``score``.\n",
      "     |      \n",
      "     |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
      "     |      \n",
      "     |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
      "     |      \n",
      "     |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
      "     |      existing request. This allows you to change the request for some\n",
      "     |      parameters and not others.\n",
      "     |      \n",
      "     |      .. versionadded:: 1.3\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |          This method is only relevant if this estimator is used as a\n",
      "     |          sub-estimator of a meta-estimator, e.g. used inside a\n",
      "     |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      sample_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``sample_weight`` parameter in ``score``.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          The updated object.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  __annotations__ = {'_parameter_constraints': <class 'dict'>}\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from _BaseDiscreteNB:\n",
      "     |  \n",
      "     |  fit(self, X, y, sample_weight=None)\n",
      "     |      Fit Naive Bayes classifier according to X, y.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      "     |          Training vectors, where `n_samples` is the number of samples and\n",
      "     |          `n_features` is the number of features.\n",
      "     |      \n",
      "     |      y : array-like of shape (n_samples,)\n",
      "     |          Target values.\n",
      "     |      \n",
      "     |      sample_weight : array-like of shape (n_samples,), default=None\n",
      "     |          Weights applied to individual samples (1. for unweighted).\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          Returns the instance itself.\n",
      "     |  \n",
      "     |  partial_fit(self, X, y, classes=None, sample_weight=None)\n",
      "     |      Incremental fit on a batch of samples.\n",
      "     |      \n",
      "     |      This method is expected to be called several times consecutively\n",
      "     |      on different chunks of a dataset so as to implement out-of-core\n",
      "     |      or online learning.\n",
      "     |      \n",
      "     |      This is especially useful when the whole dataset is too big to fit in\n",
      "     |      memory at once.\n",
      "     |      \n",
      "     |      This method has some performance overhead hence it is better to call\n",
      "     |      partial_fit on chunks of data that are as large as possible\n",
      "     |      (as long as fitting in the memory budget) to hide the overhead.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      "     |          Training vectors, where `n_samples` is the number of samples and\n",
      "     |          `n_features` is the number of features.\n",
      "     |      \n",
      "     |      y : array-like of shape (n_samples,)\n",
      "     |          Target values.\n",
      "     |      \n",
      "     |      classes : array-like of shape (n_classes,), default=None\n",
      "     |          List of all the classes that can possibly appear in the y vector.\n",
      "     |      \n",
      "     |          Must be provided at the first call to partial_fit, can be omitted\n",
      "     |          in subsequent calls.\n",
      "     |      \n",
      "     |      sample_weight : array-like of shape (n_samples,), default=None\n",
      "     |          Weights applied to individual samples (1. for unweighted).\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          Returns the instance itself.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from _BaseNB:\n",
      "     |  \n",
      "     |  predict(self, X)\n",
      "     |      Perform classification on an array of test vectors X.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like of shape (n_samples, n_features)\n",
      "     |          The input samples.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      C : ndarray of shape (n_samples,)\n",
      "     |          Predicted target values for X.\n",
      "     |  \n",
      "     |  predict_joint_log_proba(self, X)\n",
      "     |      Return joint log probability estimates for the test vector X.\n",
      "     |      \n",
      "     |      For each row x of X and class y, the joint log probability is given by\n",
      "     |      ``log P(x, y) = log P(y) + log P(x|y),``\n",
      "     |      where ``log P(y)`` is the class prior probability and ``log P(x|y)`` is\n",
      "     |      the class-conditional probability.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like of shape (n_samples, n_features)\n",
      "     |          The input samples.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      C : ndarray of shape (n_samples, n_classes)\n",
      "     |          Returns the joint log-probability of the samples for each class in\n",
      "     |          the model. The columns correspond to the classes in sorted\n",
      "     |          order, as they appear in the attribute :term:`classes_`.\n",
      "     |  \n",
      "     |  predict_log_proba(self, X)\n",
      "     |      Return log-probability estimates for the test vector X.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like of shape (n_samples, n_features)\n",
      "     |          The input samples.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      C : array-like of shape (n_samples, n_classes)\n",
      "     |          Returns the log-probability of the samples for each class in\n",
      "     |          the model. The columns correspond to the classes in sorted\n",
      "     |          order, as they appear in the attribute :term:`classes_`.\n",
      "     |  \n",
      "     |  predict_proba(self, X)\n",
      "     |      Return probability estimates for the test vector X.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like of shape (n_samples, n_features)\n",
      "     |          The input samples.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      C : array-like of shape (n_samples, n_classes)\n",
      "     |          Returns the probability of the samples for each class in\n",
      "     |          the model. The columns correspond to the classes in sorted\n",
      "     |          order, as they appear in the attribute :term:`classes_`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.base.ClassifierMixin:\n",
      "     |  \n",
      "     |  score(self, X, y, sample_weight=None)\n",
      "     |      Return the mean accuracy on the given test data and labels.\n",
      "     |      \n",
      "     |      In multi-label classification, this is the subset accuracy\n",
      "     |      which is a harsh metric since you require for each sample that\n",
      "     |      each label set be correctly predicted.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like of shape (n_samples, n_features)\n",
      "     |          Test samples.\n",
      "     |      \n",
      "     |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      "     |          True labels for `X`.\n",
      "     |      \n",
      "     |      sample_weight : array-like of shape (n_samples,), default=None\n",
      "     |          Sample weights.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      score : float\n",
      "     |          Mean accuracy of ``self.predict(X)`` w.r.t. `y`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from sklearn.base.ClassifierMixin:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.base.BaseEstimator:\n",
      "     |  \n",
      "     |  __getstate__(self)\n",
      "     |  \n",
      "     |  __repr__(self, N_CHAR_MAX=700)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __setstate__(self, state)\n",
      "     |  \n",
      "     |  __sklearn_clone__(self)\n",
      "     |  \n",
      "     |  get_params(self, deep=True)\n",
      "     |      Get parameters for this estimator.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      deep : bool, default=True\n",
      "     |          If True, will return the parameters for this estimator and\n",
      "     |          contained subobjects that are estimators.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      params : dict\n",
      "     |          Parameter names mapped to their values.\n",
      "     |  \n",
      "     |  set_params(self, **params)\n",
      "     |      Set the parameters of this estimator.\n",
      "     |      \n",
      "     |      The method works on simple estimators as well as on nested objects\n",
      "     |      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n",
      "     |      parameters of the form ``<component>__<parameter>`` so that it's\n",
      "     |      possible to update each component of a nested object.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      **params : dict\n",
      "     |          Estimator parameters.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : estimator instance\n",
      "     |          Estimator instance.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
      "     |  \n",
      "     |  get_metadata_routing(self)\n",
      "     |      Get metadata routing of this object.\n",
      "     |      \n",
      "     |      Please check :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      routing : MetadataRequest\n",
      "     |          A :class:`~sklearn.utils.metadata_routing.MetadataRequest` encapsulating\n",
      "     |          routing information.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
      "     |  \n",
      "     |  __init_subclass__(**kwargs) from abc.ABCMeta\n",
      "     |      Set the ``set_{method}_request`` methods.\n",
      "     |      \n",
      "     |      This uses PEP-487 [1]_ to set the ``set_{method}_request`` methods. It\n",
      "     |      looks for the information available in the set default values which are\n",
      "     |      set using ``__metadata_request__*`` class attributes, or inferred\n",
      "     |      from method signatures.\n",
      "     |      \n",
      "     |      The ``__metadata_request__*`` class attributes are used when a method\n",
      "     |      does not explicitly accept a metadata through its arguments or if the\n",
      "     |      developer would like to specify a request value for those metadata\n",
      "     |      which are different from the default ``None``.\n",
      "     |      \n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      .. [1] https://www.python.org/dev/peps/pep-0487\n",
      "    \n",
      "    class GaussianNB(_BaseNB)\n",
      "     |  GaussianNB(*, priors=None, var_smoothing=1e-09)\n",
      "     |  \n",
      "     |  Gaussian Naive Bayes (GaussianNB).\n",
      "     |  \n",
      "     |  Can perform online updates to model parameters via :meth:`partial_fit`.\n",
      "     |  For details on algorithm used to update feature means and variance online,\n",
      "     |  see `Stanford CS tech report STAN-CS-79-773 by Chan, Golub, and LeVeque\n",
      "     |  <http://i.stanford.edu/pub/cstr/reports/cs/tr/79/773/CS-TR-79-773.pdf>`_.\n",
      "     |  \n",
      "     |  Read more in the :ref:`User Guide <gaussian_naive_bayes>`.\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  priors : array-like of shape (n_classes,), default=None\n",
      "     |      Prior probabilities of the classes. If specified, the priors are not\n",
      "     |      adjusted according to the data.\n",
      "     |  \n",
      "     |  var_smoothing : float, default=1e-9\n",
      "     |      Portion of the largest variance of all features that is added to\n",
      "     |      variances for calculation stability.\n",
      "     |  \n",
      "     |      .. versionadded:: 0.20\n",
      "     |  \n",
      "     |  Attributes\n",
      "     |  ----------\n",
      "     |  class_count_ : ndarray of shape (n_classes,)\n",
      "     |      number of training samples observed in each class.\n",
      "     |  \n",
      "     |  class_prior_ : ndarray of shape (n_classes,)\n",
      "     |      probability of each class.\n",
      "     |  \n",
      "     |  classes_ : ndarray of shape (n_classes,)\n",
      "     |      class labels known to the classifier.\n",
      "     |  \n",
      "     |  epsilon_ : float\n",
      "     |      absolute additive value to variances.\n",
      "     |  \n",
      "     |  n_features_in_ : int\n",
      "     |      Number of features seen during :term:`fit`.\n",
      "     |  \n",
      "     |      .. versionadded:: 0.24\n",
      "     |  \n",
      "     |  feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
      "     |      Names of features seen during :term:`fit`. Defined only when `X`\n",
      "     |      has feature names that are all strings.\n",
      "     |  \n",
      "     |      .. versionadded:: 1.0\n",
      "     |  \n",
      "     |  var_ : ndarray of shape (n_classes, n_features)\n",
      "     |      Variance of each feature per class.\n",
      "     |  \n",
      "     |      .. versionadded:: 1.0\n",
      "     |  \n",
      "     |  theta_ : ndarray of shape (n_classes, n_features)\n",
      "     |      mean of each feature per class.\n",
      "     |  \n",
      "     |  See Also\n",
      "     |  --------\n",
      "     |  BernoulliNB : Naive Bayes classifier for multivariate Bernoulli models.\n",
      "     |  CategoricalNB : Naive Bayes classifier for categorical features.\n",
      "     |  ComplementNB : Complement Naive Bayes classifier.\n",
      "     |  MultinomialNB : Naive Bayes classifier for multinomial models.\n",
      "     |  \n",
      "     |  Examples\n",
      "     |  --------\n",
      "     |  >>> import numpy as np\n",
      "     |  >>> X = np.array([[-1, -1], [-2, -1], [-3, -2], [1, 1], [2, 1], [3, 2]])\n",
      "     |  >>> Y = np.array([1, 1, 1, 2, 2, 2])\n",
      "     |  >>> from sklearn.naive_bayes import GaussianNB\n",
      "     |  >>> clf = GaussianNB()\n",
      "     |  >>> clf.fit(X, Y)\n",
      "     |  GaussianNB()\n",
      "     |  >>> print(clf.predict([[-0.8, -1]]))\n",
      "     |  [1]\n",
      "     |  >>> clf_pf = GaussianNB()\n",
      "     |  >>> clf_pf.partial_fit(X, Y, np.unique(Y))\n",
      "     |  GaussianNB()\n",
      "     |  >>> print(clf_pf.predict([[-0.8, -1]]))\n",
      "     |  [1]\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      GaussianNB\n",
      "     |      _BaseNB\n",
      "     |      sklearn.base.ClassifierMixin\n",
      "     |      sklearn.base.BaseEstimator\n",
      "     |      sklearn.utils._estimator_html_repr._HTMLDocumentationLinkMixin\n",
      "     |      sklearn.utils._metadata_requests._MetadataRequester\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, *, priors=None, var_smoothing=1e-09)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  fit(self, X, y, sample_weight=None)\n",
      "     |      Fit Gaussian Naive Bayes according to X, y.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like of shape (n_samples, n_features)\n",
      "     |          Training vectors, where `n_samples` is the number of samples\n",
      "     |          and `n_features` is the number of features.\n",
      "     |      \n",
      "     |      y : array-like of shape (n_samples,)\n",
      "     |          Target values.\n",
      "     |      \n",
      "     |      sample_weight : array-like of shape (n_samples,), default=None\n",
      "     |          Weights applied to individual samples (1. for unweighted).\n",
      "     |      \n",
      "     |          .. versionadded:: 0.17\n",
      "     |             Gaussian Naive Bayes supports fitting with *sample_weight*.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          Returns the instance itself.\n",
      "     |  \n",
      "     |  partial_fit(self, X, y, classes=None, sample_weight=None)\n",
      "     |      Incremental fit on a batch of samples.\n",
      "     |      \n",
      "     |      This method is expected to be called several times consecutively\n",
      "     |      on different chunks of a dataset so as to implement out-of-core\n",
      "     |      or online learning.\n",
      "     |      \n",
      "     |      This is especially useful when the whole dataset is too big to fit in\n",
      "     |      memory at once.\n",
      "     |      \n",
      "     |      This method has some performance and numerical stability overhead,\n",
      "     |      hence it is better to call partial_fit on chunks of data that are\n",
      "     |      as large as possible (as long as fitting in the memory budget) to\n",
      "     |      hide the overhead.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like of shape (n_samples, n_features)\n",
      "     |          Training vectors, where `n_samples` is the number of samples and\n",
      "     |          `n_features` is the number of features.\n",
      "     |      \n",
      "     |      y : array-like of shape (n_samples,)\n",
      "     |          Target values.\n",
      "     |      \n",
      "     |      classes : array-like of shape (n_classes,), default=None\n",
      "     |          List of all the classes that can possibly appear in the y vector.\n",
      "     |      \n",
      "     |          Must be provided at the first call to partial_fit, can be omitted\n",
      "     |          in subsequent calls.\n",
      "     |      \n",
      "     |      sample_weight : array-like of shape (n_samples,), default=None\n",
      "     |          Weights applied to individual samples (1. for unweighted).\n",
      "     |      \n",
      "     |          .. versionadded:: 0.17\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          Returns the instance itself.\n",
      "     |  \n",
      "     |  set_fit_request(self: sklearn.naive_bayes.GaussianNB, *, sample_weight: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.naive_bayes.GaussianNB\n",
      "     |      Request metadata passed to the ``fit`` method.\n",
      "     |      \n",
      "     |      Note that this method is only relevant if\n",
      "     |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
      "     |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |      \n",
      "     |      The options for each parameter are:\n",
      "     |      \n",
      "     |      - ``True``: metadata is requested, and passed to ``fit`` if provided. The request is ignored if metadata is not provided.\n",
      "     |      \n",
      "     |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``fit``.\n",
      "     |      \n",
      "     |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
      "     |      \n",
      "     |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
      "     |      \n",
      "     |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
      "     |      existing request. This allows you to change the request for some\n",
      "     |      parameters and not others.\n",
      "     |      \n",
      "     |      .. versionadded:: 1.3\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |          This method is only relevant if this estimator is used as a\n",
      "     |          sub-estimator of a meta-estimator, e.g. used inside a\n",
      "     |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      sample_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``sample_weight`` parameter in ``fit``.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          The updated object.\n",
      "     |  \n",
      "     |  set_partial_fit_request(self: sklearn.naive_bayes.GaussianNB, *, classes: Union[bool, NoneType, str] = '$UNCHANGED$', sample_weight: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.naive_bayes.GaussianNB\n",
      "     |      Request metadata passed to the ``partial_fit`` method.\n",
      "     |      \n",
      "     |      Note that this method is only relevant if\n",
      "     |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
      "     |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |      \n",
      "     |      The options for each parameter are:\n",
      "     |      \n",
      "     |      - ``True``: metadata is requested, and passed to ``partial_fit`` if provided. The request is ignored if metadata is not provided.\n",
      "     |      \n",
      "     |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``partial_fit``.\n",
      "     |      \n",
      "     |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
      "     |      \n",
      "     |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
      "     |      \n",
      "     |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
      "     |      existing request. This allows you to change the request for some\n",
      "     |      parameters and not others.\n",
      "     |      \n",
      "     |      .. versionadded:: 1.3\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |          This method is only relevant if this estimator is used as a\n",
      "     |          sub-estimator of a meta-estimator, e.g. used inside a\n",
      "     |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      classes : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``classes`` parameter in ``partial_fit``.\n",
      "     |      \n",
      "     |      sample_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``sample_weight`` parameter in ``partial_fit``.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          The updated object.\n",
      "     |  \n",
      "     |  set_score_request(self: sklearn.naive_bayes.GaussianNB, *, sample_weight: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.naive_bayes.GaussianNB\n",
      "     |      Request metadata passed to the ``score`` method.\n",
      "     |      \n",
      "     |      Note that this method is only relevant if\n",
      "     |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
      "     |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |      \n",
      "     |      The options for each parameter are:\n",
      "     |      \n",
      "     |      - ``True``: metadata is requested, and passed to ``score`` if provided. The request is ignored if metadata is not provided.\n",
      "     |      \n",
      "     |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``score``.\n",
      "     |      \n",
      "     |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
      "     |      \n",
      "     |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
      "     |      \n",
      "     |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
      "     |      existing request. This allows you to change the request for some\n",
      "     |      parameters and not others.\n",
      "     |      \n",
      "     |      .. versionadded:: 1.3\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |          This method is only relevant if this estimator is used as a\n",
      "     |          sub-estimator of a meta-estimator, e.g. used inside a\n",
      "     |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      sample_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``sample_weight`` parameter in ``score``.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          The updated object.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  __annotations__ = {'_parameter_constraints': <class 'dict'>}\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from _BaseNB:\n",
      "     |  \n",
      "     |  predict(self, X)\n",
      "     |      Perform classification on an array of test vectors X.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like of shape (n_samples, n_features)\n",
      "     |          The input samples.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      C : ndarray of shape (n_samples,)\n",
      "     |          Predicted target values for X.\n",
      "     |  \n",
      "     |  predict_joint_log_proba(self, X)\n",
      "     |      Return joint log probability estimates for the test vector X.\n",
      "     |      \n",
      "     |      For each row x of X and class y, the joint log probability is given by\n",
      "     |      ``log P(x, y) = log P(y) + log P(x|y),``\n",
      "     |      where ``log P(y)`` is the class prior probability and ``log P(x|y)`` is\n",
      "     |      the class-conditional probability.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like of shape (n_samples, n_features)\n",
      "     |          The input samples.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      C : ndarray of shape (n_samples, n_classes)\n",
      "     |          Returns the joint log-probability of the samples for each class in\n",
      "     |          the model. The columns correspond to the classes in sorted\n",
      "     |          order, as they appear in the attribute :term:`classes_`.\n",
      "     |  \n",
      "     |  predict_log_proba(self, X)\n",
      "     |      Return log-probability estimates for the test vector X.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like of shape (n_samples, n_features)\n",
      "     |          The input samples.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      C : array-like of shape (n_samples, n_classes)\n",
      "     |          Returns the log-probability of the samples for each class in\n",
      "     |          the model. The columns correspond to the classes in sorted\n",
      "     |          order, as they appear in the attribute :term:`classes_`.\n",
      "     |  \n",
      "     |  predict_proba(self, X)\n",
      "     |      Return probability estimates for the test vector X.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like of shape (n_samples, n_features)\n",
      "     |          The input samples.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      C : array-like of shape (n_samples, n_classes)\n",
      "     |          Returns the probability of the samples for each class in\n",
      "     |          the model. The columns correspond to the classes in sorted\n",
      "     |          order, as they appear in the attribute :term:`classes_`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.base.ClassifierMixin:\n",
      "     |  \n",
      "     |  __sklearn_tags__(self)\n",
      "     |  \n",
      "     |  score(self, X, y, sample_weight=None)\n",
      "     |      Return the mean accuracy on the given test data and labels.\n",
      "     |      \n",
      "     |      In multi-label classification, this is the subset accuracy\n",
      "     |      which is a harsh metric since you require for each sample that\n",
      "     |      each label set be correctly predicted.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like of shape (n_samples, n_features)\n",
      "     |          Test samples.\n",
      "     |      \n",
      "     |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      "     |          True labels for `X`.\n",
      "     |      \n",
      "     |      sample_weight : array-like of shape (n_samples,), default=None\n",
      "     |          Sample weights.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      score : float\n",
      "     |          Mean accuracy of ``self.predict(X)`` w.r.t. `y`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from sklearn.base.ClassifierMixin:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.base.BaseEstimator:\n",
      "     |  \n",
      "     |  __getstate__(self)\n",
      "     |  \n",
      "     |  __repr__(self, N_CHAR_MAX=700)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __setstate__(self, state)\n",
      "     |  \n",
      "     |  __sklearn_clone__(self)\n",
      "     |  \n",
      "     |  get_params(self, deep=True)\n",
      "     |      Get parameters for this estimator.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      deep : bool, default=True\n",
      "     |          If True, will return the parameters for this estimator and\n",
      "     |          contained subobjects that are estimators.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      params : dict\n",
      "     |          Parameter names mapped to their values.\n",
      "     |  \n",
      "     |  set_params(self, **params)\n",
      "     |      Set the parameters of this estimator.\n",
      "     |      \n",
      "     |      The method works on simple estimators as well as on nested objects\n",
      "     |      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n",
      "     |      parameters of the form ``<component>__<parameter>`` so that it's\n",
      "     |      possible to update each component of a nested object.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      **params : dict\n",
      "     |          Estimator parameters.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : estimator instance\n",
      "     |          Estimator instance.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
      "     |  \n",
      "     |  get_metadata_routing(self)\n",
      "     |      Get metadata routing of this object.\n",
      "     |      \n",
      "     |      Please check :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      routing : MetadataRequest\n",
      "     |          A :class:`~sklearn.utils.metadata_routing.MetadataRequest` encapsulating\n",
      "     |          routing information.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
      "     |  \n",
      "     |  __init_subclass__(**kwargs) from abc.ABCMeta\n",
      "     |      Set the ``set_{method}_request`` methods.\n",
      "     |      \n",
      "     |      This uses PEP-487 [1]_ to set the ``set_{method}_request`` methods. It\n",
      "     |      looks for the information available in the set default values which are\n",
      "     |      set using ``__metadata_request__*`` class attributes, or inferred\n",
      "     |      from method signatures.\n",
      "     |      \n",
      "     |      The ``__metadata_request__*`` class attributes are used when a method\n",
      "     |      does not explicitly accept a metadata through its arguments or if the\n",
      "     |      developer would like to specify a request value for those metadata\n",
      "     |      which are different from the default ``None``.\n",
      "     |      \n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      .. [1] https://www.python.org/dev/peps/pep-0487\n",
      "    \n",
      "    class MultinomialNB(_BaseDiscreteNB)\n",
      "     |  MultinomialNB(*, alpha=1.0, force_alpha=True, fit_prior=True, class_prior=None)\n",
      "     |  \n",
      "     |  Naive Bayes classifier for multinomial models.\n",
      "     |  \n",
      "     |  The multinomial Naive Bayes classifier is suitable for classification with\n",
      "     |  discrete features (e.g., word counts for text classification). The\n",
      "     |  multinomial distribution normally requires integer feature counts. However,\n",
      "     |  in practice, fractional counts such as tf-idf may also work.\n",
      "     |  \n",
      "     |  Read more in the :ref:`User Guide <multinomial_naive_bayes>`.\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  alpha : float or array-like of shape (n_features,), default=1.0\n",
      "     |      Additive (Laplace/Lidstone) smoothing parameter\n",
      "     |      (set alpha=0 and force_alpha=True, for no smoothing).\n",
      "     |  \n",
      "     |  force_alpha : bool, default=True\n",
      "     |      If False and alpha is less than 1e-10, it will set alpha to\n",
      "     |      1e-10. If True, alpha will remain unchanged. This may cause\n",
      "     |      numerical errors if alpha is too close to 0.\n",
      "     |  \n",
      "     |      .. versionadded:: 1.2\n",
      "     |      .. versionchanged:: 1.4\n",
      "     |         The default value of `force_alpha` changed to `True`.\n",
      "     |  \n",
      "     |  fit_prior : bool, default=True\n",
      "     |      Whether to learn class prior probabilities or not.\n",
      "     |      If false, a uniform prior will be used.\n",
      "     |  \n",
      "     |  class_prior : array-like of shape (n_classes,), default=None\n",
      "     |      Prior probabilities of the classes. If specified, the priors are not\n",
      "     |      adjusted according to the data.\n",
      "     |  \n",
      "     |  Attributes\n",
      "     |  ----------\n",
      "     |  class_count_ : ndarray of shape (n_classes,)\n",
      "     |      Number of samples encountered for each class during fitting. This\n",
      "     |      value is weighted by the sample weight when provided.\n",
      "     |  \n",
      "     |  class_log_prior_ : ndarray of shape (n_classes,)\n",
      "     |      Smoothed empirical log probability for each class.\n",
      "     |  \n",
      "     |  classes_ : ndarray of shape (n_classes,)\n",
      "     |      Class labels known to the classifier\n",
      "     |  \n",
      "     |  feature_count_ : ndarray of shape (n_classes, n_features)\n",
      "     |      Number of samples encountered for each (class, feature)\n",
      "     |      during fitting. This value is weighted by the sample weight when\n",
      "     |      provided.\n",
      "     |  \n",
      "     |  feature_log_prob_ : ndarray of shape (n_classes, n_features)\n",
      "     |      Empirical log probability of features\n",
      "     |      given a class, ``P(x_i|y)``.\n",
      "     |  \n",
      "     |  n_features_in_ : int\n",
      "     |      Number of features seen during :term:`fit`.\n",
      "     |  \n",
      "     |      .. versionadded:: 0.24\n",
      "     |  \n",
      "     |  feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
      "     |      Names of features seen during :term:`fit`. Defined only when `X`\n",
      "     |      has feature names that are all strings.\n",
      "     |  \n",
      "     |      .. versionadded:: 1.0\n",
      "     |  \n",
      "     |  See Also\n",
      "     |  --------\n",
      "     |  BernoulliNB : Naive Bayes classifier for multivariate Bernoulli models.\n",
      "     |  CategoricalNB : Naive Bayes classifier for categorical features.\n",
      "     |  ComplementNB : Complement Naive Bayes classifier.\n",
      "     |  GaussianNB : Gaussian Naive Bayes.\n",
      "     |  \n",
      "     |  References\n",
      "     |  ----------\n",
      "     |  C.D. Manning, P. Raghavan and H. Schuetze (2008). Introduction to\n",
      "     |  Information Retrieval. Cambridge University Press, pp. 234-265.\n",
      "     |  https://nlp.stanford.edu/IR-book/html/htmledition/naive-bayes-text-classification-1.html\n",
      "     |  \n",
      "     |  Examples\n",
      "     |  --------\n",
      "     |  >>> import numpy as np\n",
      "     |  >>> rng = np.random.RandomState(1)\n",
      "     |  >>> X = rng.randint(5, size=(6, 100))\n",
      "     |  >>> y = np.array([1, 2, 3, 4, 5, 6])\n",
      "     |  >>> from sklearn.naive_bayes import MultinomialNB\n",
      "     |  >>> clf = MultinomialNB()\n",
      "     |  >>> clf.fit(X, y)\n",
      "     |  MultinomialNB()\n",
      "     |  >>> print(clf.predict(X[2:3]))\n",
      "     |  [3]\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      MultinomialNB\n",
      "     |      _BaseDiscreteNB\n",
      "     |      _BaseNB\n",
      "     |      sklearn.base.ClassifierMixin\n",
      "     |      sklearn.base.BaseEstimator\n",
      "     |      sklearn.utils._estimator_html_repr._HTMLDocumentationLinkMixin\n",
      "     |      sklearn.utils._metadata_requests._MetadataRequester\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, *, alpha=1.0, force_alpha=True, fit_prior=True, class_prior=None)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __sklearn_tags__(self)\n",
      "     |  \n",
      "     |  set_fit_request(self: sklearn.naive_bayes.MultinomialNB, *, sample_weight: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.naive_bayes.MultinomialNB\n",
      "     |      Request metadata passed to the ``fit`` method.\n",
      "     |      \n",
      "     |      Note that this method is only relevant if\n",
      "     |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
      "     |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |      \n",
      "     |      The options for each parameter are:\n",
      "     |      \n",
      "     |      - ``True``: metadata is requested, and passed to ``fit`` if provided. The request is ignored if metadata is not provided.\n",
      "     |      \n",
      "     |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``fit``.\n",
      "     |      \n",
      "     |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
      "     |      \n",
      "     |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
      "     |      \n",
      "     |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
      "     |      existing request. This allows you to change the request for some\n",
      "     |      parameters and not others.\n",
      "     |      \n",
      "     |      .. versionadded:: 1.3\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |          This method is only relevant if this estimator is used as a\n",
      "     |          sub-estimator of a meta-estimator, e.g. used inside a\n",
      "     |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      sample_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``sample_weight`` parameter in ``fit``.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          The updated object.\n",
      "     |  \n",
      "     |  set_partial_fit_request(self: sklearn.naive_bayes.MultinomialNB, *, classes: Union[bool, NoneType, str] = '$UNCHANGED$', sample_weight: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.naive_bayes.MultinomialNB\n",
      "     |      Request metadata passed to the ``partial_fit`` method.\n",
      "     |      \n",
      "     |      Note that this method is only relevant if\n",
      "     |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
      "     |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |      \n",
      "     |      The options for each parameter are:\n",
      "     |      \n",
      "     |      - ``True``: metadata is requested, and passed to ``partial_fit`` if provided. The request is ignored if metadata is not provided.\n",
      "     |      \n",
      "     |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``partial_fit``.\n",
      "     |      \n",
      "     |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
      "     |      \n",
      "     |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
      "     |      \n",
      "     |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
      "     |      existing request. This allows you to change the request for some\n",
      "     |      parameters and not others.\n",
      "     |      \n",
      "     |      .. versionadded:: 1.3\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |          This method is only relevant if this estimator is used as a\n",
      "     |          sub-estimator of a meta-estimator, e.g. used inside a\n",
      "     |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      classes : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``classes`` parameter in ``partial_fit``.\n",
      "     |      \n",
      "     |      sample_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``sample_weight`` parameter in ``partial_fit``.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          The updated object.\n",
      "     |  \n",
      "     |  set_score_request(self: sklearn.naive_bayes.MultinomialNB, *, sample_weight: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.naive_bayes.MultinomialNB\n",
      "     |      Request metadata passed to the ``score`` method.\n",
      "     |      \n",
      "     |      Note that this method is only relevant if\n",
      "     |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
      "     |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |      \n",
      "     |      The options for each parameter are:\n",
      "     |      \n",
      "     |      - ``True``: metadata is requested, and passed to ``score`` if provided. The request is ignored if metadata is not provided.\n",
      "     |      \n",
      "     |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``score``.\n",
      "     |      \n",
      "     |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
      "     |      \n",
      "     |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
      "     |      \n",
      "     |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
      "     |      existing request. This allows you to change the request for some\n",
      "     |      parameters and not others.\n",
      "     |      \n",
      "     |      .. versionadded:: 1.3\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |          This method is only relevant if this estimator is used as a\n",
      "     |          sub-estimator of a meta-estimator, e.g. used inside a\n",
      "     |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      sample_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``sample_weight`` parameter in ``score``.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          The updated object.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  __annotations__ = {}\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from _BaseDiscreteNB:\n",
      "     |  \n",
      "     |  fit(self, X, y, sample_weight=None)\n",
      "     |      Fit Naive Bayes classifier according to X, y.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      "     |          Training vectors, where `n_samples` is the number of samples and\n",
      "     |          `n_features` is the number of features.\n",
      "     |      \n",
      "     |      y : array-like of shape (n_samples,)\n",
      "     |          Target values.\n",
      "     |      \n",
      "     |      sample_weight : array-like of shape (n_samples,), default=None\n",
      "     |          Weights applied to individual samples (1. for unweighted).\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          Returns the instance itself.\n",
      "     |  \n",
      "     |  partial_fit(self, X, y, classes=None, sample_weight=None)\n",
      "     |      Incremental fit on a batch of samples.\n",
      "     |      \n",
      "     |      This method is expected to be called several times consecutively\n",
      "     |      on different chunks of a dataset so as to implement out-of-core\n",
      "     |      or online learning.\n",
      "     |      \n",
      "     |      This is especially useful when the whole dataset is too big to fit in\n",
      "     |      memory at once.\n",
      "     |      \n",
      "     |      This method has some performance overhead hence it is better to call\n",
      "     |      partial_fit on chunks of data that are as large as possible\n",
      "     |      (as long as fitting in the memory budget) to hide the overhead.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      "     |          Training vectors, where `n_samples` is the number of samples and\n",
      "     |          `n_features` is the number of features.\n",
      "     |      \n",
      "     |      y : array-like of shape (n_samples,)\n",
      "     |          Target values.\n",
      "     |      \n",
      "     |      classes : array-like of shape (n_classes,), default=None\n",
      "     |          List of all the classes that can possibly appear in the y vector.\n",
      "     |      \n",
      "     |          Must be provided at the first call to partial_fit, can be omitted\n",
      "     |          in subsequent calls.\n",
      "     |      \n",
      "     |      sample_weight : array-like of shape (n_samples,), default=None\n",
      "     |          Weights applied to individual samples (1. for unweighted).\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          Returns the instance itself.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from _BaseNB:\n",
      "     |  \n",
      "     |  predict(self, X)\n",
      "     |      Perform classification on an array of test vectors X.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like of shape (n_samples, n_features)\n",
      "     |          The input samples.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      C : ndarray of shape (n_samples,)\n",
      "     |          Predicted target values for X.\n",
      "     |  \n",
      "     |  predict_joint_log_proba(self, X)\n",
      "     |      Return joint log probability estimates for the test vector X.\n",
      "     |      \n",
      "     |      For each row x of X and class y, the joint log probability is given by\n",
      "     |      ``log P(x, y) = log P(y) + log P(x|y),``\n",
      "     |      where ``log P(y)`` is the class prior probability and ``log P(x|y)`` is\n",
      "     |      the class-conditional probability.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like of shape (n_samples, n_features)\n",
      "     |          The input samples.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      C : ndarray of shape (n_samples, n_classes)\n",
      "     |          Returns the joint log-probability of the samples for each class in\n",
      "     |          the model. The columns correspond to the classes in sorted\n",
      "     |          order, as they appear in the attribute :term:`classes_`.\n",
      "     |  \n",
      "     |  predict_log_proba(self, X)\n",
      "     |      Return log-probability estimates for the test vector X.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like of shape (n_samples, n_features)\n",
      "     |          The input samples.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      C : array-like of shape (n_samples, n_classes)\n",
      "     |          Returns the log-probability of the samples for each class in\n",
      "     |          the model. The columns correspond to the classes in sorted\n",
      "     |          order, as they appear in the attribute :term:`classes_`.\n",
      "     |  \n",
      "     |  predict_proba(self, X)\n",
      "     |      Return probability estimates for the test vector X.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like of shape (n_samples, n_features)\n",
      "     |          The input samples.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      C : array-like of shape (n_samples, n_classes)\n",
      "     |          Returns the probability of the samples for each class in\n",
      "     |          the model. The columns correspond to the classes in sorted\n",
      "     |          order, as they appear in the attribute :term:`classes_`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.base.ClassifierMixin:\n",
      "     |  \n",
      "     |  score(self, X, y, sample_weight=None)\n",
      "     |      Return the mean accuracy on the given test data and labels.\n",
      "     |      \n",
      "     |      In multi-label classification, this is the subset accuracy\n",
      "     |      which is a harsh metric since you require for each sample that\n",
      "     |      each label set be correctly predicted.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like of shape (n_samples, n_features)\n",
      "     |          Test samples.\n",
      "     |      \n",
      "     |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      "     |          True labels for `X`.\n",
      "     |      \n",
      "     |      sample_weight : array-like of shape (n_samples,), default=None\n",
      "     |          Sample weights.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      score : float\n",
      "     |          Mean accuracy of ``self.predict(X)`` w.r.t. `y`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from sklearn.base.ClassifierMixin:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.base.BaseEstimator:\n",
      "     |  \n",
      "     |  __getstate__(self)\n",
      "     |  \n",
      "     |  __repr__(self, N_CHAR_MAX=700)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __setstate__(self, state)\n",
      "     |  \n",
      "     |  __sklearn_clone__(self)\n",
      "     |  \n",
      "     |  get_params(self, deep=True)\n",
      "     |      Get parameters for this estimator.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      deep : bool, default=True\n",
      "     |          If True, will return the parameters for this estimator and\n",
      "     |          contained subobjects that are estimators.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      params : dict\n",
      "     |          Parameter names mapped to their values.\n",
      "     |  \n",
      "     |  set_params(self, **params)\n",
      "     |      Set the parameters of this estimator.\n",
      "     |      \n",
      "     |      The method works on simple estimators as well as on nested objects\n",
      "     |      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n",
      "     |      parameters of the form ``<component>__<parameter>`` so that it's\n",
      "     |      possible to update each component of a nested object.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      **params : dict\n",
      "     |          Estimator parameters.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : estimator instance\n",
      "     |          Estimator instance.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
      "     |  \n",
      "     |  get_metadata_routing(self)\n",
      "     |      Get metadata routing of this object.\n",
      "     |      \n",
      "     |      Please check :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      routing : MetadataRequest\n",
      "     |          A :class:`~sklearn.utils.metadata_routing.MetadataRequest` encapsulating\n",
      "     |          routing information.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
      "     |  \n",
      "     |  __init_subclass__(**kwargs) from abc.ABCMeta\n",
      "     |      Set the ``set_{method}_request`` methods.\n",
      "     |      \n",
      "     |      This uses PEP-487 [1]_ to set the ``set_{method}_request`` methods. It\n",
      "     |      looks for the information available in the set default values which are\n",
      "     |      set using ``__metadata_request__*`` class attributes, or inferred\n",
      "     |      from method signatures.\n",
      "     |      \n",
      "     |      The ``__metadata_request__*`` class attributes are used when a method\n",
      "     |      does not explicitly accept a metadata through its arguments or if the\n",
      "     |      developer would like to specify a request value for those metadata\n",
      "     |      which are different from the default ``None``.\n",
      "     |      \n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      .. [1] https://www.python.org/dev/peps/pep-0487\n",
      "\n",
      "DATA\n",
      "    __all__ = ['BernoulliNB', 'GaussianNB', 'MultinomialNB', 'ComplementNB...\n",
      "\n",
      "FILE\n",
      "    c:\\users\\sailesh\\.conda\\envs\\mlt\\lib\\site-packages\\sklearn\\naive_bayes.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sklearn.naive_bayes\n",
    "help(sklearn.naive_bayes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "abdd3ed0-02f1-4d10-b280-563984c82cab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ABCMeta', 'BaseEstimator', 'BernoulliNB', 'CategoricalNB', 'ClassifierMixin', 'ComplementNB', 'GaussianNB', 'Integral', 'Interval', 'LabelBinarizer', 'MultinomialNB', 'Real', '_BaseDiscreteNB', '_BaseNB', '__all__', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__spec__', '_check_n_features', '_check_partial_fit_first_call', '_check_sample_weight', '_fit_context', 'abstractmethod', 'binarize', 'check_is_fitted', 'check_non_negative', 'label_binarize', 'logsumexp', 'np', 'safe_sparse_dot', 'validate_data', 'warnings']\n"
     ]
    }
   ],
   "source": [
    "import sklearn.naive_bayes\n",
    "print(dir(sklearn.naive_bayes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5f672f9-a0f5-4fe0-8a79-c6368858311a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ABCMeta', abc.ABCMeta),\n",
       " ('BaseEstimator', sklearn.base.BaseEstimator),\n",
       " ('BernoulliNB', sklearn.naive_bayes.BernoulliNB),\n",
       " ('CategoricalNB', sklearn.naive_bayes.CategoricalNB),\n",
       " ('ClassifierMixin', sklearn.base.ClassifierMixin),\n",
       " ('ComplementNB', sklearn.naive_bayes.ComplementNB),\n",
       " ('GaussianNB', sklearn.naive_bayes.GaussianNB),\n",
       " ('Integral', numbers.Integral),\n",
       " ('Interval', sklearn.utils._param_validation.Interval),\n",
       " ('LabelBinarizer', sklearn.preprocessing._label.LabelBinarizer),\n",
       " ('MultinomialNB', sklearn.naive_bayes.MultinomialNB),\n",
       " ('Real', numbers.Real),\n",
       " ('_BaseDiscreteNB', sklearn.naive_bayes._BaseDiscreteNB),\n",
       " ('_BaseNB', sklearn.naive_bayes._BaseNB)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import inspect\n",
    "inspect.getmembers(sklearn.naive_bayes, inspect.isclass) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f73c18-b901-405e-88c7-9a7c606b6633",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
