Metadata-Version: 2.1
Name: unilawbench
Version: 1.5.2
Summary: ä¸­æ–‡æ³•å¾‹å¤§æ¨¡å‹è¯„æµ‹å·¥å…·
Home-page: https://github.com/unilawbench/unilawbench
Author: UniLawBench Team
Author-email: contact@unilawbench.org
Description-Content-Type: text/markdown
Requires-Dist: PyQt5
Requires-Dist: pytrec-eval-terrier
Requires-Dist: accelerate
Requires-Dist: datasets<=3.2.0,>=3.0.0
Requires-Dist: immutabledict
Requires-Dist: jieba
Requires-Dist: jsonlines
Requires-Dist: langdetect
Requires-Dist: latex2sympy2
Requires-Dist: matplotlib
Requires-Dist: modelscope[framework]
Requires-Dist: nltk>=3.9
Requires-Dist: openai
Requires-Dist: pandas
Requires-Dist: pyarrow
Requires-Dist: pyyaml
Requires-Dist: requests
Requires-Dist: rouge-chinese
Requires-Dist: rouge-score>=0.1.0
Requires-Dist: sacrebleu
Requires-Dist: scikit-learn
Requires-Dist: seaborn
Requires-Dist: sympy
Requires-Dist: tabulate
Requires-Dist: torch
Requires-Dist: tqdm
Requires-Dist: transformers>=4.33
Requires-Dist: word2number
Requires-Dist: ms-opencompass>=0.1.4


<div align="center">
  <img width="500" src="https://raw.githubusercontent.com/your-org/UniLawBench/main/figs/UniLawBench_logo.png" alt="UniLawBench" />
</div>

<h1 align="center">UniLawBench Â· PyPI ç‰ˆ</h1>
<p align="center">
  <a href="https://pypi.org/project/unilawbench"><img src="https://img.shields.io/pypi/v/unilawbench?color=brightgreen" alt="PyPI"></a>
  <a href="https://github.com/modelscope/evalscope"><img src="https://img.shields.io/badge/EvalScope-%E2%9C%94-blue" alt="EvalScope"></a>
  <a href="https://github.com/your-org/UniLawBench"><img src="https://img.shields.io/badge/GitHub-Repo-black" alt="GitHub"></a>
</p>

---

## ğŸ—‚ï¸ é¡¹ç›®ç®€ä»‹
**UniLawBench** æ˜¯é¢å‘ä¸­æ–‡æ³•å¾‹åœºæ™¯çš„å¤§æ¨¡å‹è¯„æµ‹å·¥å…·ã€‚  
PyPI ç‰ˆå†…ç½®å…¨éƒ¨ 20 ä¸ªä»»åŠ¡æ•°æ®ï¼Œå¹¶é€šè¿‡ `console_scripts` å°†ä¸»ç¨‹åºæ³¨å†Œä¸º **`unilawbench`** å‘½ä»¤ï¼ŒçœŸæ­£å®ç° _pip â†’ run_ å¼€ç®±å³ç”¨ã€‚  
æ­¤å¤–ï¼Œæœ¬ç‰ˆæœ¬è¿˜é›†æˆäº† **PyQt5** å›¾å½¢ç•Œé¢ï¼Œç”¨æˆ·å¯é€šè¿‡å‘½ä»¤è¡Œç›´æ¥å¯åŠ¨å›¾å½¢ç•Œé¢ï¼Œå®Œæˆæ¨¡å‹é€‰æ‹©ã€æ•°æ®è½¬æ¢ç­‰æ“ä½œã€‚

> âš ï¸ åŒ…å«å®Œæ•´æ•°æ®é›†ï¼Œä¸å¿…å†å•ç‹¬ä¸‹è½½ã€‚

---

## ğŸ“¦ å®‰è£…

```bash
python -m pip install --upgrade pip
pip install unilawbench
```

å®‰è£…æ—¶ä¼šè‡ªåŠ¨æ‹‰å– `evalscope[all]` åŠå…¶ä¾èµ–ï¼ˆåŒ…å« OpenCompass/VLMEvalKit ç­‰åç«¯ï¼‰ã€‚åŒæ—¶ï¼Œ**PyQt5** ä¼šä½œä¸ºä¾èµ–è‡ªåŠ¨å®‰è£…ã€‚

---

## ğŸš€ å¿«é€Ÿä¸Šæ‰‹

### 1. è¯„æµ‹ (`eval`)
```bash
# è¯„ä¼°æ‰€æœ‰é€‰æ‹©é¢˜æ•°æ®é›†
unilawbench eval -form mcq --run-all -model ./weights

# åªè¯„ä¼° 1-1ã€2-5 ä¸¤ä¸ªé—®ç­”æ•°æ®é›†
unilawbench eval -form qa -set 1-1 2-5 -model ./weights
```

### 2. æ•°æ®è½¬æ¢ (`convert`)
```bash
# JSON â†¦ CSVï¼ˆå¤šé€‰ï¼‰
unilawbench convert --type mcq data/2-2.json data/2-2.csv

# JSON â†¦ JSONLï¼ˆçº çº·ç„¦ç‚¹ï¼‰
unilawbench convert --type focus data/focus.json data/focus.jsonl
```

---

## ğŸ–¥ï¸ å¯åŠ¨å›¾å½¢ç•Œé¢

### 3. å¯åŠ¨å›¾å½¢ç•Œé¢
```bash
unilawbench gui
```

è¿è¡Œæ­¤å‘½ä»¤åï¼Œä¼šå¯åŠ¨ä¸€ä¸ªå¸¦æœ‰é€‰é¡¹å¡çš„ PyQt5 çª—å£ï¼Œç”¨æˆ·å¯ä»¥é€šè¿‡ç•Œé¢é€‰æ‹©æ¨¡å‹è·¯å¾„ã€è¿›è¡Œæ–‡ä»¶è½¬æ¢ç­‰æ“ä½œã€‚

---

## ğŸ“š ä»»åŠ¡åˆ—è¡¨ï¼ˆå®Œæ•´ 20 é¡¹ï¼‰

| è®¤çŸ¥æ°´å¹³ | ID   | ä»»åŠ¡åç§°                     | æ•°æ®æº              | æŒ‡æ ‡                       | ç±»å‹ |
| -------- | ---- | ---------------------------- | ------------------- | -------------------------- | ---- |
| **æ³•å¾‹çŸ¥è¯†è®°å¿†** | 1-1 | æ³•æ¡èƒŒè¯µ                   | FLK                 | ROUGE-L                    | ç”Ÿæˆ |
|          | 1-2 | çŸ¥è¯†é—®ç­”                     | JEC_QA              | Accuracy                   | å•é€‰ |
| **æ³•å¾‹çŸ¥è¯†ç†è§£** | 2-1 | æ–‡ä»¶æ ¡å¯¹                   | CAIL2022            | F<sub>0.5</sub>            | ç”Ÿæˆ |
|          | 2-2 | çº çº·ç„¦ç‚¹è¯†åˆ«                 | LAIC2021            | F1                         | å¤šé€‰ |
|          | 2-3 | å©šå§»çº çº·é‰´å®š                 | AIStudio            | F1                         | å¤šé€‰ |
|          | 2-4 | é—®é¢˜ä¸»é¢˜è¯†åˆ«                 | CrimeKgAssitant     | Accuracy                   | å•é€‰ |
|          | 2-5 | é˜…è¯»ç†è§£                     | CAIL2019            | rc-F1                      | æŠ½å– |
|          | 2-6 | å‘½åå®ä½“è¯†åˆ«                 | CAIL2021            | soft-F1                    | æŠ½å– |
|          | 2-7 | èˆ†æƒ…æ‘˜è¦                     | CAIL2022            | ROUGE-L                    | ç”Ÿæˆ |
|          | 2-8 | è®ºç‚¹æŒ–æ˜                     | CAIL2022            | Accuracy                   | å•é€‰ |
|          | 2-9 | äº‹ä»¶æ£€æµ‹                     | LEVEN               | F1                         | å¤šé€‰ |
|          | 2-10 | è§¦å‘è¯æå–                   | LEVEN               | soft-F1                    | æŠ½å– |
| **æ³•å¾‹çŸ¥è¯†åº”ç”¨** | 3-1 | æ³•æ¡é¢„æµ‹ï¼ˆåŸºäºäº‹å®ï¼‰       | CAIL2018            | F1                         | å¤šé€‰ |
|          | 3-2 | æ³•æ¡é¢„æµ‹ï¼ˆåŸºäºåœºæ™¯ï¼‰         | LawGPT_zh Project   | ROUGE-L                    | ç”Ÿæˆ |
|          | 3-3 | ç½ªåé¢„æµ‹                     | CAIL2018            | F1                         | å¤šé€‰ |
|          | 3-4 | åˆ‘æœŸé¢„æµ‹ï¼ˆæ— æ³•æ¡å†…å®¹ï¼‰       | CAIL2018            | Normalized log-distance    | å›å½’ |
|          | 3-5 | åˆ‘æœŸé¢„æµ‹ï¼ˆç»™å®šæ³•æ¡å†…å®¹ï¼‰     | CAIL2018            | Normalized log-distance    | å›å½’ |
|          | 3-6 | æ¡ˆä¾‹åˆ†æ                     | JEC_QA              | Accuracy                   | å•é€‰ |
|          | 3-7 | çŠ¯ç½ªé‡‘é¢è®¡ç®—                 | LAIC2021            | Accuracy                   | å›å½’ |
|          | 3-8 | å’¨è¯¢                         | hualv.com           | ROUGE-L                    | ç”Ÿæˆ |

---

## ğŸ› ï¸ ç›®å½•ç»“æ„

```
unilawbench/
â”œâ”€ cli.py                 # ä¸»å…¥å£
â”œâ”€ dataset/               # å†…ç½®æ•°æ®é›† (mcq / qa)
â”œâ”€ utils/                 # æ•°æ®è½¬æ¢ç­‰å·¥å…·
â”œâ”€ gui/                   # PyQt5 å›¾å½¢ç•Œé¢ (window.py)
â””â”€ ...
```

---

## ğŸ“œ è®¸å¯è¯

- **ä»£ç **ï¼šApache-2.0  
- **æ•°æ®**ï¼šéµå¾ªå„ä¸Šæ¸¸æ•°æ®é›†è®¸å¯è¯ï¼Œè¯¦è§ `dataset/README.md`

---

## ğŸ“‘ å¼•ç”¨

```bibtex
@article{fei2023lawbench,
  title   = {LawBench: Benchmarking Legal Knowledge of Large Language Models},
  author  = {Fei, Zhiwei and Shen, Xiaoyu and others},
  journal = {arXiv preprint arXiv:2309.16289},
  year    = {2023}
}
```

> å¦‚æœ UniLawBench å¯¹æ‚¨çš„ç ”ç©¶æˆ–ä¸šåŠ¡æœ‰å¸®åŠ©ï¼Œè¯·å¼•ç”¨ä¸Šæ–‡ï¼Œå¹¶åœ¨æ–‡ä¸­æ³¨æ˜ä½¿ç”¨æœ¬å·¥å…· ğŸ™
