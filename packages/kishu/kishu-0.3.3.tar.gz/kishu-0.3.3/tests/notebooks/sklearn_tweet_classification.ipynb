{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Twitter Sentiment Analysis With Scikit-Learn</h2>\n",
    "<p>In this lesson we will use the scikit-learn Python library to perform some natural language processing tasks on our Twitter #climatechange dataset to evaluate user sentiment within the  280 character chunk of tweet text. For a supervised learning task, one must specify training and test datasets. For this example, we will use Textblob's built-in sentiment analysis to generate the core of our training and test datasets. </p>\n",
    "<p>This process consists of running the Textblob polarity sentiment analysis on the tweet text from our #climatechange dataset and extract a subset of the most positive or negative tweet text and create two datasets large enough to give us reasonable results but small enough to process quickly. </p>\n",
    "<p>We needed a reasonably large sample size so we chose weets for the positive dataset which had polarity sentiment values greater than 0.6 and tweets in the negative dataset which had polarity sentiment less than 0.4. This resulted in ???? positive tweets and ???? negative tweets. </p>\n",
    "<p>We then filtered the data to remove end-of-line characters, special characters, multiple sequential spaces, single character words, etc. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Import Packages</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "#import datetime\n",
    "#import os\n",
    "#import sys\n",
    "#import math\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from textblob import TextBlob\n",
    "#import sklearn\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import #climatechange Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/data/elastic-notebook/data/cvw/twitter/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(data_dir + 'climatechange_tweets_all.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Filtered Training/Test Dataset of Polarity Sentiment Measure Using Textblob\n",
    "\n",
    "In order to carry out classification, one needs to have labeled data examples: a set of inputs, along with associated labels, so that a classification algorithm can learn how to disciminate among the different labels based on the input.  Creating such a dataset (sometimes referred to as a \"gold standard\" dataset) can be very time consuming.\n",
    "\n",
    "In this exercise here, we have a set of tweets, and we'd like to \n",
    "\n",
    "<p>Creating a training/test dataset can require a significant amount of time. Often crowd-sourcing is used for this purpose. Since this is just a tutorial based on 'low-stakes' examples, we will use a simpler and quicker method to create our training/test dataset with Textblob. Textblob provides a feature designed to perform sentiment analysis for two different measures of sentiment, polarity and subjectivity. In this example we will use polarity, i.e. the negative or positive nature of a text sample, to classify our #climatechange dataset into mostly positive and mostly negative datasets. </p>\n",
    "\n",
    "<p>In the next code cell, we filter the data in several ways before processing with TextBlob. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff = df.drop_duplicates(subset='retweet_id')[['retweet_id', 'text']]\n",
    "count = 0\n",
    "for idx, row in dff.iterrows():\n",
    "    # Remove end-of-line characters\n",
    "    tweet_text = re.sub('\\n','',row['text'])\n",
    "    # Remove special characters\n",
    "    tweet_text = re.sub(r'\\W', ' ', tweet_text)\n",
    "    # remove all single characters\n",
    "    tweet_text = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', tweet_text)\n",
    "    # Remove single characters from the start\n",
    "    tweet_text = re.sub(r'\\^[a-zA-Z]\\s+', ' ', tweet_text) \n",
    "    # Substituting multiple spaces with single space\n",
    "    tweet_text = re.sub(r'\\s+', ' ', tweet_text, flags=re.I)\n",
    "    # Removing prefixed 'b'\n",
    "    tweet_text = re.sub(r'^b\\s+', '', tweet_text)\n",
    "    # Converting to Lowercase\n",
    "    tweet_text = tweet_text.lower()\n",
    "    # Calculate the Sentiment with TextBlob\n",
    "    tweet_text_sentiment = TextBlob(tweet_text)\n",
    "    #\n",
    "    dff.loc[idx, 'tweet_text'] = tweet_text\n",
    "    dff.loc[idx, 'polarity'] = tweet_text_sentiment.sentiment.polarity\n",
    "    dff.loc[idx, 'subjectivity'] = tweet_text_sentiment.sentiment.subjectivity\n",
    "    #\n",
    "    count += 1\n",
    "    if count%10000 == 0:\n",
    "        print(count)\n",
    "\n",
    "dff.drop('text', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dff.info())\n",
    "dff.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff['polarity'].plot.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff['polarity_label'] = dff['polarity'].apply(\n",
    "    lambda x: 'positive' if x > 0.5 else ('negative' if x < -0.3 else 'neutral'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff['subjectivity'].plot.hist(bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff['subjectivity_label'] = dff['subjectivity'].apply(\n",
    "    lambda x: 'subjective' if x > 0.9 else ('objective' if x < 0.02 else 'neither'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a Classifier\n",
    "\n",
    "Now that we have created our datasets we can proceed to create a classifier, the aim of which is to take as input a given tweet text and to assign a label as to its likely sentiment (positive, negative, or neutral).\n",
    "\n",
    "In order \n",
    "\n",
    "<p>Next, we need to initialize a vectorizer. This converts the tweet text into a word 'vector' in which each word becomes a 'component' of the vector and has a specific magnitude. We have not performed any preprocessing on the data or removed any stop words. We will set lowercase to False.</p>\n",
    "\n",
    "which should be able to identify with reasonable accuracy whether a tweet has a positive or negative sentiment. First, we will import our data. Note the print statement in the cell which processes the negative dataset. It is there just to give us a peek into what Textblob determined were negative tweet text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer     \n",
    "\n",
    "vectorizer = CountVectorizer(\n",
    "    analyzer = 'word',\n",
    "    lowercase = False,\n",
    "    max_features = 85\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = vectorizer.fit_transform(dff.tweet_text).toarray()\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a final step, we'll split the training data to get an evaluation set through scikit-learn's built-in cross validation method. All we need to do is provide the data and assign a training percentage (in this case, 80%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = features\n",
    "y = dff.polarity_label\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, train_size=0.8, random_state=1234)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a Linear Classifier\n",
    "\n",
    "Finally, having preprocessed the data, we can build a classifier for this corpus! As mentioned before, we'll be using the Logistic Regression from scikit-learn, so we'll start there: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "log_model = LogisticRegression(solver='liblinear')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the model is initialized, we have to fit it to our specific dataset, so we use scikit-learn's `fit()` method to do so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_model = log_model.fit(X=X_train, y=y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally, we use this classifier to label the evaluation set we created earlier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = log_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the Model's Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In scikit-learn, there is a function called sklearn.metrics.accuracy_score which calculates the accuracy percentage. Using this, we see that this model has an accuracy of about 70%. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we ran this on our raw unfiltered data we get ~70%. That's not bad, but 76% is much better, and we could probably do even better if we manually reviewed the datasets for any misclassifications by TextBlob. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "cross_validate(log_model, X, y, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try some other classifiers, such as Naive Bayes. Scikit-learn offers a few variations on the Naive-Bayes classifier, Gaussian, Multinomial, and Complement. We will create and test each model and compare our results with the Logistic Regression model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Gaussian NB Classifier</h2>\n",
    "<p>This classifier does not really make sense because it assumes the distribution of our data is gaussian, which is not likely for tweet text. But let's run it anyhow and confirm our suspicions.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb_model = GaussianNB()\n",
    "cross_validate(gnb_model, X, y, cv=5)\n",
    "#gnb_model = gnb.fit(X=X_train, y=y_train)\n",
    "#y_pred = gnb_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.metrics import accuracy_score\n",
    "#print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(y_train[y_train == 'negative'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Multinomial NB Classifier</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "mnb_model = MultinomialNB()\n",
    "cross_validate(mnb_model, X, y, cv=5)\n",
    "#mnb_model = mnb.fit(X=X_train, y=y_train)\n",
    "#y_pred = mnb_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Complement NB Classifier</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import ComplementNB\n",
    "cnb_model = ComplementNB()\n",
    "cross_validate(cnb_model, X, y, cv=5)\n",
    "#cnb_model = cnb.fit(X=X_train, y=y_train)\n",
    "#y_pred = cnb_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears none of the Naive Bayes classifiers performs better than Logistic Regression. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retweet_ids = set()\n",
    "retweet_id_list = []\n",
    "positive_tweets = []\n",
    "negative_tweets = []\n",
    "polarity = []\n",
    "subjectivity = []\n",
    "tweet_text_list = []\n",
    "val_inc = 0\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    # Check if retweet id is in set and process if not\n",
    "    if row['retweet_id'] not in retweet_ids:\n",
    "        retweet_ids.add(row['retweet_id'])\n",
    "        retweet_id_list.append(row['retweet_id'])\n",
    "        # Remove end-of-line characters\n",
    "        tweet_text = re.sub('\\n','',row['text'])\n",
    "        # Remove special characters\n",
    "        tweet_text = re.sub(r'\\W', ' ', tweet_text)\n",
    "        # remove all single characters\n",
    "        tweet_text = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', tweet_text)\n",
    "        # Remove single characters from the start\n",
    "        tweet_text = re.sub(r'\\^[a-zA-Z]\\s+', ' ', tweet_text) \n",
    "        # Substituting multiple spaces with single space\n",
    "        tweet_text = re.sub(r'\\s+', ' ', tweet_text, flags=re.I)\n",
    "        # Removing prefixed 'b'\n",
    "        tweet_text = re.sub(r'^b\\s+', '', tweet_text)\n",
    "        # Converting to Lowercase\n",
    "        tweet_text = tweet_text.lower()\n",
    "        # Calculate the Sentiment with TextBlob\n",
    "        tweet_text_sentiment = TextBlob(tweet_text)\n",
    "        polarity.append(tweet_text_sentiment.sentiment.polarity)\n",
    "        subjectivity.append(tweet_text_sentiment.sentiment.subjectivity)\n",
    "        tweet_text_list.append(tweet_text)\n",
    "        val_inc += 1\n",
    "        if val_inc%10000 == 0:\n",
    "            print(str(val_inc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polarity_df = pd.DataFrame(retweet_id_list, columns=['retweet_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polarity_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to add the tweet text and polarity to our dataframe as an additional column. Since these are lists, we can trust that they retain a specific immutable sequence and thus will 'line-up' corresponding values correctly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polarity_df['tweet_text'] = tweet_text_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polarity_df['polarity'] = polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polarity_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optional Exercise: Subjectivity Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Save Filtered Polarity Data</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's save our results in case we need this data for future examples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#REMOVE\n",
    "\n",
    "polarity_df.to_csv(data_dir + 'polarity_df_clean.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>[Optional as an Exercise] Save Filtered Subjectivity Data</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#REMOVE\n",
    "\n",
    "subjectivity_df = pd.DataFrame(retweet_id_list, columns=['retweet_id'])\n",
    "subjectivity_df['tweet_text'] = tweet_text_list\n",
    "subjectivity_df['subjectivity'] = subjectivity\n",
    "subjectivity_df.to_csv(data_dir + 'subjectivity_df_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "subjectivity_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Extract Positive and Negative Text</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REMOVE\n",
    "\n",
    "positive_tweets_df = polarity_df[polarity_df.polarity > 0.5]\n",
    "negative_tweets_df = polarity_df[polarity_df.polarity < -0.3]\n",
    "positive_text = positive_tweets_df.tweet_text\n",
    "negative_text = negative_tweets_df.tweet_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>[Optional as an Exercise] Extract Subjective and Objective Text</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjective_tweets_df = polarity_df[subjectivity_df.subjectivity > 0.9]\n",
    "objective_tweets_df = polarity_df[subjectivity_df.subjectivity < 0.02]\n",
    "subjective_text = subjective_tweets_df.tweet_text\n",
    "objective_text = objective_tweets_df.tweet_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Save Filtered Polarity Data</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's save our results in case we need this data for future examples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_text.to_csv(data_dir + 'positive_text_clean.csv', index=False, header=False)\n",
    "negative_text.to_csv(data_dir + 'negative_text_clean.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>[Optional as an Exercise] Save Filtered Subjectivity Data</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjective_text.to_csv(data_dir + 'subjective_text_clean.csv', index=False, header=False)\n",
    "objective_text.to_csv(data_dir + 'objective_text_clean.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#REMOVE\n",
    "\n",
    "text_pos = []\n",
    "labels_pos = []\n",
    "with open(data_dir + 'positive_text_clean.csv', encoding='utf-8') as f:\n",
    "    for i in f: \n",
    "        text_pos.append(i) \n",
    "        labels_pos.append('pos')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#REMOVE\n",
    "\n",
    "\n",
    "text_neg = []\n",
    "labels_neg = []\n",
    "with open(data_dir + 'negative_text_clean.csv', encoding='utf-8') as f:\n",
    "    for i in f: \n",
    "        #print(i)\n",
    "        text_neg.append(i)\n",
    "        labels_neg.append('neg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we split each dataset into a training and a test dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_text = text_pos[:int((.8)*len(text_pos))] + text_neg[:int((.8)*len(text_neg))]\n",
    "training_labels = labels_pos[:int((.8)*len(labels_pos))] + labels_neg[:int((.8)*len(labels_neg))]\n",
    "\n",
    "test_text = text_pos[int((.8)*len(text_pos)):] + text_neg[int((.8)*len(text_neg)):]\n",
    "test_labels = labels_pos[int((.8)*len(labels_pos)):] + labels_neg[int((.8)*len(labels_neg)):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_frac = 0.8\n",
    "breakpoint = int(test_frac * len(dff))\n",
    "training = dff.iloc[:breakpoint]\n",
    "testing = dff.iloc[breakpoint:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Next, we need to initialize a vectorizer. This converts the tweet text into a word 'vector' in which each word becomes a 'component' of the vector and has a specific magnitude. We have not performed any preprocessing on the data or removed any stop words. We will set lowercase to False.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = vectorizer.fit_transform(\n",
    "    training_text + test_text)\n",
    "\n",
    "features_nd = features.toarray() # for easy use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#REMOVE\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test  = train_test_split(\n",
    "        features_nd[0:len(training_text)], \n",
    "        training_labels, \n",
    "        random_state=124)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>In this next step we concatenate our text into a single array for feature extraction.</p>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
