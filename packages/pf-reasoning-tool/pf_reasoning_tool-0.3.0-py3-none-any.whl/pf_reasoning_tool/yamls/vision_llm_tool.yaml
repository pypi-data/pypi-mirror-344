# pf-reasoning-tool-proj/pf_reasoning_tool/yamls/vision_llm_tool.yaml

$schema: https://azuremlschemas.azureedge.net/promptflow/latest/Tool.schema.json
name: Vision LLM Call
description: "Calls a vision-capable LLM (like GPT-4V) with text, images (Base64), and configurable temperature."
type: python # Correct type for a tool using @tool with custom API logic
category: HW_PF_tools # Your desired category

# --- Tool Code Location ---
module: pf_reasoning_tool.tools.vision_llm_tool
function: vision_llm

# --- No default_prompt section as input 'prompt' is a simple string ---

inputs:
  connection:
    type: [CustomConnection, AzureOpenAIConnection, OpenAIConnection]
    description: "The connection object for OpenAI or Azure OpenAI."

  deployment_name:
    type: [string]
    description: "Name of the Azure OpenAI vision deployment (e.g., gpt-4-vision-preview)."

  prompt:
    type: [string]
    description: "The text prompt to send along with the images."

  images:
    type: [object] # PromptFlow treats List[Image] as object
    description: "A list of PromptFlow Image objects (output from a tool like prepare_pf_image_input)."

  max_tokens:
    type: [int]
    description: "Maximum number of tokens for the completion."
    default: 1000 # Numeric default
    optional: true

  temperature:
    type: [number] # Use 'number' for float/double
    description: "Controls randomness (0.0 to 2.0). Lower is more deterministic."
    default: 0.7 # Numeric default
    optional: true

outputs:
  output:
    type: [string]
    description: "The text response generated by the vision model."