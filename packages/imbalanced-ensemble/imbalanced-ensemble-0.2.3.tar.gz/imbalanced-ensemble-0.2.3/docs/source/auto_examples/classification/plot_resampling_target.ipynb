{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Customize resampling target\n\nThis example demonstrates how to customize the resampling target to achieve advanced resampling control.\nThis can be easily done by setting the \"target_label\" and \"n_target_samples\" parameter when calling the \"fit()\" method. \n\nNote that this feature only applies to resampling-based ensemble classifiers that are iteratively trained.\n\nThis example uses:\n\n    - :class:`imbens.ensemble.SelfPacedEnsembleClassifier`\n    - :class:`imbens.ensemble.SMOTEBoostClassifier`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Authors: Zhining Liu <zhining.liu@outlook.com>\n# License: MIT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(__doc__)\n\n# Import imbalanced-ensemble\nimport imbens\n\n# Import utilities\nfrom sklearn.datasets import make_classification\nfrom sklearn.model_selection import train_test_split\nfrom imbens.ensemble.base import sort_dict_by_key\nfrom collections import Counter\n\n# Import plot utilities\nfrom imbens.utils._plot import set_ax_border\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nsns.set_context('talk')\n\nRANDOM_STATE = 42\n\ninit_kwargs = {\n    'n_estimators': 1,\n    'random_state': RANDOM_STATE,\n}\nfit_kwargs = {\n    'train_verbose': {\n        'print_metrics': False,\n    },\n}\n\n# sphinx_gallery_thumbnail_number = -1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Prepare data\nMake a toy 3-class imbalanced classification task.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Generate and split a synthetic dataset\nX, y = make_classification(\n    n_classes=3,\n    n_samples=2000,\n    class_sep=2,\n    weights=[0.1, 0.3, 0.6],\n    n_informative=3,\n    n_redundant=1,\n    flip_y=0,\n    n_features=20,\n    n_clusters_per_class=2,\n    random_state=RANDOM_STATE,\n)\nX_train, X_valid, y_train, y_valid = train_test_split(\n    X, y, test_size=0.5, stratify=y, random_state=RANDOM_STATE\n)\n\n# Print class distribution\nprint('Training dataset distribution    %s' % sort_dict_by_key(Counter(y_train)))\nprint('Validation dataset distribution  %s' % sort_dict_by_key(Counter(y_valid)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Implement some plot utilities\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "ylim = (0, 630)\n\nall_distribution = {}\n\n\ndef plot_class_distribution(\n    distr: dict,\n    xlabel: str = 'Class Label',\n    ylabel: str = 'Number of samples',\n    **kwargs\n):\n    distr = dict(sorted(distr.items(), key=lambda k: k[0], reverse=True))\n    ax = sns.barplot(\n        x=list(distr.keys()), y=list(distr.values()), order=list(distr.keys()), **kwargs\n    )\n    set_ax_border(ax)\n    ax.grid(axis='y', alpha=0.5, ls='-.')\n    ax.set_xlabel(xlabel)\n    ax.set_ylabel(ylabel)\n    return ax\n\n\ndef plot_class_distribution_comparison(\n    clf,\n    title1='Original imbalanced class distribution',\n    title2='After resampling',\n    figsize=(12, 6),\n):\n    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=figsize)\n    plot_class_distribution(clf.origin_distr_, ax=ax1)\n    ax1.set(ylim=ylim, title=title1)\n    plot_class_distribution(clf.target_distr_, ax=ax2)\n    ax2.set(ylim=ylim, title=title2)\n    fig.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Default under-sampling\nBy default, under-sampling-based ensemble methods will consider the smallest class as the minority class (class 0 with 100 samples).\nAll other classes (class 1 and 2) will be considered as majority classes and will be under-sampled until the number of samples is equalized.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Take ``SelfPacedEnsembleClassifier`` as example\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "spe_clf = imbens.ensemble.SelfPacedEnsembleClassifier(**init_kwargs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Train with the default under-sampling setting**\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "spe_clf.fit(X_train, y_train, **fit_kwargs)\n\nall_distribution['Before under-sampling'] = spe_clf.origin_distr_\nresampling_type = 'After default under-sampling'\nall_distribution[resampling_type] = spe_clf.target_distr_\nplot_class_distribution_comparison(spe_clf, title2=resampling_type)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Specify the class targeted by the under-sampling\n**Set parameter ``target_label``: int**\nAll other classes that have more samples than the target class will be considered as majority classes.\nThey will be under-sampled until the number of samples is equalized.\nThe remaining minority classes (if any) will stay unchanged.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "spe_clf.fit(X_train, y_train, target_label=1, **fit_kwargs)  # target class 1\n\nresampling_type = 'After under-sampling (target class 1)'\nall_distribution[resampling_type] = spe_clf.target_distr_\nplot_class_distribution_comparison(spe_clf, title2=resampling_type)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Specify the desired number of samples after under-sampling\n**Set parameter ``n_target_samples``: int or dict**\nIf int, all classes that have more than the n_target_samples samples will be under-sampled until the number of samples is equalized.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "spe_clf.fit(\n    X_train, y_train, n_target_samples=200, **fit_kwargs  # target number of samples 200\n)\n\nresampling_type = 'After under-sampling (target number 200)'\nall_distribution[resampling_type] = spe_clf.target_distr_\nplot_class_distribution_comparison(spe_clf, title2=resampling_type)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Specify the desired number of samples of each class after under-sampling\n**Set parameter ``n_target_samples``: int or dict**\nIf dict, the keys correspond to the targeted classes. The values correspond to the desired number of samples for each targeted class.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "spe_clf.fit(\n    X_train,\n    y_train,\n    n_target_samples={\n        0: 80,\n        1: 200,\n        2: 400,\n    },  # target number of samples\n    **fit_kwargs\n)\n\nresampling_type = 'After under-sampling \\n(target number {0: 80, 1: 200, 2: 400})'\nall_distribution[resampling_type] = spe_clf.target_distr_\nplot_class_distribution_comparison(spe_clf, title2=resampling_type)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Over-sampling\nBy default, over-sampling-based ensemble methods will consider the largest class as the majority class (class 2 with 600 samples).\nAll other classes (class 0 and 1) will be considered as minority classes and will be over-sampled until the number of samples is equalized.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**The over-sampling schedule can be customized in the same way as under-sampling.**\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Take ``SMOTEBoostClassifier`` as example\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "smoteboost_clf = imbens.ensemble.SMOTEBoostClassifier(**init_kwargs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Train with the default under-sampling setting**\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "smoteboost_clf.fit(X_train, y_train, **fit_kwargs)\n\nall_distribution['Before over-sampling'] = smoteboost_clf.origin_distr_\nresampling_type = 'After default over-sampling'\nall_distribution[resampling_type] = smoteboost_clf.target_distr_\nplot_class_distribution_comparison(smoteboost_clf, title2=resampling_type)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Specify the class targeted by the over-sampling**\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "smoteboost_clf.fit(X_train, y_train, target_label=1, **fit_kwargs)  # target class 1\n\nresampling_type = 'After over-sampling (target class 1)'\nall_distribution[resampling_type] = smoteboost_clf.target_distr_\nplot_class_distribution_comparison(smoteboost_clf, title2=resampling_type)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Specify the desired number of samples after over-sampling**\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "smoteboost_clf.fit(\n    X_train, y_train, n_target_samples=400, **fit_kwargs  # target number of samples 400\n)\n\nresampling_type = 'After over-sampling (target number 400)'\nall_distribution[resampling_type] = smoteboost_clf.target_distr_\nplot_class_distribution_comparison(smoteboost_clf, title2=resampling_type)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Specify the desired number of samples of each class after over-sampling**\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "smoteboost_clf.fit(\n    X_train,\n    y_train,\n    n_target_samples={\n        0: 200,\n        1: 400,\n        2: 600,\n    },  # target number of samples\n    **fit_kwargs\n)\n\nresampling_type = 'After over-sampling \\n(target number {0: 200, 1: 400, 2: 600})'\nall_distribution[resampling_type] = smoteboost_clf.target_distr_\nplot_class_distribution_comparison(smoteboost_clf, title2=resampling_type)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualize different resampling target\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "sns.set_context('notebook')\nfig, axes = plt.subplots(2, 5, figsize=(20, 8))\nfor ax, title in zip(axes.flatten(), list(all_distribution.keys())):\n    plot_class_distribution(all_distribution[title], ax=ax, palette=\"Blues_d\")\n    ax.set(ylim=ylim, title=title)\nfig.tight_layout()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}