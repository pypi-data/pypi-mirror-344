{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ef43f053-dfd9-4619-b9a6-2b51eb596947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "25ae764c-a6fb-463d-8654-f6ac976ef173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default backend: cpu\n"
     ]
    }
   ],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jaxtyping import Array, Float, PyTree\n",
    "print(\"Default backend:\", jax.default_backend())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "afc1814d-547b-45f0-84bf-97a351f166a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[CpuDevice(id=0)]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jax.devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "031844d3-9eeb-45c3-a2b0-f9ccd0bee0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import equinox as eqx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b88d557-3d68-42bb-b9cb-80a83079bdb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuralop.models import FNO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "119f2d88-574c-43d6-89a7-b205a4a9b8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuralop.data.datasets import load_darcy_flow_small\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "04394ffa-65ea-4f6f-8bbc-4646a9f6a341",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading test db for resolution 16 with 50 samples \n",
      "Loading test db for resolution 32 with 50 samples \n"
     ]
    }
   ],
   "source": [
    "data_dir = '/Users/alexszen/Desktop/github/neuraloperator/neuralop/data/datasets/data'\n",
    "\n",
    "train_loader, test_loaders, data_processor = load_darcy_flow_small(data_root=data_dir,\n",
    "        n_train=100, batch_size=4, \n",
    "        test_resolutions=[16, 32], n_tests=[50, 50], test_batch_sizes=[4, 2],\n",
    "        )\n",
    "\n",
    "train_dataset = train_loader.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3c1d740-9ea4-4bfd-a315-1eb52c0eb9bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 16, 16])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]['x'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "49d60352-a64a-4d91-bc2c-eaab437c4437",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f3c6bcf-d647-43cd-aa8f-ab14ef7f3423",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x146131df0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGdCAYAAABU0qcqAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjEsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvc2/+5QAAAAlwSFlzAAAPYQAAD2EBqD+naQAAHSFJREFUeJzt3X9wVNX9//H33d1kE2ISSBBIJAH0w4j8EEV+fBCnhYGR4UtRpqMWBzEDM1pbFBCHYtqCbVEjtqURZECYqdgZfvmHIGW+wlBE0E9BTBArHy0/vqYhwjekKmRJQjab3fuZczvJx2iQWO/h3Lv7fMycCXf35n0Pm9193XPv2buWbdu2AABwlQWu9gYBAFAIIACAEQQQAMAIAggAYAQBBAAwggACABhBAAEAjCCAAABGhMRjEomEnD17VrKzs8WyLNPdAQB8S+r6BhcvXpTCwkIJBAL+CSAVPkVFRaa7AQD4jmpqaqRv377+CSA18lHukP8jIUkz3Z3UwEjz6uMKWEhirRKTd+T/tr+f+yaA2g67qfAJWQTQVUEAGUAAIfmf3lc6jcIkBACAEQQQAMAIAggAYAQBBABIrgBavXq19O/fXzIyMmTMmDFy+PBhXZsCAPiQlgDaunWrLFy4UJ566ik5cuSIDB8+XCZPnix1dXU6NgcA8CEtAbRixQp56KGHZPbs2TJ48GBZu3atdOvWTf74xz/q2BwAwIdcD6CWlhaprKyUSZMm/e9GAgFn+eDBg19bPxqNSiQS6dAAAMnP9QD67LPPJB6PS+/evTvcrpZra2u/tn5ZWZnk5ua2Ny7DAwCpwfgsuNLSUqmvr29v6tpBAIDk5/qleHr27CnBYFDOnTvX4Xa13KdPn6+tHw6HnQYASC2uj4DS09Pltttuk71793b4igW1PHbsWLc3BwDwKS0XI1VTsEtKSmTkyJEyevRoKS8vl8bGRmdWHAAA2gLoRz/6kfzzn/+UpUuXOhMPbrnlFtm1a9fXJiYAAFKXZauvrvMQNQ1bzYYbL3fzdQxXC1/HcPV562UHuKrVjslb8rozsSwnJ8e7s+AAAKmJAAIAGEEAAQCMIIAAAMkzC87LLI0ferVC+h7OQM88bbUvjC4UnZp6BbXVTmicp5LWoG+iQN7Hl7TVDjTFtNW2dE6e0Fk7rnfSh5VIiB/ZAT1jkEA8KvJRF9bTsnUAAK6AAAIAGEEAAQCMIIAAAEYQQAAAIwggAIARBBAAwAgCCABgBAEEADCCAAIAGEEAAQCMIIAAAEYQQAAAIwggAIARBBAAwAgCCABgBAEEADCCAAIAGEEAAQCMIIAAAEYQQAAAIwggAIARIUkxVkjff9nq1k1b7daCHtpqfzE4KDpFr2/WVjs9M6atduR8hrbarRqfKxmfJ7TVDrRqKy2BuK2vdqu+2oql8XERS1/ptAY9HW9t7drYhhEQAMAIAggAYAQBBAAwggACABhBAAEAjCCAAABGEEAAgOQIoLKyMhk1apRkZ2dLr169ZPr06XL8+HG3NwMA8DnXA2j//v0yd+5cOXTokOzZs0disZjceeed0tjY6PamAAA+5vplAXbt2tVhecOGDc5IqLKyUr73ve+5vTkAgE9pvxRPfX298zMvL6/T+6PRqNPaRCIR3V0CACT7JIREIiELFiyQcePGydChQy97zig3N7e9FRUV6ewSACAVAkidCzp27Jhs2bLlsuuUlpY6o6S2VlNTo7NLAIBkPwT36KOPys6dO+XAgQPSt2/fy64XDoedBgBILa4HkG3b8thjj8m2bdvkrbfekgEDBri9CQBAEgjpOOy2adMmef31153PAtXW1jq3q/M7mZmZbm8OAOBTrp8DWrNmjXMuZ/z48VJQUNDetm7d6vamAAA+puUQHAAAV8K14AAARhBAAAAjCCAAgBEEEAAgOa8F5zVWmr7/shVO11Y7lqOvdnOfVtFpeP8z2mr37XZBW+2P83prq326/jpttVuy9e1XBmPaSktAZ+0W0SrYom/yVeiSvtqBFj3PlXiga3UZAQEAjCCAAABGEEAAACMIIACAEQQQAMAIAggAYAQBBAAwggACABhBAAEAjCCAAABGEEAAACMIIACAEQQQAMAIAggAYAQBBAAwggACABhBAAEAjCCAAABGEEAAACMIIACAEQQQAMAIAggAYERIUk0wqK92mr6HM/3zS9pqB3PTRKdbu9doq/0fGee01c4KRbXVrr4uX1vtSzn6/p6BZn37rIGopa92i2gVbNbX97QmfbXj6XqeK/GWeJfWYwQEADCCAAIAGEEAAQCMIIAAAEYQQAAAIwggAIARBBAAIDkD6LnnnhPLsmTBggW6NwUA8BGtAfTee+/JSy+9JDfffLPOzQAAfEhbADU0NMjMmTNl/fr10qNHD12bAQD4lLYAmjt3rkydOlUmTZqkaxMAAB/TcvGyLVu2yJEjR5xDcFcSjUad1iYSiejoEgAg2UdANTU1Mn/+fNm4caNkZGRccf2ysjLJzc1tb0VFRW53CQCQCgFUWVkpdXV1MmLECAmFQk7bv3+/rFy50vl3PN7xKqmlpaVSX1/f3lSAAQCSn+uH4CZOnCgffvhhh9tmz54tgwYNksWLF0vwK1+HEA6HnQYASC2uB1B2drYMHTq0w21ZWVmSn5//tdsBAKmLKyEAAJL3G1Hfeuutq7EZAICPMAICABhBAAEAjCCAAABGEEAAACMIIABA8s6C85RAxw/CuslO0/dwNva7Rlvtvj3PiU7/kaGv/rVBfdcOLEi/oK1232vPa6v9RVamttrNl9K11W6N6nv9tEb17mtbGuvHmvTVDjbrqRu3urYeIyAAgBEEEADACAIIAGAEAQQAMIIAAgAYQQABAIwggAAARhBAAAAjCCAAgBEEEADACAIIAGAEAQQAMIIAAgAYQQABAIwggAAARhBAAAAjCCAAgBEEEADACAIIAGAEAQQAMIIAAgAYQQABAIwISYqx0tO01bZDQW21P73T1lZ7/nVHRafswCVttS8kuokfDe5Rq6322XCuttoXumVqq30xmq6t9iWNtZVYi7630nhM3zgh9nmGlrrxqNWl9RgBAQCMIIAAAEYQQAAAIwggAIARBBAAwAgCCABgBAEEAEieADpz5ow88MADkp+fL5mZmTJs2DCpqKjQsSkAgE+5/ump8+fPy7hx42TChAnyxhtvyLXXXisnT56UHj16uL0pAICPuR5Ay5cvl6KiInn55ZfbbxswYIDbmwEA+Jzrh+B27NghI0eOlHvvvVd69eolt956q6xfv/6y60ejUYlEIh0aACD5uR5An3zyiaxZs0YGDhwou3fvlp/85Ccyb948eeWVVzpdv6ysTHJzc9ubGj0BAJKf6wGUSCRkxIgR8uyzzzqjn4cfflgeeughWbt2bafrl5aWSn19fXurqalxu0sAgFQIoIKCAhk8eHCH22666SY5ffp0p+uHw2HJycnp0AAAyc/1AFIz4I4fP97hthMnTki/fv3c3hQAwMdcD6DHH39cDh065ByCO3XqlGzatEnWrVsnc+fOdXtTAAAfcz2ARo0aJdu2bZPNmzfL0KFDZdmyZVJeXi4zZ850e1MAAB/T8jV+P/jBD5wGAMDlcC04AIARBBAAwAgCCABgBAEEAEieSQielp6mrfTnt+Vrq/3YHbu11b4+vU50Srfi2monNO5DdQ82aavdL+NzbbUzAy3aan8RztJW+3y0m7baF2Nh0akppu99JRrT9zbddE2GlrrxLnaZERAAwAgCCABgBAEEADCCAAIAGEEAAQCMIIAAAEYQQAAAIwggAIARBBAAwAgCCABgBAEEADCCAAIAGEEAAQCMIIAAAEYQQAAAIwggAIARBBAAwAgCCABgBAEEADCCAAIAGEEAAQCMIIAAAEaExKss61/NZZ/Muk50eXTGn7XVvjYU0VY7w4qJTulWXFvtNKtVW+2AJHxZOxzQ9/e8JhTVVjs37ZK22vWxTNHpYiysrXaDxtr/L5ynpW7Ctru0HiMgAIARBBAAwAgCCABgBAEEADCCAAIAGEEAAQCMIIAAAMkRQPF4XJYsWSIDBgyQzMxMueGGG2TZsmVid3FeOAAgNbj+QdTly5fLmjVr5JVXXpEhQ4ZIRUWFzJ49W3Jzc2XevHlubw4A4FOuB9Bf//pXufvuu2Xq1KnOcv/+/WXz5s1y+PBhtzcFAPAx1w/B3X777bJ37145ceKEs/zBBx/IO++8I1OmTOl0/Wg0KpFIpEMDACQ/10dATz75pBMigwYNkmAw6JwTeuaZZ2TmzJmdrl9WVia//vWv3e4GACDVRkCvvvqqbNy4UTZt2iRHjhxxzgX97ne/c352prS0VOrr69tbTU2N210CAKTCCGjRokXOKGjGjBnO8rBhw6S6utoZ6ZSUlHxt/XA47DQAQGpxfQTU1NQkgUDHsupQXCKh7/LzAAD/cX0ENG3aNOecT3FxsTMN+/3335cVK1bInDlz3N4UAMDHXA+gVatWOR9E/elPfyp1dXVSWFgoP/7xj2Xp0qVubwoA4GOuB1B2draUl5c7DQCAy+FacAAAIwggAIARBBAAwAgCCACQHJMQXGMF/tVcFrvxkuiSHdBXOyfQrK12ViAqOqVZcfEjnf1O11g7IxDTVrtboEVb7WuC+p7j1wT1PscjoQxttb8IZmmr/YmmulYX12MEBAAwggACABhBAAEAjCCAAABGEEAAACMIIACAEQQQAMAIAggAYAQBBAAwggACABhBAAEAjCCAAABGEEAAACMIIACAEQQQAMAIAggAYAQBBAAwggACABhBAAEAjCCAAABGEEAAACMIIACAESFJMfFLQW21g5atrXa3QFRb7SwrJjqlWQnxo3TR1+/0QFxb7TSrVVvtdEtfvzOsFm21uwX01VYyAlnaatdFs7XV1vXn7GpdRkAAACMIIACAEQQQAMAIAggAYAQBBAAwggACABhBAAEA/BFABw4ckGnTpklhYaFYliXbt2/vcL9t27J06VIpKCiQzMxMmTRpkpw8edLNPgMAUjGAGhsbZfjw4bJ69epO73/++edl5cqVsnbtWnn33XclKytLJk+eLM3NzW70FwCQqldCmDJlitM6o0Y/5eXl8stf/lLuvvtu57Y//elP0rt3b2ekNGPGjO/eYwBAUnD1HFBVVZXU1tY6h93a5ObmypgxY+TgwYOd/k40GpVIJNKhAQCSn6sBpMJHUSOeL1PLbfd9VVlZmRNSba2oqMjNLgEAPMr4LLjS0lKpr69vbzU1Naa7BADwWwD16dPH+Xnu3LkOt6vltvu+KhwOS05OTocGAEh+rgbQgAEDnKDZu3dv+23qnI6aDTd27Fg3NwUASLVZcA0NDXLq1KkOEw+OHj0qeXl5UlxcLAsWLJCnn35aBg4c6ATSkiVLnM8MTZ8+3e2+AwBSKYAqKipkwoQJ7csLFy50fpaUlMiGDRvkZz/7mfNZoYcfflguXLggd9xxh+zatUsyMjLc7TkAILUCaPz48c7nfS5HXR3hN7/5jdMAAPDsLDgAQGoigAAARhBAAAAjCCAAgD8mIfid1RTUVvtsrLu22v+ZUa2tdlws0Skol5+04mVpVkJb7cA3TOT57rUTvvxbplmt2mpnJGKiU1Ygqq32R1Kgrba2P2cX6zICAgAYQQABAIwggAAARhBAAAAjCCAAgBEEEADACAIIAGAEAQQAMIIAAgAYQQABAIwggAAARhBAAAAjCCAAgBEEEADACAIIAGAEAQQAMIIAAgAYQQABAIwggAAARhBAAAAjCCAAgBEEEADAiJCkmEBUX+Z+FsvWVjvN0lZabghliV9F7Zi22mdbo9pqixUXP0pY+h7vuOh7kgcDtvhVSyKorbYV1/SYd7EuIyAAgBEEEADACAIIAGAEAQQAMIIAAgAYQQABAIwggAAA/gigAwcOyLRp06SwsFAsy5Lt27e33xeLxWTx4sUybNgwycrKctZ58MEH5ezZs273GwCQagHU2Ngow4cPl9WrV3/tvqamJjly5IgsWbLE+fnaa6/J8ePH5a677nKrvwCAVL0SwpQpU5zWmdzcXNmzZ0+H21588UUZPXq0nD59WoqLi//9ngIAkor2S/HU19c7h+q6d+/e6f3RaNRpbSKRiO4uAQCSfRJCc3Ozc07o/vvvl5ycnE7XKSsrc0ZOba2oqEhnlwAAyR5AakLCfffdJ7Zty5o1ay67XmlpqTNKams1NTW6ugQASPZDcG3hU11dLW+++eZlRz9KOBx2GgAgtYR0hc/Jkydl3759kp+f7/YmAACpGEANDQ1y6tSp9uWqqio5evSo5OXlSUFBgdxzzz3OFOydO3dKPB6X2tpaZz11f3p6uru9BwCkTgBVVFTIhAkT2pcXLlzo/CwpKZFf/epXsmPHDmf5lltu6fB7ajQ0fvz4795jAEBqBpAKETWx4HK+6T4AANpwLTgAgBEEEADACAIIAGAEAQQAMIIAAgAk58VIvSbUZGmrffLitdpqf5jdU1vtDOtz0Sk/kKmtdkiC2mrnBfXVjtoJbbWb7VZttdNEX78DGh+TC/FuotOnLfo+cF/bePkryXxXwWZNhf/3+tLfiBEQAMAIAggAYAQBBAAwggACABhBAAEAjCCAAABGEEAAACMIIACAEQQQAMAIAggAYAQBBAAwggACABhBAAEAjCCAAABGEEAAACMIIACAEQQQAMAIAggAYAQBBAAwggACABhBAAEAjCCAAABGhMSr7ISIqOaujM9Fmw9O99VWe739fW21/yvn/4tOPdMatNVOs+LaasfF0lY7Zgf11U7oe1lHbX21G1rD2mp/EcsSnaoi+dpqnzmTp612j/O2lrrxlq7VZQQEADCCAAIAGEEAAQCMIIAAAEYQQAAAIwggAIA/AujAgQMybdo0KSwsFMuyZPv27Zdd95FHHnHWKS8v/679BACkegA1NjbK8OHDZfXq1d+43rZt2+TQoUNOUAEA8FXf+lNlU6ZMcdo3OXPmjDz22GOye/dumTp16rfdBAAgBbh+DiiRSMisWbNk0aJFMmTIELfLAwCShOvX1Vi+fLmEQiGZN29el9aPRqNOaxOJRNzuEgAg2UdAlZWV8sILL8iGDRucyQddUVZWJrm5ue2tqKjIzS4BAFIhgN5++22pq6uT4uJiZxSkWnV1tTzxxBPSv3//Tn+ntLRU6uvr21tNTY2bXQIApMIhOHXuZ9KkSR1umzx5snP77NmzO/2dcDjsNABAavnWAdTQ0CCnTp1qX66qqpKjR49KXl6eM/LJz+94WfK0tDTp06eP3Hjjje70GACQmgFUUVEhEyZMaF9euHCh87OkpMQ59wMAgJYAGj9+vNh217/E6B//+Me33QQAIAVwLTgAgBEEEADACAIIAGAEAQQAMIIAAgAkx7XgvK77qZi22lYiU1vt4ydv0Fb7vzOvF53sNFtfbb/uQul7SMTSWFsSXbvE1r/DimsrLYFW0SrUpO9x6XFe3x80t0rP+2Fra9fq+vXlCwDwOQIIAGAEAQQAMIIAAgAYQQABAIwggAAARhBAAAAjCCAAgBEEEADACAIIAGAEAQQAMIIAAgAYQQABAIwggAAARhBAAAAjCCAAgBEEEADACAIIAGAEAQQAMIIAAgAYQQABAIwIicfYtu38bLVjWuq3xppFl3hLXF9tfd2WhPWvx1wXO66vvu3XXSiND7nWP2fC0lba0vfyEWnVWFu9PqP6Hpd4i74/aGurpvfZ1uYO7+eXY9lXWuMq+/TTT6WoqMh0NwAA31FNTY307dvXPwGUSCTk7Nmzkp2dLZZ15b2KSCTiBJb6j+bk5Ihf0O+ry6/99nPf6Xfq9tu2bbl48aIUFhZKIBDwzyE41dlvSszLUQ+46Qf930G/ry6/9tvPfaffqdnv3NzcK67j1yPoAACfI4AAAEb4PoDC4bA89dRTzk8/od9Xl1/77ee+0++rK+zDfntuEgIAIDX4fgQEAPAnAggAYAQBBAAwggACABjh6wBavXq19O/fXzIyMmTMmDFy+PBh8bqysjIZNWqUc6WHXr16yfTp0+X48ePiN88995xzpYoFCxaI1505c0YeeOAByc/Pl8zMTBk2bJhUVFSIl8XjcVmyZIkMGDDA6fMNN9wgy5Ytu+K1tUw4cOCATJs2zfnUu3pObN++vcP9qs9Lly6VgoIC5/8yadIkOXnypHi537FYTBYvXuw8V7Kyspx1HnzwQecqLV5/vL/skUcecdYpLy8XL/JtAG3dulUWLlzoTDs8cuSIDB8+XCZPnix1dXXiZfv375e5c+fKoUOHZM+ePc4T/c4775TGxkbxi/fee09eeuklufnmm8Xrzp8/L+PGjZO0tDR544035KOPPpLf//730qNHD/Gy5cuXy5o1a+TFF1+Ujz/+2Fl+/vnnZdWqVeI16rmrXn9qh7Azqt8rV66UtWvXyrvvvuu8oavXanOzxivsfsd+NzU1Oe8raidA/XzttdecHcW77rpLvP54t9m2bZvzPqOCyrNsnxo9erQ9d+7c9uV4PG4XFhbaZWVltp/U1dWpXVp7//79th9cvHjRHjhwoL1nzx77+9//vj1//nzbyxYvXmzfcccdtt9MnTrVnjNnTofbfvjDH9ozZ860vUw9l7dt29a+nEgk7D59+ti//e1v22+7cOGCHQ6H7c2bN9te7XdnDh8+7KxXXV1te73fn376qX3dddfZx44ds/v162f/4Q9/sL3IlyOglpYWqaysdIbyX76GnFo+ePCg+El9fb3zMy8vT/xAjd6mTp3a4bH3sh07dsjIkSPl3nvvdQ553nrrrbJ+/Xrxuttvv1327t0rJ06ccJY/+OADeeedd2TKlCniJ1VVVVJbW9vh+aKuEaYOmfvxtaoOZ3Xv3l28LJFIyKxZs2TRokUyZMgQ8TLPXYy0Kz777DPnGHnv3r073K6W//73v4tfqCeKOoeiDhENHTpUvG7Lli3O4Qh1CM4vPvnkE+dQljpc+/Of/9zp+7x58yQ9PV1KSkrEq5588knn6saDBg2SYDDoPN+feeYZmTlzpviJCh+ls9dq231+oA4XqnNC999/vycu9PlN1OHaUCjkPM+9zpcBlCzUaOLYsWPOnq3XqUu8z58/3zlvpSZ9+Cnk1Qjo2WefdZbVCEg95up8hJcD6NVXX5WNGzfKpk2bnL3Yo0ePOjsr6ni+l/udjNR52vvuu8+ZTKF2ZryssrJSXnjhBWdHsStfZ2OaLw/B9ezZ09krPHfuXIfb1XKfPn3EDx599FHZuXOn7Nu379/6+gkTT2w1wWPEiBHO3pVqakKFOrms/q320L1IzbwaPHhwh9tuuukmOX36tHiZOnyiRkEzZsxwZmKpQyqPP/64M4vST9pej359rbaFT3V1tbPz5fXRz9tvv+28TouLi9tfp6rvTzzxhDNj2Gt8GUDq8Mltt93mHCP/8p6uWh47dqx4mdqLUuGjZqi8+eabzjRbP5g4caJ8+OGHzp54W1MjC3VISP1b7RB4kTq8+dVp7uq8Sr9+/cTL1Cysr36Rl3qM1fPcT9TzWwXNl1+r6tCimg3n9ddqW/ioKeN/+ctfnGn8Xjdr1iz529/+1uF1qkbNaodm9+7d4jW+PQSnjumrQxHqTXD06NHOPHc1PXH27Nni9cNu6rDK66+/7nwWqO04uDoxqz4j4VWqr189T6Wm06oXpZfPX6lRgzqhrw7BqTcT9VmxdevWOc3L1Oc81DkftSerDsG9//77smLFCpkzZ454TUNDg5w6darDxAP1xqcm1qj+q0OHTz/9tAwcONAJJDW1Wb0pqs/AebXfauR8zz33OIey1JEKNcJve62q+9VOsFcf7/yvBKX6CILaCbjxxhvFc2wfW7VqlV1cXGynp6c707IPHTpke516yDtrL7/8su03fpiGrfz5z3+2hw4d6kz9HTRokL1u3Trb6yKRiPPYqud3RkaGff3119u/+MUv7Gg0anvNvn37On1Ol5SUtE/FXrJkid27d2/nbzBx4kT7+PHjnu53VVXVZV+r6ve82u/OeHkaNl/HAAAwwpfngAAA/kcAAQCMIIAAAEYQQAAAIwggAIARBBAAwAgCCABgBAEEADCCAAIAGEEAAQCMIIAAAEYQQAAAMeF/AAjM3ry3j5C1AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(train_dataset[0]['y'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a2422a4-a040-4b04-a8cd-50cb34fe2ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = train_dataset[0]['x'].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ecfd35ce-1da4-4793-bd55-b16b6146f0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x_with_c = jnp.expand_dims(test_x, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b6f90b7e-c2b8-48cf-af6b-4284ac3e0a42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 16, 16)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x_with_c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4b623594-dbd8-4027-9f03-fac1373afc25",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = jnp.fft.fft2(test_x_with_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "866501a4-a4ea-45d6-91f8-61fd55580aa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 16, 16)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "da142edd-d164-4311-80c0-450870741be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "modes = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4f6d743b-8743-4797-bd42-f116932bf797",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cropped = test[:,:,:modes,:modes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3cc2464a-31fd-4719-85fa-55a5053a0a1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 12, 12)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_cropped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "55d7d807-f583-45da-8514-e3b4a81341f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "h_crop = jnp.arange(modes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9abab197-0621-4b61-b2c3-e02b2d92eb8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 1)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_crop[:,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "af74b5e4-688e-4284-8ef6-ea2ae26e91b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0\n",
    "key = jax.random.key(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "40196639-1e5c-4734-9fd7-cba1fea9180c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from equinox.nn._misc import default_init\n",
    "from equinox._module import field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "23b33267-8b36-4bb2-915a-9276455b19b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpectralConv2D(eqx.Module):\n",
    "    real_weights: jax.Array\n",
    "    img_weights: jax.Array\n",
    "    real_bias: jax.Array\n",
    "    img_bias: jax.Array\n",
    "    in_channels: int = eqx.field(static=True)\n",
    "    out_channels: int = eqx.field(static=True)\n",
    "    modes: int = eqx.field(static=True)\n",
    "    use_bias: bool = eqx.field(static=True)\n",
    "\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, modes, key, use_bias=True):\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels \n",
    "        self.modes = modes \n",
    "        self.use_bias = use_bias\n",
    "        keys = jax.random.split(key, 4)\n",
    "        scale = 2 / (in_channels + out_channels) ** 2\n",
    "        self.real_weights = jax.random.normal(keys[0], (out_channels, in_channels, modes, modes)) * scale\n",
    "        self.img_weights = jax.random.normal(keys[0], (out_channels, in_channels, modes, modes)) * scale\n",
    "        self.real_bias = jnp.zeros((out_channels)) if use_bias else None\n",
    "        self.img_bias = jnp.zeros((out_channels)) if use_bias else None\n",
    "\n",
    "    def __call__(self, x: jax.Array):\n",
    "\n",
    "        c, h, w = x.shape\n",
    "        assert c == self.in_channels, f'Input channels must match in_channels, got {c} != {self.in_channels}'\n",
    "        out_ft_real = jnp.zeros((self.out_channels, h, w))\n",
    "        out_ft_imag = jnp.zeros((self.out_channels, h, w))\n",
    "        x_ft = jnp.fft.fft2(x)\n",
    "        x_ft_real_crop = jnp.real(x_ft)[:, :self.modes, :self.modes]\n",
    "        x_ft_img_crop = jnp.imag(x_ft)[:, :self.modes, :self.modes]\n",
    "        out_real_crop = (x_ft_real_crop * self.real_weights - x_ft_img_crop * self.img_weights).sum(axis=1)\n",
    "        out_img_crop = (x_ft_real_crop * self.img_weights + x_ft_img_crop * self.real_weights).sum(axis=1)\n",
    "        out_ft_real = out_ft_real.at[:, :self.modes, :self.modes].set(out_real_crop)\n",
    "        out_ft_imag = out_ft_imag.at[:, :self.modes, :self.modes].set(out_img_crop)\n",
    "        out = jnp.fft.ifft2(out_ft_real + 1j * out_ft_imag)\n",
    "        return jnp.real(out)\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "                                   \n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d38a7782-2c3d-44b3-b588-f352c85182be",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_c = 12\n",
    "out_c = 24\n",
    "h = 16\n",
    "w = 16\n",
    "modes = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "0e1d24a3-8057-4087-ab7f-8023efae464f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_in = jnp.zeros((in_c, h, w))\n",
    "weights = jnp.zeros((out_c, in_c, h, w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e948c3f0-9036-4c41-b45b-8a3862c1f616",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test_in * weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "404b1a2f-917e-4177-a87a-6c5170e0ed54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24, 12, 16, 16)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_summed = jnp.sum(test, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "134d6bd7-39f3-4b44-9912-01c3c7a86590",
   "metadata": {},
   "outputs": [],
   "source": [
    "key, subkey = jax.random.split(key)\n",
    "testconv = SpectralConv2D(in_c, out_c, modes, subkey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "44183015-1113-4fb8-8a60-15f42c17b93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "testout = testconv(test_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "66e5ff2c-7e15-4b5a-a371-8bc6c0776129",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24, 16, 16)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testout.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "da1f5139-72da-4767-84dc-77998de79f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spectral_conv.py\n",
    "from __future__ import annotations\n",
    "from typing import Sequence, Tuple, Optional\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import equinox as eqx\n",
    "\n",
    "\n",
    "def _central_crop_slices(\n",
    "    fft_shape: Sequence[int],        # e.g. (Hx, Hy, Hz//2+1)\n",
    "    n_modes: Sequence[int]           # same length as fft_shape\n",
    ") -> Tuple[slice, ...]:\n",
    "    \"\"\"\n",
    "    Build slice objects that pick the centred block of size n_modes[:-1]\n",
    "    in the shifted spectrum, and the first n_modes[-1] coefficients on\n",
    "    the rFFT axis (no shift there).\n",
    "    \"\"\"\n",
    "    *shifted_axes, last_axis = fft_shape\n",
    "    *modes_shifted, modes_last = n_modes\n",
    "\n",
    "    # axes that were fft‑shifted (all except the rFFT axis)\n",
    "    slices = []\n",
    "    for size, k in zip(shifted_axes, modes_shifted):\n",
    "        centre = size // 2\n",
    "        neg = k // 2\n",
    "        pos = k - neg          # keeps k elements\n",
    "        slices.append(slice(centre - neg, centre + pos))\n",
    "\n",
    "    # rFFT axis → take the low‑frequency part only\n",
    "    slices.append(slice(0, modes_last))\n",
    "    return tuple(slices)\n",
    "\n",
    "\n",
    "class SpectralConv(eqx.Module):\n",
    "    \"\"\"Equinox implementation of the plain (dense) FNO spectral convolution.\"\"\"\n",
    "    weight: jax.Array                      # (in_c, out_c, *n_modes)\n",
    "    bias:   Optional[jax.Array] = None     # (out_c, 1, …, 1)\n",
    "\n",
    "    n_modes: Tuple[int, ...] = eqx.static_field()\n",
    "    in_channels:  int  = eqx.static_field()\n",
    "    out_channels: int  = eqx.static_field()\n",
    "    fft_norm: str = eqx.static_field()\n",
    "\n",
    "    # --------------------------------------------------------------------- #\n",
    "    # constructor                                                           #\n",
    "    # --------------------------------------------------------------------- #\n",
    "    def __init__(\n",
    "        self,\n",
    "        key: jax.random.KeyArray,\n",
    "        in_channels: int,\n",
    "        out_channels: int,\n",
    "        n_modes: Sequence[int],\n",
    "        *,\n",
    "        bias: bool = True,\n",
    "        init_std: float | str = \"auto\",\n",
    "        fft_norm: str = \"forward\",\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        key          : PRNG key for weight/bias init\n",
    "        in_channels  : C_in\n",
    "        out_channels : C_out\n",
    "        n_modes      : number of modes kept on each spatial axis\n",
    "                       (note: the last entry counts rFFT coefficients)\n",
    "        bias         : add a channel‑wise bias after the inverse FFT\n",
    "        init_std     : std‐dev for weight init.  'auto' = He like in FNO.\n",
    "        fft_norm     : 'forward' (like original code) or any jnp.fft option\n",
    "        \"\"\"\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.n_modes = tuple(int(m) for m in n_modes)\n",
    "        self.fft_norm = fft_norm\n",
    "\n",
    "        if init_std == \"auto\":\n",
    "            init_std = (2 / (in_channels + out_channels)) ** 0.5\n",
    "\n",
    "        key_w, key_b = jax.random.split(key)\n",
    "        w_shape = (in_channels, out_channels, *self.n_modes)\n",
    "        # complex weight, iid N(0,σ²) on both real & imag parts\n",
    "        self.weight = (\n",
    "            init_std\n",
    "            * (jax.random.normal(key_w, w_shape) + 1j * jax.random.normal(key_w, w_shape))\n",
    "        ).astype(jnp.complex64)\n",
    "\n",
    "        if bias:\n",
    "            # shape: (C_out, 1, 1, …)\n",
    "            b_shape = (out_channels,) + (1,) * len(self.n_modes)\n",
    "            self.bias = init_std * jax.random.normal(key_b, b_shape)\n",
    "        else:\n",
    "            self.bias = None\n",
    "\n",
    "    # --------------------------------------------------------------------- #\n",
    "    # forward                                                               #\n",
    "    # --------------------------------------------------------------------- #\n",
    "    def __call__(self, x: jax.Array) -> jax.Array:  # (B, C_in, *spatial)\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : real valued tensor of shape (batch, in_channels, d1, …, dN)\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        y : real tensor of shape (batch, out_channels, d1, …, dN)\n",
    "        \"\"\"\n",
    "        batch, cin, *spatial = x.shape\n",
    "        assert cin == self.in_channels, \"channel mismatch\"\n",
    "\n",
    "        fft_axes = tuple(range(-len(spatial), 0))            # last N axes\n",
    "        x_ft = jnp.fft.rfftn(x, axes=fft_axes, norm=self.fft_norm)          # → complex64\n",
    "        if len(spatial) > 1:                                 # shift except rFFT axis\n",
    "            x_ft = jnp.fft.fftshift(x_ft, axes=fft_axes[:-1])\n",
    "\n",
    "        # build zero‑filled spectrum for the output\n",
    "        out_ft = jnp.zeros(\n",
    "            (batch, self.out_channels, *x_ft.shape[2:]),\n",
    "            dtype=x_ft.dtype\n",
    "        )\n",
    "\n",
    "        # centred cropping\n",
    "        crop_slices = _central_crop_slices(x_ft.shape[2:], self.n_modes)\n",
    "        xs = (slice(None), slice(None), *crop_slices)        # for x_ft / out_ft\n",
    "        ws = (slice(None), slice(None), *([slice(None)] * len(self.n_modes)))\n",
    "\n",
    "        # contraction in Fourier domain\n",
    "        out_crop = jnp.einsum(\n",
    "            \"b i ... , i o ... -> b o ...\",                  # Einstein notation\n",
    "            x_ft[xs], self.weight[ws]\n",
    "        )\n",
    "        out_ft = out_ft.at[xs].set(out_crop)\n",
    "\n",
    "        # inverse shift & inverse FFT\n",
    "        if len(spatial) > 1:\n",
    "            out_ft = jnp.fft.ifftshift(out_ft, axes=fft_axes[:-1])\n",
    "\n",
    "        y = jnp.fft.irfftn(out_ft, s=spatial, axes=fft_axes, norm=self.fft_norm)\n",
    "\n",
    "        if self.bias is not None:\n",
    "            y = y + self.bias\n",
    "\n",
    "        return y.real                                         # ensure real output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "982fb31c-76c0-4fdf-8eee-6cefda1c7269",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax, jax.numpy as jnp, equinox as eqx\n",
    "#from spectral_conv_opt_nb import SpectralConv\n",
    "\n",
    "key = jax.random.PRNGKey(0)\n",
    "conv = SpectralConv(key, in_channels=4, out_channels=8, n_modes=(16, 16))\n",
    "\n",
    "in_c = 4\n",
    "out_c = 8\n",
    "h = 64\n",
    "w = 64\n",
    "x = jax.random.normal(key, (in_c, h, w))   # (Cin,H,W)\n",
    "#y_single = conv(x_single)                        # (Cout,H,W)\n",
    "                   # (B,Cout,H,W)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "a84a079b-c5e5-41c2-971a-0b5da17b320b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax, jax.numpy as jnp, equinox as eqx\n",
    "#from spectral_conv_opt_nb import SpectralConv\n",
    "\n",
    "key = jax.random.PRNGKey(0)\n",
    "#conv = SpectralConv(key, in_channels=4, out_channels=8, n_modes=(16, 16))\n",
    "\n",
    "in_c = 4\n",
    "out_c = 8\n",
    "h = 64\n",
    "w = 64\n",
    "n_modes = 9\n",
    "x = jax.random.normal(key, (in_c, h, w))   # (Cin,H,W)\n",
    "#y_single = conv(x_single)                        # (Cout,H,W)\n",
    "                   # (B,Cout,H,W)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a98767da-3f7d-49e4-81a3-44e05a1f39d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "subkey, key = jax.random.split(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "6b8123ea-e1b2-4a1c-a700-c81b1b28e287",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpectralConv:\n",
    "    weights: jax.Array\n",
    "    bias: Optional[jax.Array]\n",
    "    in_channels:  int  = eqx.static_field()\n",
    "    out_channels:  int  = eqx.static_field()\n",
    "    n_modes:  int  = eqx.static_field()\n",
    "    def __init__(self, in_channels, out_channels, n_modes, height, width, use_bias, key):\n",
    "        \n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.n_modes = n_modes\n",
    "        self.use_bias = use_bias\n",
    "\n",
    "        key_w, key_b = jax.random.split(subkey)\n",
    "\n",
    "        # weights go from in_c to out_c, squares of size n_modes x n_modes\n",
    "        w_shape = (in_c, out_c, 2*n_modes[0], n_modes[1])\n",
    "        self.weight = jax.random.normal(key_w, w_shape) + 1j*jax.random.normal(key_w, w_shape)\n",
    "        \n",
    "        # one bias per output channel, broadcast along spatial dimensions.\n",
    "        if use_bias:\n",
    "            b_shape = (out_c,) + (1,) * len(spatial)\n",
    "            self.bias = jnp.zeros(b_shape)\n",
    "        \n",
    "    def _build_slices(self, spatial):\n",
    "        \n",
    "        # Build slices for x: we grab n_modes x n_modes corners\n",
    "        center_slice = spatial[0]//2\n",
    "        start_slice = center_slice - self.n_modes[0]\n",
    "        end_slice = center_slice + self.n_modes[0]\n",
    "        x_slices = (slice(None), slice(start_slice, end_slice), slice(0, self.n_modes[1]))\n",
    "\n",
    "    def __call__(self, x):\n",
    "        \n",
    "        _, *spatial = x.shape\n",
    "\n",
    "        # do fft on spatial dimensions \n",
    "        fft_axes = tuple(range(-len(x.shape)+1, 0))\n",
    "        x_ft = jnp.fft.fftshift(jnp.fft.rfftn(x, axes = fft_axes), axes=fft_axes[:-1])\n",
    "\n",
    "        # create slices to grab corners of input\n",
    "        slices = self._build_slices(spatial)\n",
    "\n",
    "        # contract weight and corners of x over input channels.\n",
    "        out_ft_crop = jnp.einsum(\"i...,io...->o...\", x_ft[x_slices], w)\n",
    "        \n",
    "        # Create and fill output \n",
    "        out_ft = jnp.zeros((out_c, *x_ft.shape[1:]), dtype=x_ft.dtype)\n",
    "        out_ft = out_ft.at[x_slices].set(out_ft_crop)\n",
    "        out = jnp.fft.irfftn(jnp.fft.fftshift(out_ft, axes=fft_axes[:-1]), axes=fft_axes)\n",
    "        if self.use_bias:\n",
    "            out += self.bias\n",
    "        return out\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "c5c1436e-d1a4-47e9-a7c5-7e5bfe0bf3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_modes = [3, 5, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "8f629dcc-3401-4c6b-be36-18e4f2a5d767",
   "metadata": {},
   "outputs": [],
   "source": [
    "double_modes = (2*mode for mode in n_modes[:-1])\n",
    "w_shape = (in_c, out_c, *double_modes, n_modes[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "021a5f03-debf-4423-846e-10a53f0eea3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 8, 6, 10, 3)"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "d7780477-57c8-4367-91d1-00956612e930",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpectralConvND:\n",
    "    weights: jax.Array\n",
    "    bias: Optional[jax.Array]\n",
    "    in_channels: int = eqx.static_field()\n",
    "    out_channels: int = eqx.static_field()\n",
    "    n_modes: List[int] = eqx.static_field()\n",
    "    use_bias: bool = eqx.static_field()\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, n_modes, use_bias, key):\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.n_modes = n_modes\n",
    "        self.use_bias = use_bias\n",
    "\n",
    "        key_w, key_b = jax.random.split(key)\n",
    "\n",
    "        # weights go from in_c to out_c, squares of size n_modes x n_modes\n",
    "        double_modes = (2 * mode for mode in n_modes[:-1])\n",
    "        w_shape = (in_channels, out_channels, *double_modes, n_modes[-1])\n",
    "        self.weight = jax.random.normal(\n",
    "            key_w, w_shape) + 1j * jax.random.normal(key_w, w_shape)\n",
    "\n",
    "        # one bias per output channel, broadcast along spatial dimensions.\n",
    "        if use_bias:\n",
    "            b_shape = (out_channels, ) + (1, ) * len(n_modes)\n",
    "            self.bias = jnp.zeros(b_shape)\n",
    "\n",
    "    def _build_slices(self, spatial):\n",
    "\n",
    "        x_slices = [slice(None)]\n",
    "        # Build slices for x: we grab n_modes x n_modes corners\n",
    "        for i in range(len(spatial[:-1])):\n",
    "            center_slice = spatial[i] // 2\n",
    "            start_slice = center_slice - self.n_modes[i]\n",
    "            end_slice = center_slice + self.n_modes[i]\n",
    "            x_slices += [slice(start_slice, end_slice)]\n",
    "\n",
    "        x_slices += [slice(0, self.n_modes[-1])]\n",
    "        return tuple(x_slices)\n",
    "\n",
    "    def __call__(self, x):\n",
    "\n",
    "        _, *spatial = x.shape\n",
    "\n",
    "        assert len(spatial) == len(self.n_modes), \\\n",
    "        f'Dimension error, x is of dimensions {len(spatial)} \\\n",
    "        and spectral conv of dimension {len(self.n_modes)}'\n",
    "\n",
    "        # do fft on spatial dimensions\n",
    "        fft_axes = tuple(range(-len(x.shape) + 1, 0))\n",
    "        x_ft = jnp.fft.fftshift(jnp.fft.rfftn(x, axes=fft_axes),\n",
    "                                axes=fft_axes[:-1])\n",
    "\n",
    "        # create slices to grab corners of input\n",
    "        slices = self._build_slices(spatial)\n",
    "\n",
    "        # contract weight and corners of x over input channels.\n",
    "        out_ft_crop = jnp.einsum(\"i...,io...->o...\", x_ft[slices], self.weight)\n",
    "\n",
    "        # Create and fill output\n",
    "        out_ft = jnp.zeros((self.out_channels, *x_ft.shape[1:]),\n",
    "                           dtype=x_ft.dtype)\n",
    "        out_ft = out_ft.at[slices].set(out_ft_crop)\n",
    "        out = jnp.fft.irfftn(jnp.fft.fftshift(out_ft, axes=fft_axes[:-1]),\n",
    "                             axes=fft_axes)\n",
    "        if self.use_bias:\n",
    "            out += self.bias\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "816c8aaa-414a-4a26-9582-18ffc05b4d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_modes = [5, 6, 7]\n",
    "key = jax.random.PRNGKey(0)\n",
    "\n",
    "x = jax.random.normal(key, (in_c, 64, 64, 64))   # (Cin,H,W)\n",
    "\n",
    "test = SpectralConvND(in_c, out_c, n_modes, True, key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "ba03b96e-a678-4055-b3f5-077cf3d82bfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 64, 64, 64)"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_test = test(x)\n",
    "out_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "9d7848e4-98cd-4c45-860f-8bf0a4a3e949",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "n_modes = [5, 7]\n",
    "\n",
    "in_c, *spatial = x.shape\n",
    "\n",
    "# fft on spatial dimensions then fftshift to zero center\n",
    "fft_axes = tuple(range(-len(x.shape)+1, 0))\n",
    "x_ft = jnp.fft.fftshift(jnp.fft.rfftn(x, axes = fft_axes), axes=fft_axes[:-1])\n",
    "\n",
    "# weights go from in_c to out_c, squares of size n_modes x n_modes\n",
    "key_w, key_b = jax.random.split(subkey)\n",
    "w_shape = (in_c, out_c, 2*n_modes[0], n_modes[1])\n",
    "w = jax.random.normal(key_w, w_shape) + 1j*jax.random.normal(key_w, w_shape)\n",
    "\n",
    "# one bias per output channel, broadcast along spatial dimensions.\n",
    "b_shape = (out_c) + (1) * len(spatial)\n",
    "b = jnp.zeros(b_shape)\n",
    "\n",
    "# Build slices for x: we grab n_modes x n_modes corners\n",
    "center_slice = spatial[0]//2\n",
    "start_slice = center_slice - n_modes[0]\n",
    "end_slice = center_slice + n_modes[0]\n",
    "x_slices = (slice(None), slice(start_slice, end_slice), slice(0, n_modes[1]))\n",
    "\n",
    "# contract weight and corners of x over input channels.\n",
    "out_ft_crop = jnp.einsum(\"i...,io...->o...\", x_ft[x_slices], w)\n",
    "\n",
    "# Create and fill output \n",
    "out_ft = jnp.zeros((out_c, *x_ft.shape[1:]), dtype=x_ft.dtype)\n",
    "out_ft = out_ft.at[x_slices].set(out_ft_crop)\n",
    "\n",
    "# fftshift and fft back\n",
    "out = jnp.fft.irfftn(jnp.fft.fftshift(out_ft, axes=fft_axes[:-1]), axes=fft_axes)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "fc68e644-6225-4e96-8c33-8d12d943bbe8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 12, 7)"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_ft[x_slices].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "ec4b0595-f53a-4c6f-bd1e-592a1aaafd34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 8, 10, 7)"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "180ce2bc-a6a2-4025-aef9-2808b1885f47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 18, 9)"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_ft[x_slices].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "8564d595-0900-4ab2-9d68-783c4a407e9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_modes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "24fbb272-a579-491d-a6d7-a2bded24727b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 64, 33)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_ft.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "6f65e8ef-9ddd-4843-b6d1-be7b462e866c",
   "metadata": {},
   "outputs": [],
   "source": [
    "corners = jnp.r_[:n_modes, spatial[1]-n_modes:spatial[1]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "70e73bd1-7165-433a-83b1-c3125e9823d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_slice = (slice(None), corners, slice(0, n_modes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "d5364f14-25c3-4fab-af71-4f4624ab99ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 16, 8)"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_ft[test_slice].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "d27b2d34-280f-4732-b8a3-d7f6b2777542",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 64, 8)"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_ft[:, corners, slice(0,n_modes)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "243a9eba-85dc-4e8c-8bcd-a26ec4c75387",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 64, 64)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "849fb139-23a7-4fc6-b13a-8bb8eba4bfc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 64, 64)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "48ca7522-818f-491d-8665-bbed5d250346",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 64, 33)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_ft.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "91ca2620-659f-4082-a74a-68a39f84b94b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 15, 15)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_sliced.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "c92e981c-5c60-4240-8874-eb479a13700c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 8, 15, 15)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "c8c8fd20-9617-4a95-9103-6a194664fb0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_shape = (in_c, out_c, 2*n_modes[0]) + tuple(n_modes[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "745ed0df-edfe-4bfa-b6bf-29e173c4c5f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 8, 10, 7)"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "d1fd5d66-1a00-4c6a-b0c6-dbf3f8aecb5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2240"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "math.prod(w_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e558f4-7057-41a6-b5ab-37c40c65d063",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
