{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cloning the github repository...\n",
      "\n",
      "\n",
      "Loading the Annotation Vocabulary...\n",
      "\n",
      "\n",
      "Importing dependencies...\n",
      "\n",
      "\n",
      "Loading the model...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83b76942aaf64ad595a1bc47d88fd4de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modeling_fastesm.py:   0%|          | 0.00/41.4k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/Synthyra/ESM2-650M:\n",
      "- modeling_fastesm.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "Some weights of FastEsmModel were not initialized from the model checkpoint at Synthyra/ESM2-650M and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b913c0a971d74c7b8dfb657c7300ddde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.84G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of FastEsmModel were not initialized from the model checkpoint at Synthyra/ESM2-650M and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "#@title **Setup**\n",
    "\n",
    "#@markdown ### Identification\n",
    "huggingface_token = \"\" #@param {type:\"string\"}\n",
    "github_token = \"\" #@param {type:\"string\"}\n",
    "#@markdown ---\n",
    "\n",
    "github_clone_path = f\"https://{github_token}@github.com/Synthyra/TranslatorInference.git\"\n",
    "\n",
    "print(\"\\nCloning the github repository...\\n\")\n",
    "# !git clone {github_clone_path}\n",
    "# %cd TranslatorInference\n",
    "# !pip install -r requirements.txt --quiet\n",
    "\n",
    "if huggingface_token:\n",
    "    print(\"\\nLogging into HuggingFace...\\n\")\n",
    "    from huggingface_hub import login\n",
    "    login(huggingface_token)\n",
    "\n",
    "print(\"\\nLoading the Annotation Vocabulary...\\n\")\n",
    "import pickle\n",
    "with open('id2label.pkl', 'rb') as f:\n",
    "    id2label = pickle.load(f)\n",
    "\n",
    "with open('label2id.pkl', 'rb') as f:\n",
    "    label2id = pickle.load(f)\n",
    "\n",
    "\n",
    "from annotation_mapping import name_ec, ec_name, name_go, go_name, name_ip, ip_name, name_gene, gene_name\n",
    "annotation_vocab_dict = {\n",
    "    'ec': (name_ec, ec_name),\n",
    "    'go': (name_go, go_name),\n",
    "    'ip': (name_ip, ip_name),\n",
    "    '3d': (name_gene, gene_name)\n",
    "}\n",
    "\n",
    "print(\"\\nImporting dependencies...\\n\")\n",
    "import torch\n",
    "import ipywidgets as widgets\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "from utils import describe_prompt, return_preds, get_probs\n",
    "from model import SeqToAnnTranslator, TranslatorConfig\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "print(\"\\nLoading the model...\\n\")\n",
    "model_path = 'lhallee/translator_seq_to_ann_final'\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "config = TranslatorConfig.from_pretrained(model_path)\n",
    "model = SeqToAnnTranslator(config).from_pretrained(model_path).eval().to(device)\n",
    "tokenizer = model.esm.tokenizer\n",
    "\n",
    "\n",
    "aspect_dict = {\n",
    "    'ec': 'Enzyme Comission Number',\n",
    "    'bp': 'GO Biological Process',\n",
    "    'cc': 'GO Cellular Component',\n",
    "    'mf': 'GO Molecular Function',\n",
    "    'ip': 'InterPro',\n",
    "    'threed': 'Gene3D',\n",
    "    'keywords': 'Uniprot Keywords'\n",
    "}\n",
    "#@markdown *Press play to setup the environment*\n",
    "\n",
    "#@markdown ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title **Inference**\n",
    "#@markdown Enter a sequence to annotate\n",
    "seq = \"MDEMILLRRVLLAGFICALLVPSGLSCGPGRGIGTRKRFKKLTPLAYKQFTPNVPEKTLGASGRYEGKITRNSERFKELTPNYNPDIIFKDEENTGADRLMTQRCKDKLNALAISVMNQWPGVKLRVTEGWDEDGHHFEESLHYEGRAVDITTSDRDRSKYGMLARLAAEAGFDWVYFESKAHIHCSVKAENSVAAKSGGCFPGSATVALEQGVRIPVKDLRPGDRVLAADGLGKLVYSDFLLFMDKEETVRKVFYVIETSRERVRLTAAHLLFVGQAHPGNDSGGDFRSVFGSAGFRSMFASSVRAGHRVLTVDREGRGLREATVERVYLEEATGAYAPVTAHGTVVIDRVLASCYAVIEEHSWAHWAFAPLRVGLGILSFFSPQDYSSHSPPAPSQSEGVHWYSEILYRIGTWVLQEDTIHPLGMAAKSS\" #@param {type:\"string\"}\n",
    "\n",
    "num_annotations = 32\n",
    "seqs = [seq]\n",
    "\n",
    "probs = get_probs(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    seqs=seqs,\n",
    "    num_annotations=num_annotations,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "#@markdown Press play to annotate\n",
    "#@markdown ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title A guide to topk and confidence\n",
    "\n",
    "#@markdown ---\n",
    "#@markdown **Translator** predicts a fixed number of protein annotations from the [**Annotation Vocabulary**](https://www.biorxiv.org/content/10.1101/2024.07.30.605924v1) from an input protein sequence.\n",
    "\n",
    "#@markdown The `topk` parameter controls the number of annotations retrieved per \"token.\"\n",
    "\n",
    "#@markdown The `confidence` parameter controls the minimum predicted confidence score for an annotation to be included in the output.\n",
    "\n",
    "#@markdown Shown below is a figure showcasing the trade-off between topk and confidence. A higher topk value will result in more annotations being retrieved, but at the cost of lower confidence and precision.\n",
    "\n",
    "#@markdown Lower topk values will result in higher precision, meaning each annotation shown is more likely to be correct.\n",
    "\n",
    "#@markdown Higher topk values will result in higher recall, meaning that within the set of annotations, more are likely to be retrieved.\n",
    "\n",
    "#@markdown A very high topk value is way to explore possible annotations but is less likely to be accurate.\n",
    "\n",
    "#@markdown The optimal topk value is a trade-off between precision and recall, often measured by their harmonic mean (F1 score), which is at topk=3 for our evaluation sets.\n",
    "\n",
    "#@markdown The figure also showcasing the minimum confidence score at each topk value such that **every annotation above that confidence was correctly predicted**.\n",
    "\n",
    "#@markdown Therefore, you can adjust topk and confidence to be more \"sure\" about the output or more \"exploratory.\"\n",
    "\n",
    "#@markdown ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6ca5192ca4c4a9ea39675d7bdad2cac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(BoundedIntText(value=3, description='TopK', min=1), BoundedFloatText(value=0.04, description='M…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "713d30b0cf6945708ec06851953f557c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output(layout=Layout(border_bottom='1px solid #ddd', border_left='1px solid #ddd', border_right='1px solid #dd…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#@title **Press play to view results**\n",
    "\n",
    "#@markdown ---\n",
    "#@markdown Annotations are colored by confidence, with blue being the lowest confidence and red being the highest.\n",
    "#@markdown In general, anything above 0.1 is fairly high confidence (as they sum to 1 over 88000 options!).\n",
    "\n",
    "topk_text = widgets.BoundedIntText(\n",
    "    value=3,\n",
    "    min=1,\n",
    "    max=100,\n",
    "    step=1,\n",
    "    description='TopK',\n",
    "    continuous_update=False\n",
    ")\n",
    "\n",
    "confidence_text = widgets.BoundedFloatText(\n",
    "    value=0.04,\n",
    "    min=0.0,\n",
    "    max=1.0,\n",
    "    step=0.01,\n",
    "    description='Min Confidence',\n",
    "    continuous_update=False\n",
    ")\n",
    "\n",
    "# Create the Output widget and enforce white background + scrolling.\n",
    "output = widgets.Output()\n",
    "# Set a large height, enable scrolling, and explicitly set background to white:\n",
    "output.layout = widgets.Layout(\n",
    "    height='1000px',\n",
    "    overflow='auto',         # or 'scroll'\n",
    "    border='1px solid #ddd'\n",
    ")\n",
    "\n",
    "def color_text_by_conf(text, conf):\n",
    "    \"\"\"\n",
    "    Returns an HTML <span> with color going from blue (conf=0) to red (conf=1).\n",
    "    \"\"\"\n",
    "    red_val   = int(conf * 255)\n",
    "    blue_val  = 255 - red_val\n",
    "    return f\"<span style='color:rgb({red_val},0,{blue_val}); font-weight:bold;'>{text} ({conf:.4f})</span>\"\n",
    "\n",
    "def update_output(*args):\n",
    "    with output:\n",
    "        output.clear_output()\n",
    "        \n",
    "        # Get the widget values:\n",
    "        topk_val = topk_text.value\n",
    "        confidence_val = confidence_text.value\n",
    "        \n",
    "        # Get filtered predictions\n",
    "        final_ids, confidences = return_preds(\n",
    "            probs=probs,\n",
    "            topk=topk_val, \n",
    "            minimum_confidence=confidence_val\n",
    "        )\n",
    "        \n",
    "        described, track_ids = describe_prompt(final_ids, id2label, annotation_vocab_dict)\n",
    "        conf_map = dict(zip(final_ids, confidences))\n",
    "        \n",
    "        html_output = \"\"\n",
    "        for aspect, entries in described.items():\n",
    "            aspect_name = aspect_dict.get(aspect, aspect)\n",
    "            html_output += f\"<h4 style='color:black; font-weight:bold;'>{aspect_name}</h4>\"\n",
    "            for entry in entries:\n",
    "                id_ = track_ids[entry]\n",
    "                conf = conf_map.get(id_, 0.0)\n",
    "                html_output += color_text_by_conf(entry, conf) + \"<br>\"\n",
    "            html_output += \"<hr>\"\n",
    "        \n",
    "        # Display the HTML, wrapped in a white background div just in case:\n",
    "        html_output = f\"<div style='background-color:white;'>{html_output}</div>\"\n",
    "        display(HTML(html_output))\n",
    "        \n",
    "        # Force scroll to the top with a tiny JS snippet.\n",
    "        # This attempts to find the container of the current output and reset scrollTop.\n",
    "        scroll_to_top_js = \"\"\"\n",
    "        <script>\n",
    "        // Grab the closest output area for this cell (the ipywidget .output_scroll or .jupyter-widgets-output-area)\n",
    "        let out_area = this.closest('.jupyter-widgets-output-area') || this.closest('.output_scroll');\n",
    "        if (out_area) {\n",
    "            out_area.scrollTop = 0;\n",
    "        }\n",
    "        </script>\n",
    "        \"\"\"\n",
    "        display(HTML(scroll_to_top_js))\n",
    "\n",
    "# Observe changes\n",
    "topk_text.observe(update_output, names='value')\n",
    "confidence_text.observe(update_output, names='value')\n",
    "\n",
    "# Display widgets and output\n",
    "display(widgets.VBox([topk_text, confidence_text]), output)\n",
    "\n",
    "# Initialize the display\n",
    "update_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 25\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_dataset\n\u001b[1;32m---> 25\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m \u001b[43mload_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m     seqs \u001b[38;5;241m=\u001b[39m dataset[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseqs\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     28\u001b[0m results \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\Users\\lhall\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\datasets\\load.py:2606\u001b[0m, in \u001b[0;36mload_dataset\u001b[1;34m(path, name, data_dir, data_files, split, cache_dir, features, download_config, download_mode, verification_mode, ignore_verifications, keep_in_memory, save_infos, revision, token, use_auth_token, task, streaming, num_proc, storage_options, trust_remote_code, **config_kwargs)\u001b[0m\n\u001b[0;32m   2601\u001b[0m verification_mode \u001b[38;5;241m=\u001b[39m VerificationMode(\n\u001b[0;32m   2602\u001b[0m     (verification_mode \u001b[38;5;129;01mor\u001b[39;00m VerificationMode\u001b[38;5;241m.\u001b[39mBASIC_CHECKS) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m save_infos \u001b[38;5;28;01melse\u001b[39;00m VerificationMode\u001b[38;5;241m.\u001b[39mALL_CHECKS\n\u001b[0;32m   2603\u001b[0m )\n\u001b[0;32m   2605\u001b[0m \u001b[38;5;66;03m# Create a dataset builder\u001b[39;00m\n\u001b[1;32m-> 2606\u001b[0m builder_instance \u001b[38;5;241m=\u001b[39m \u001b[43mload_dataset_builder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2607\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2608\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2609\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2610\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_files\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2611\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2612\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2613\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2614\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdownload_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2615\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2616\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2617\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2618\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2619\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_require_default_config_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   2620\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mconfig_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2621\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2623\u001b[0m \u001b[38;5;66;03m# Return iterable dataset in case of streaming\u001b[39;00m\n\u001b[0;32m   2624\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m streaming:\n",
      "File \u001b[1;32mc:\\Users\\lhall\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\datasets\\load.py:2277\u001b[0m, in \u001b[0;36mload_dataset_builder\u001b[1;34m(path, name, data_dir, data_files, cache_dir, features, download_config, download_mode, revision, token, use_auth_token, storage_options, trust_remote_code, _require_default_config_name, **config_kwargs)\u001b[0m\n\u001b[0;32m   2275\u001b[0m     download_config \u001b[38;5;241m=\u001b[39m download_config\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m download_config \u001b[38;5;28;01melse\u001b[39;00m DownloadConfig()\n\u001b[0;32m   2276\u001b[0m     download_config\u001b[38;5;241m.\u001b[39mstorage_options\u001b[38;5;241m.\u001b[39mupdate(storage_options)\n\u001b[1;32m-> 2277\u001b[0m dataset_module \u001b[38;5;241m=\u001b[39m \u001b[43mdataset_module_factory\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2278\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2279\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2280\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2281\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdownload_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2282\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2283\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_files\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2284\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2285\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2286\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_require_default_config_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_require_default_config_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2287\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_require_custom_configs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mbool\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mconfig_kwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2288\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2289\u001b[0m \u001b[38;5;66;03m# Get dataset builder class from the processing script\u001b[39;00m\n\u001b[0;32m   2290\u001b[0m builder_kwargs \u001b[38;5;241m=\u001b[39m dataset_module\u001b[38;5;241m.\u001b[39mbuilder_kwargs\n",
      "File \u001b[1;32mc:\\Users\\lhall\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\datasets\\load.py:1786\u001b[0m, in \u001b[0;36mdataset_module_factory\u001b[1;34m(path, revision, download_config, download_mode, dynamic_modules_path, data_dir, data_files, cache_dir, trust_remote_code, _require_default_config_name, _require_custom_configs, **download_kwargs)\u001b[0m\n\u001b[0;32m   1783\u001b[0m download_config\u001b[38;5;241m.\u001b[39mforce_extract \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1784\u001b[0m download_config\u001b[38;5;241m.\u001b[39mforce_download \u001b[38;5;241m=\u001b[39m download_mode \u001b[38;5;241m==\u001b[39m DownloadMode\u001b[38;5;241m.\u001b[39mFORCE_REDOWNLOAD\n\u001b[1;32m-> 1786\u001b[0m filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mfilter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreplace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m   1787\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m filename\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.py\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m   1788\u001b[0m     filename \u001b[38;5;241m=\u001b[39m filename \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.py\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "#@title **High throughput annotation**\n",
    "topk = \"3\" #@param {type:\"string\"}\n",
    "min_confidence = \"0.04\" #@param {type:\"string\"}\n",
    "#@markdown Number of annotations refers to how many annotation `tokens` are predicted.\n",
    "#@markdown The model is trained to predict between 1 and 62 annotations.\n",
    "#@markdown 32 is a good default.\n",
    "num_annotations = 32 #@param {type:\"slider\", min:1, max:62, step:1}\n",
    "\n",
    "#@markdown ---\n",
    "#@markdown Give local csv with \"seqs\" column or huggingface dataset path with one train split and \"seqs\" column.\n",
    "#@markdown Outputs to a local csv\n",
    "data_path = \"\" #@param {type:\"string\"}\n",
    "local = False #@param {type:\"boolean\"}\n",
    "output_path = \"results.csv\" #@param {type:\"string\"}\n",
    "\n",
    "topk = int(topk)\n",
    "confidence = float(min_confidence)\n",
    "num_annotations = int(num_annotations)\n",
    "\n",
    "if local:\n",
    "    dataset = pd.read_csv(data_path)\n",
    "    seqs = dataset[\"seqs\"].tolist()\n",
    "else:\n",
    "    from datasets import load_dataset\n",
    "    dataset = load_dataset(data_path)\n",
    "    seqs = dataset[\"train\"][\"seqs\"]\n",
    "\n",
    "results = []\n",
    "for seq in tqdm(seqs, desc=\"Annotating sequences\"):\n",
    "    probs = get_probs(\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        seqs=[seq],\n",
    "        num_annotations=num_annotations,\n",
    "        device=device\n",
    "    )\n",
    "\n",
    "    final_ids, confidences = return_preds(\n",
    "        probs=probs, \n",
    "        topk=topk, \n",
    "        minimum_confidence=confidence\n",
    "    )\n",
    "\n",
    "    described, track_ids = describe_prompt(final_ids, id2label, annotation_vocab_dict)\n",
    "    conf_map = dict(zip(final_ids, confidences))\n",
    "\n",
    "    result_dict = {\"seqs\": seq}\n",
    "    \n",
    "    for aspect, entries in described.items():\n",
    "        aspect_name = aspect_dict.get(aspect, aspect)\n",
    "        entries_with_conf = []\n",
    "        for entry in entries:\n",
    "            id_ = track_ids[entry]\n",
    "            conf = conf_map.get(id_, 0.0)\n",
    "            entries_with_conf.append((entry, conf))\n",
    "        # Sort entries by confidence in descending order\n",
    "        entries_with_conf.sort(key=lambda x: x[1], reverse=True)\n",
    "        # Format entries after sorting\n",
    "        formatted_entries = [f\"{entry} ({conf:.4f})\" for entry, conf in entries_with_conf]\n",
    "        result_dict[aspect_name] = \"; \".join(formatted_entries)\n",
    "    \n",
    "    results.append(result_dict)\n",
    "\n",
    "# Create and save DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv(output_path, index=False)\n",
    "print(f\"Results saved to {output_path}\")\n",
    "\n",
    "#@markdown Press play to annotate your dataset\n",
    "#@markdown ---\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
