# PgDbToolkit üìä

![Python](https://img.shields.io/badge/python-3.8%2B-blue)
![License](https://img.shields.io/badge/license-MIT-green)
![PostgreSQL](https://img.shields.io/badge/postgresql-14%2B-blue)
![Psycopg](https://img.shields.io/badge/psycopg-3.1%2B-brightgreen)
![Build](https://img.shields.io/badge/build-passing-brightgreen)

`PgDbToolkit` es una biblioteca Python robusta y completa para interactuar con bases de datos PostgreSQL, ofreciendo tanto operaciones sincr√≥nicas como as√≠ncronas con una API elegante y consistente. Dise√±ada para desarrolladores que buscan simplicidad sin sacrificar potencia, esta biblioteca facilita todo desde operaciones CRUD b√°sicas hasta consultas vectoriales avanzadas y migraciones de esquemas.

## Tabla de Contenidos

- [PgDbToolkit üìä](#pgdbtoolkit-)
  - [Tabla de Contenidos](#tabla-de-contenidos)
  - [Caracter√≠sticas Principales ‚ú®](#caracter√≠sticas-principales-)
  - [Instalaci√≥n üöÄ](#instalaci√≥n-)
  - [Configuraci√≥n üõ†Ô∏è](#configuraci√≥n-Ô∏è)
    - [Usando variables de entorno](#usando-variables-de-entorno)
    - [Configuraci√≥n directa](#configuraci√≥n-directa)
  - [Ejemplos de Uso üíª](#ejemplos-de-uso-)
    - [API Sincr√≥nica](#api-sincr√≥nica)
    - [API Asincr√≥nica](#api-asincr√≥nica)
    - [Uso de Pools de Conexiones](#uso-de-pools-de-conexiones)
    - [Soporte para Vectores y B√∫squeda por Similitud](#soporte-para-vectores-y-b√∫squeda-por-similitud)
    - [Sistema de Migraciones](#sistema-de-migraciones)
    - [Validaci√≥n de Datos](#validaci√≥n-de-datos)
  - [Caracter√≠sticas Avanzadas üî•](#caracter√≠sticas-avanzadas-)
    - [Operaciones por Lotes](#operaciones-por-lotes)
    - [Transacciones At√≥micas](#transacciones-at√≥micas)
    - [Logging Personalizado](#logging-personalizado)
    - [Soft Delete](#soft-delete)
    - [Exportaci√≥n de Datos](#exportaci√≥n-de-datos)
    - [Gesti√≥n de Usuarios](#gesti√≥n-de-usuarios)
  - [API Completa üìö](#api-completa-)
    - [Gesti√≥n de Bases de Datos](#gesti√≥n-de-bases-de-datos)
    - [Gesti√≥n de Tablas](#gesti√≥n-de-tablas)
    - [Gesti√≥n de Registros](#gesti√≥n-de-registros)
    - [Operaciones Vectoriales](#operaciones-vectoriales)
    - [Utilidades](#utilidades)
  - [Manejo de Errores üõ°Ô∏è](#manejo-de-errores-Ô∏è)
  - [Roadmap üõ£Ô∏è](#roadmap-Ô∏è)
  - [Contribuciones üë•](#contribuciones-)
  - [Licencia üìÑ](#licencia-)

## Caracter√≠sticas Principales ‚ú®

- **API Dual**: Implementaciones sincr√≥nica (`PgDbToolkit`) y asincr√≥nica (`AsyncPgDbToolkit`) con interfaces id√©nticas
- **Manejo Inteligente de Consultas**: Construcci√≥n autom√°tica de consultas SQL complejas con condiciones avanzadas
- **Soporte para pgvector**: Integraci√≥n directa con la extensi√≥n vectorial de PostgreSQL para b√∫squedas de similitud
- **Gesti√≥n de Pools de Conexiones**: Manejo eficiente de m√∫ltiples conexiones simult√°neas
- **Sistema de Migraciones**: Versionado y aplicaci√≥n controlada de cambios de esquema
- **Validaci√≥n Robusta**: Funciones integradas para validar datos antes de su inserci√≥n
- **Manejo Especializado de Errores**: Jerarqu√≠a de excepciones espec√≠ficas para diagn√≥stico preciso
- **Operaciones por Lotes**: Procesamiento eficiente de grandes vol√∫menes de datos con `batch_operation` y `bulk_insert_with_copy`
- **Exportaci√≥n de Datos**: Funcionalidad integrada para exportar resultados de consultas a CSV
- **Transacciones At√≥micas**: Soporte completo para transacciones y operaciones at√≥micas
- **Logging Configurable**: Sistema centralizado de logs con niveles personalizables
- **Soft Delete**: Implementaci√≥n de borrado l√≥gico para mantener historial de registros
- **Gesti√≥n de Usuarios**: Herramientas para la creaci√≥n y gesti√≥n de usuarios de PostgreSQL

## Instalaci√≥n üöÄ

```bash
pip install pgdbtoolkit
```

Para habilitar todas las caracter√≠sticas, incluya los extras:

```bash
pip install "pgdbtoolkit[all]"
```

O instale solo lo que necesite:

```bash
pip install "pgdbtoolkit[async,pool,vector]"
```

## Configuraci√≥n üõ†Ô∏è

### Usando variables de entorno

Cree un archivo `.env` en la ra√≠z de su proyecto:

```env
DB_HOST=localhost
DB_PORT=5432
DB_USER=postgres
DB_PASSWORD=secreto
DB_DATABASE=mi_base_de_datos
DB_SSLMODE=prefer
DB_CONNECT_TIMEOUT=10

# Configuraci√≥n para pools de conexi√≥n
DB_POOL_MIN_SIZE=2
DB_POOL_MAX_SIZE=10
DB_POOL_MAX_IDLE=300
DB_POOL_MAX_LIFETIME=3600
DB_POOL_TIMEOUT=30.0
```

### Configuraci√≥n directa

```python
from pgdbtoolkit import PgDbToolkit, AsyncPgDbToolkit

# Configuraci√≥n personalizada
db_config = {
    "host": "localhost",
    "port": 5432,
    "user": "postgres",
    "password": "secreto",
    "dbname": "mi_base_de_datos"
}

# Versi√≥n sincr√≥nica
db = PgDbToolkit(db_config=db_config)

# Versi√≥n asincr√≥nica
db_async = AsyncPgDbToolkit(db_config=db_config)
```

## Ejemplos de Uso üíª

### API Sincr√≥nica

```python
from pgdbtoolkit import PgDbToolkit

# Inicializar toolkit (usar√° variables de entorno por defecto)
db = PgDbToolkit()

# Crear una tabla
db.create_table("usuarios", {
    "id": "SERIAL PRIMARY KEY",
    "nombre": "VARCHAR(100) NOT NULL",
    "email": "VARCHAR(255) UNIQUE",
    "edad": "INTEGER",
    "activo": "BOOLEAN DEFAULT TRUE",
    "fecha_registro": "TIMESTAMP DEFAULT CURRENT_TIMESTAMP"
})

# Insertar m√∫ltiples registros
usuarios = [
    {"nombre": "Juan P√©rez", "email": "juan@ejemplo.com", "edad": 30},
    {"nombre": "Ana Garc√≠a", "email": "ana@ejemplo.com", "edad": 25},
    {"nombre": "Carlos L√≥pez", "email": "carlos@ejemplo.com", "edad": 35}
]
ids = db.insert_records("usuarios", usuarios)
print(f"IDs insertados: {ids}")

# Consulta avanzada con condiciones
resultados = db.fetch_records(
    "usuarios",
    columns=["id", "nombre", "email"],
    conditions={
        ("edad", ">"): 25,
        "activo": True
    },
    order_by=[("nombre", "ASC")],
    limit=10
)
print(resultados)

# Actualizar registros
db.update_records(
    "usuarios",
    {"activo": False},
    {"id": 1}
)

# Eliminar registros con condiciones complejas
db.delete_records(
    "usuarios", 
    {
        "activo": False,
        ("fecha_registro", "<"): "2023-01-01"
    }
)

# Ejecutar query personalizado
df = db.execute_query(
    "SELECT u.nombre, u.email, c.total FROM usuarios u JOIN compras c ON u.id = c.usuario_id WHERE c.total > %s",
    (100,)
)
```

### API Asincr√≥nica

```python
import asyncio
from pgdbtoolkit import AsyncPgDbToolkit

async def main():
    # Inicializar toolkit asincr√≥nico
    db = AsyncPgDbToolkit()
    
    # Crear una tabla
    await db.create_table("productos", {
        "id": "SERIAL PRIMARY KEY",
        "nombre": "VARCHAR(100) NOT NULL",
        "precio": "DECIMAL(10,2)",
        "stock": "INTEGER DEFAULT 0",
        "fecha_creacion": "TIMESTAMP DEFAULT CURRENT_TIMESTAMP"
    })
    
    # Insertar registros en lote
    productos = [{"nombre": f"Producto {i}", "precio": i * 10, "stock": i} for i in range(1000)]
    await db.batch_operation("insert", "productos", productos, batch_size=100)
    
    # Consultar registros con condiciones complejas
    resultados = await db.fetch_records(
        "productos",
        conditions={("precio", "BETWEEN"): [50, 150]},
        order_by=[("precio", "DESC")]
    )
    print(resultados)
    
    # Exportar resultados a CSV
    await db.export_query_to_csv(
        "SELECT * FROM productos WHERE stock < %s",
        (10,),
        filepath="productos_bajos_stock.csv"
    )
    
    # Ejecutar m√∫ltiples operaciones en una transacci√≥n
    await db.execute_transaction([
        ("UPDATE productos SET stock = stock - 1 WHERE id = %s", (42,)),
        ("INSERT INTO ventas (producto_id, cantidad) VALUES (%s, %s)", (42, 1))
    ])

if __name__ == "__main__":
    asyncio.run(main())
```

### Uso de Pools de Conexiones

```python
from pgdbtoolkit import PgConnectionPool, PgAsyncConnectionPool
import asyncio

# Pool sincr√≥nico
with PgConnectionPool(min_size=2, max_size=10) as pool:
    with pool.connection() as conn:
        with conn.cursor() as cur:
            cur.execute("SELECT * FROM usuarios")
            print(cur.fetchall())
    
    # Obtener estad√≠sticas del pool
    stats = pool.stats()
    print(f"Conexiones activas: {stats.get('active', 0)}")

# Pool asincr√≥nico
async def usando_pool_async():
    async with PgAsyncConnectionPool(min_size=2, max_size=10) as pool:
        async with pool.connection() as conn:
            async with conn.cursor() as cur:
                await cur.execute("SELECT * FROM usuarios")
                print(await cur.fetchall())
        
        # Redimensionar el pool din√°micamente
        await pool.resize(min_size=5, max_size=20)
        
        # Obtener estad√≠sticas
        stats = await pool.stats()
        print(f"Conexiones activas: {stats.get('active', 0)}")

asyncio.run(usando_pool_async())
```

### Soporte para Vectores y B√∫squeda por Similitud

```python
import json
import numpy as np

# Habilitar extensi√≥n vector
db.create_vector_extension()

# Crear tabla con campo vector
db.create_table("embeddings", {
    "id": "SERIAL PRIMARY KEY",
    "text": "TEXT NOT NULL",
    "embedding": "vector(1536)"
})

# Insertar un embedding
embedding = np.random.rand(1536).tolist()  # Vector de dimensi√≥n 1536
db.insert_records("embeddings", {
    "text": "Ejemplo de texto para embedding",
    "embedding": embedding
})

# B√∫squeda por similaridad utilizando el operador <=> (distancia coseno)
query_embedding = np.random.rand(1536).tolist()
results = db.execute_query(
    "SELECT id, text, 1 - (embedding <=> %s::vector) as similarity FROM embeddings ORDER BY similarity DESC LIMIT 5",
    (json.dumps(query_embedding),)
)
print(results)

# B√∫squeda utilizando el √≠ndice KNN (si est√° creado)
results = db.execute_query(
    "SELECT id, text, 1 - (embedding <=> %s::vector) as similarity FROM embeddings ORDER BY embedding <=> %s::vector LIMIT 5",
    (json.dumps(query_embedding), json.dumps(query_embedding))
)
print(results)

# B√∫squeda con condiciones adicionales
results = db.execute_query(
    """
    SELECT id, text, 1 - (embedding <=> %s::vector) as similarity 
    FROM embeddings 
    WHERE text ILIKE %s
    ORDER BY similarity DESC LIMIT 5
    """,
    (json.dumps(query_embedding), "%ejemplo%")
)
print(results)
```

### Sistema de Migraciones

```python
from pgdbtoolkit import PgDbToolkit, MigrationManager

db = PgDbToolkit()
migrations = MigrationManager(db, migrations_dir="./migrations")

# Crear una nueva migraci√≥n
migrations.create_migration(
    name="crear_tabla_usuarios",
    up_sql="""
    CREATE TABLE usuarios (
        id SERIAL PRIMARY KEY,
        nombre VARCHAR(100) NOT NULL,
        email VARCHAR(255) UNIQUE,
        fecha_registro TIMESTAMP DEFAULT CURRENT_TIMESTAMP
    );
    """,
    down_sql="""
    DROP TABLE IF EXISTS usuarios;
    """
)

# Aplicar migraciones pendientes (versi√≥n sincr√≥nica)
applied = migrations.apply_migrations_sync()
print(f"Se aplicaron {len(applied)} migraciones")

# Revertir la √∫ltima migraci√≥n (versi√≥n sincr√≥nica)
reverted = migrations.rollback_migrations_sync(steps=1)
print(f"Se revirtieron {len(reverted)} migraciones")

# Versi√≥n asincr√≥nica
async def run_migrations():
    # Aplicar migraciones
    applied = await migrations.apply_migrations_async()
    print(f"Se aplicaron {len(applied)} migraciones")
    
    # Revertir migraciones
    reverted = await migrations.rollback_migrations_async(steps=1)
    print(f"Se revirtieron {len(reverted)} migraciones")

# Generar migraci√≥n a partir de diferencias de esquema
target_schema = {
    "usuarios": {
        "id": "SERIAL PRIMARY KEY",
        "nombre": "VARCHAR(100) NOT NULL",
        "email": "VARCHAR(255) UNIQUE",
        "fecha_registro": "TIMESTAMP DEFAULT CURRENT_TIMESTAMP",
        "direccion": "TEXT"  # Nueva columna
    }
}
migrations.generate_migration_from_schema_diff(target_schema, prefix="add_direccion")
```

### Validaci√≥n de Datos

```python
from pgdbtoolkit import validate_email, validate_schema, validate_length, validate_numeric

# Validar un email
try:
    validate_email("usuario@ejemplo.com", "email")
except Exception as e:
    print(e)

# Validar estructura completa de datos
schema = {
    "nombre": {"type": str, "required": True, "validators": [lambda x, **kw: validate_length(x, 3, 100)]},
    "email": {"type": str, "required": True, "validators": [validate_email]},
    "edad": {"type": int, "validators": [lambda x, **kw: validate_numeric(x, 18, 120)]}
}

errors = validate_schema({"nombre": "Ana", "email": "ana@ejemplo.com", "edad": 25}, schema)
if errors:
    print("Errores de validaci√≥n:", errors)
else:
    print("Datos v√°lidos")

# Validar registro antes de insertar
from pgdbtoolkit import validate_record

table_schema = {
    "nombre": {"type": str, "required": True, "validators": [lambda x, **kw: validate_length(x, 3, 100)]},
    "email": {"type": str, "required": True, "validators": [validate_email]},
    "edad": {"type": int, "validators": [lambda x, **kw: validate_numeric(x, 18, 120)]}
}

try:
    validate_record({"nombre": "Ana", "email": "ana@ejemplo.com", "edad": 25}, table_schema)
    print("Registro v√°lido")
except Exception as e:
    print(f"Error de validaci√≥n: {e}")
```

## Caracter√≠sticas Avanzadas üî•

### Operaciones por Lotes

```python
# Insertar miles de registros de manera eficiente
registros = [{"campo1": f"valor{i}", "campo2": i} for i in range(10000)]

# M√©todo 1: Usando batch_operation
db.batch_operation("insert", "mi_tabla", registros, batch_size=500)

# M√©todo 2: Usando bulk_insert_with_copy (m√°s r√°pido para grandes vol√∫menes)
num_insertados = db.bulk_insert_with_copy("mi_tabla", registros)
print(f"Se insertaron {num_insertados} registros")

# Versi√≥n asincr√≥nica
async def insertar_lotes():
    num_insertados = await db.bulk_insert_with_copy("mi_tabla", registros)
    print(f"Se insertaron {num_insertados} registros de forma as√≠ncrona")
```

### Transacciones At√≥micas

```python
# Asegurar que m√∫ltiples operaciones se ejecuten como una unidad
# Versi√≥n sincr√≥nica
db.execute_transaction([
    ("INSERT INTO cuentas (id, balance) VALUES (%s, %s)", (1, 1000)),
    ("INSERT INTO cuentas (id, balance) VALUES (%s, %s)", (2, 500)),
    ("INSERT INTO transferencias (origen, destino, monto) VALUES (%s, %s, %s)", (1, 2, 200)),
    ("UPDATE cuentas SET balance = balance - %s WHERE id = %s", (200, 1)),
    ("UPDATE cuentas SET balance = balance + %s WHERE id = %s", (200, 2))
])

# Con referencias a resultados anteriores
# La funci√≥n lambda puede acceder a los resultados de las consultas anteriores
resultados = db.execute_transaction([
    ("INSERT INTO productos (nombre, precio) VALUES (%s, %s) RETURNING id", ("Nuevo Producto", 99.99)),
    ("INSERT INTO inventario (producto_id, cantidad) VALUES (%s, %s)", 
     lambda results: (results[0].iloc[0, 0], 100))  # Usa el ID del producto insertado
])

# Versi√≥n asincr√≥nica
async def realizar_transferencia():
    await db.execute_transaction([
        ("INSERT INTO transferencias (origen, destino, monto) VALUES (%s, %s, %s)", (1, 2, 200)),
        ("UPDATE cuentas SET balance = balance - %s WHERE id = %s", (200, 1)),
        ("UPDATE cuentas SET balance = balance + %s WHERE id = %s", (200, 2))
    ])
```

### Logging Personalizado

```python
from pgdbtoolkit import Log

# Configurar nivel de log global
Log.configure(level="DEBUG", log_file="db_operations.log")

# O para un m√≥dulo espec√≠fico
logger = Log(__name__)
logger.info("Operaci√≥n completada con √©xito")
logger.error("Ocurri√≥ un error importante")
logger.debug("Informaci√≥n detallada para depuraci√≥n")

# Captura autom√°tica de errores en operaciones de base de datos
# Los logs incluyen informaci√≥n como consultas SQL, par√°metros y stacktrace
try:
    db.execute_query("SELECT * FROM tabla_inexistente")
except Exception as e:
    # El error ya ha sido registrado autom√°ticamente
    pass
```

### Soft Delete

```python
# Borrado l√≥gico: marcar registros como eliminados pero mantenerlos en la base de datos
# Versi√≥n sincr√≥nica
db.delete_records(
    "usuarios",
    {"id": 123},
    soft_delete=True,
    delete_column="deleted_at"  # Se usar√° CURRENT_TIMESTAMP
)

# Si la columna no existe, se crear√° autom√°ticamente

# Excluir registros eliminados l√≥gicamente en consultas
activos = db.fetch_records(
    "usuarios",
    conditions={"deleted_at": None}  # Solo registros no eliminados
)

# Versi√≥n asincr√≥nica
async def soft_delete_usuario(id_usuario):
    await db.delete_records(
        "usuarios",
        {"id": id_usuario},
        soft_delete=True,
        delete_column="deleted_at"
    )
```

### Exportaci√≥n de Datos

```python
# Exportar resultados de consulta a CSV
# Versi√≥n sincr√≥nica
csv_path = db.export_query_to_csv(
    "SELECT * FROM ventas WHERE fecha BETWEEN %s AND %s",
    ("2023-01-01", "2023-12-31"),
    filepath="ventas_2023.csv"
)
print(f"Datos exportados a {csv_path}")

# Si no se especifica filepath, retorna un DataFrame
df = db.export_query_to_csv(
    "SELECT * FROM productos WHERE stock < %s",
    (10,)
)
print(f"Se encontraron {len(df)} productos con stock bajo")

# Versi√≥n asincr√≥nica
async def exportar_datos():
    csv_path = await db.export_query_to_csv(
        "SELECT * FROM ventas WHERE fecha BETWEEN %s AND %s",
        ("2023-01-01", "2023-12-31"),
        filepath="ventas_2023_async.csv"
    )
    print(f"Datos exportados a {csv_path}")
```

### Gesti√≥n de Usuarios

```python
# Crear un nuevo usuario en PostgreSQL
db.create_user(
    username="app_user",
    password="secreto123",
    superuser=False,
    createdb=False,
    createrole=False,
    login=True,
    connection_limit=10
)

# Otorgar privilegios a un usuario
db.grant_database_privileges(
    username="app_user",
    database="mi_aplicacion",
    privileges=["CONNECT", "SELECT", "INSERT", "UPDATE"]
)

# Actualizar un usuario existente
db.update_user(
    "app_user", 
    {
        "password": "nuevo_secreto",
        "connection_limit": 20
    }
)

# Ver usuarios existentes
usuarios = db.get_users()
print(usuarios)

# Eliminar un usuario
db.delete_user("app_user", cascade=True)  # cascade=True elimina tambi√©n objetos propiedad del usuario
```

## API Completa üìö

El toolkit proporciona una extensa API para cubrir todas sus necesidades de acceso a datos:

### Gesti√≥n de Bases de Datos

- `create_database(database_name)`: Crea una nueva base de datos.
- `delete_database(database_name)`: Elimina una base de datos existente.
- `get_databases()`: Obtiene una lista de todas las bases de datos.

### Gesti√≥n de Tablas

- `create_table(table_name, schema)`: Crea una nueva tabla con el esquema proporcionado.
- `delete_table(table_name)`: Elimina una tabla existente.
- `alter_table(table_name, ...)`: Modifica una tabla existente (a√±adir/eliminar columnas, restricciones, etc.).
- `get_tables()`: Obtiene una lista de todas las tablas en la base de datos actual.
- `get_table_info(table_name)`: Obtiene informaci√≥n detallada sobre una tabla.
- `truncate_table(table_name)`: Elimina todos los registros de una tabla sin eliminar la tabla.

### Gesti√≥n de Registros

- `insert_records(table_name, record)`: Inserta uno o m√°s registros en una tabla.
- `fetch_records(table_name, columns, conditions, order_by, limit, offset)`: Consulta registros con condiciones avanzadas.
- `update_records(table_name, data, conditions)`: Actualiza registros que cumplen condiciones.
- `delete_records(table_name, conditions, soft_delete, delete_column)`: Elimina registros que cumplen condiciones, con opci√≥n de borrado l√≥gico.
- `execute_query(query, params)`: Ejecuta una consulta SQL personalizada.
- `search_records(table_name, search_term, search_column, additional_conditions)`: Realiza b√∫squedas de texto en una tabla.
- `batch_operation(operation, table_name, records, batch_size)`: Realiza operaciones por lotes.
- `bulk_insert_with_copy(table_name, data, columns)`: Inserta grandes vol√∫menes de datos usando COPY.
- `export_query_to_csv(query, params, filepath)`: Exporta resultados de consulta a CSV.
- `execute_transaction(queries)`: Ejecuta m√∫ltiples operaciones en una sola transacci√≥n.
- `execute_multiple_queries(queries)`: Ejecuta m√∫ltiples consultas en una sola conexi√≥n.

### Operaciones Vectoriales

- `create_vector_extension()`: Habilita la extensi√≥n pgvector en la base de datos.
- `execute_query()`: Utilizado para realizar consultas vectoriales personalizadas.
- `insert_records()`: Para insertar datos incluyendo vectores.
- `update_records()`: Para actualizar registros con vectores.
- `search_records()`: Para buscar registros mediante texto (complementa b√∫squedas vectoriales).

### Utilidades

- `create_user(username, password, ...)`: Crea un usuario en PostgreSQL.
- `update_user(username, attributes)`: Actualiza atributos de un usuario.
- `delete_user(username, cascade)`: Elimina un usuario.
- `get_users()`: Obtiene lista de usuarios.
- `grant_database_privileges(username, database, privileges)`: Otorga privilegios a un usuario.

## Manejo de Errores üõ°Ô∏è

La biblioteca proporciona excepciones espec√≠ficas para diferentes tipos de errores:

```python
from pgdbtoolkit.exceptions import (
    DatabaseError, 
    ConnectionError, 
    QueryError, 
    ValidationError,
    RecordNotFoundError,
    MissingConfigError,
    ConfigurationError,
    PoolError,
    MigrationError
)

# Ejemplo de uso
try:
    db.execute_query("SELECT * FROM tabla_inexistente")
except QueryError as e:
    print(f"Error en consulta: {e}")
    # Manejar el error espec√≠ficamente

try:
    db.insert_records("usuarios", {"email": "correo_invalido"})
except ValidationError as e:
    print(f"Error de validaci√≥n: {e}")
    # Solicitar correcci√≥n al usuario

# Patr√≥n de manejo de errores recomendado
try:
    # Operaciones de base de datos...
    db.execute_transaction([...])
except ConnectionError:
    # Manejar problemas de conexi√≥n
    print("No se pudo conectar a la base de datos")
except QueryError as e:
    # Manejar errores de consulta
    print(f"La consulta fall√≥: {e}")
except ValidationError as e:
    # Manejar errores de validaci√≥n
    print(f"Datos inv√°lidos: {e}")
except DatabaseError as e:
    # Manejar cualquier otro error de base de datos
    print(f"Error de base de datos: {e}")
```

## Roadmap üõ£Ô∏è

- [ ] Soporte para campos geom√©tricos (PostGIS)
- [ ] Herramientas de an√°lisis y rendimiento de consultas
- [ ] Interfaz web para gesti√≥n de migraciones
- [ ] Soporte para almacenamiento y b√∫squeda de documentos JSON/JSONB
- [ ] Generaci√≥n autom√°tica de modelos ORM
- [ ] Mejoras en la integraci√≥n con frameworks web populares
- [ ] Caching inteligente de resultados frecuentes
- [ ] Soporte para SQL Server y MySQL

## Contribuciones üë•

¬°Las contribuciones son bienvenidas! Para contribuir:

1. Realiza un fork del repositorio.
2. Crea una nueva rama (`git checkout -b feature/mi-nueva-funcionalidad`).
3. Realiza tus cambios y commitea (`git commit -am 'A√±adir nueva funcionalidad'`).
4. Push a la rama (`git push origin feature/mi-nueva-funcionalidad`).
5. Crea un nuevo Pull Request.

Consulta `CONTRIBUTING.md` para m√°s detalles sobre nuestro proceso de contribuci√≥n y est√°ndares de c√≥digo.

## Licencia üìÑ

Este proyecto est√° licenciado bajo la Licencia Apache 2.0 - ver el archivo [LICENSE](LICENSE) para m√°s detalles.

```
Copyright 2024 Gustavo Inostroza

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
```