from mcp.server.fastmcp import FastMCP
import os
import csv
import glob
import shutil
import matplotlib.pyplot as plt
import seaborn as sns
from typing import List
try:
    from googlesearch import search
except ImportError:
    print("Please install googlesearch-python: pip install googlesearch-python")

from pm_studio_mcp.pm_studio_utils import (
    replace_stop_words,
    write_csv_data,
    find_files_by_pattern,
    parse_csv_content,
)
from pm_studio_mcp.pm_studio_constant import (
    FINAL_RESULT_FILE,
    UNWRAP_DEFAULT_COLUMN_INDEX,
    UNWRAP_COLUMN_NAME,
    OCV_COLUMN_NAME,
    GREETING_TEMPLATE,
)
 
# Create MCP server instance
mcp = FastMCP("pm-studio-mcp")  # this is my mcp server name

# Configure WORKING_PATH from environment variables if provided
if 'WORKING_PATH' in os.environ:
    WORKING_PATH = os.environ['WORKING_PATH']
    print(f"Using configured working path: {WORKING_PATH}")
else:
    print(f"Please config your working path in mcp.json")

# Create the working directory if it doesn't exist
os.makedirs(WORKING_PATH, exist_ok=True)

@mcp.tool()
async def greeting_with_pm_studio(name: str):  # this is the one of the tool of my MCP server
    """
    if user send a greeting message, this tool will be called
    """
    return "use command tool to print '" + GREETING_TEMPLATE.format(name=name) + "', and end the task."

@mcp.tool()
async def upload_files_to_working_dir_tool(file_paths: List[str]): #handle the file uploaded from the client
    """
    Copies the CSV files uploaded from the client chat to the working directory and renames them with an "_intermediate" suffix.

    Args:
        file_paths (List[str]): List of file paths uploaded from the client chat.
    """
    copied_files = []
    for file_path in file_paths:
        try:
            # Ensure the file is a CSV file
            if not file_path.lower().endswith('.csv'):
                return f"Error: Only CSV files are allowed. Invalid file: {file_path}"

            # Add "_intermediate" suffix to the file name
            base_name = os.path.splitext(os.path.basename(file_path))[0]
            destination = os.path.join(WORKING_PATH, f"{base_name}_intermediate.csv")

            # Copy the file to the working directory
            shutil.copy(file_path, destination)
            copied_files.append(destination)
        except Exception as e:
            return f"Error copying file {file_path}: {str(e)}"

    return f"Copied {len(copied_files)} files to working directory: {', '.join(copied_files)}"

@mcp.tool()
async def ocv_feedback_data_clean_tool(input_files: List[str]):  # Receives file paths generated by the previous tool as parameters
    """
    Clean the OCV user feedback data files provided as input, and output the specified column to new intermediate files.
    Args:
        input_files (List[str]): List of input CSV file paths generated by the previous tool.
    Returns:
        List[str]: List of generated intermediate file paths.
    """
    # Define phrases to filter out
    phrases_to_exclude = [
        "Generic - Praise",
        "[Generic] - Not useful or Spam",
        "Praise for Workspaces",
        "Test data"
    ]

    cleaned_files = []
    for file_path in input_files:
        base_name = os.path.splitext(os.path.basename(file_path))[0]
        output_file = os.path.join(WORKING_PATH, f"{base_name}_cleaned_intermediate.csv")

        with open(file_path, 'r', encoding='utf-8') as infile, open(output_file, 'w', newline='', encoding='utf-8') as outfile:
            reader = csv.reader(infile)
            writer = csv.writer(outfile)

            # Skip the first row (which is a sentence and not part of the header)
            next(reader, None)

            # Read the header to find the index of "Issue[0].Title"
            header = next(reader, None)
            if not header or OCV_COLUMN_NAME not in header:
                return f"Error: Column '{OCV_COLUMN_NAME}' not found in file {file_path}"

            issue_title_index = header.index(OCV_COLUMN_NAME)

            # Write the header for the output file
            writer.writerow([OCV_COLUMN_NAME])

            for row in reader:
                if len(row) > issue_title_index:
                    cleaned_text = replace_stop_words(row[issue_title_index])

                    # Skip rows containing any of the excluded phrases
                    if any(phrase in cleaned_text for phrase in phrases_to_exclude):
                        continue

                    # Only write rows where the cleaned text is not empty
                    if cleaned_text.strip():
                        writer.writerow([cleaned_text])
                else:
                    continue  # Skip rows where the column index is out of range

        cleaned_files.append(output_file)

    return cleaned_files
    return cleaned_files  


@mcp.tool()
async def unwrap_feedback_data_clean_tool(input_files: List[str]):  # Receives file paths generated by the previous tool as parameters
    """
    Clean the unwrap user feedback data files provided as input, and output the specified column to new intermediate files.
    Args:
        input_files (List[str]): List of input CSV file paths generated by the previous tool.
    Returns:
        List[str]: List of generated intermediate file paths.
    """

    cleaned_files = []
    for file_path in input_files:
        base_name = os.path.splitext(os.path.basename(file_path))[0]
        output_file = os.path.join(WORKING_PATH, f"{base_name}_cleaned_intermediate.csv")

        with open(file_path, 'r', encoding='utf-8') as infile, open(output_file, 'w', newline='', encoding='utf-8') as outfile:
            reader = csv.reader(infile)
            writer = csv.writer(outfile)

            header = next(reader, None)
            entry_text_index = UNWRAP_DEFAULT_COLUMN_INDEX
            sentiment_index = None

            # Identify the "Sentiment" column index
            if header:
                if "Sentiment" in header:
                    sentiment_index = header.index("Sentiment")
                if UNWRAP_COLUMN_NAME in header:
                    entry_text_index = header.index(UNWRAP_COLUMN_NAME)

                # Write the header to the output file
                writer.writerow([UNWRAP_COLUMN_NAME])

            for row in reader:
                # Skip rows where the "Sentiment" column is "Positive"
                if sentiment_index is not None and len(row) > sentiment_index and row[sentiment_index] == "Positive":
                    continue

                # Extract and clean the specific column
                if len(row) > entry_text_index:
                    cleaned_text = replace_stop_words(row[entry_text_index])
                    writer.writerow([cleaned_text])
                else:
                    writer.writerow([""])

        cleaned_files.append(output_file)

    return cleaned_files


@mcp.tool()
async def merge_feedback_data_clean_tool(input_files: List[str]):  # Receives file paths generated by the previous tool as paramters
    """
    Merge the intermediate data files generated by unwrap_feedback_data_clean_tool and ocv_feedback_data_clean_tool.
    Args:
        input_files (List[str]): List of input CSV file paths generated by the previous tools.
    Returns:
        str: Path to the merged output file.
    """
    # Define the output file path
    output_file = os.path.join(WORKING_PATH, "merged_intermediate.csv")
    
    # Check if input files are provided
    if not input_files or len(input_files) < 2:
        return "Error: At least two input files are required for merging."

    try:
        # Open the output file for writing
        with open(output_file, 'w', newline='', encoding='utf-8') as outfile:
            writer = csv.writer(outfile)
            
            for file_path in input_files:
                # Ensure the file has the "_intermediate.csv" suffix
                if not file_path.endswith("_intermediate.csv"):
                    return f"Error: Invalid file format. Expected '_intermediate.csv' but got {file_path}"
                
                # Read each input file and append its content to the output file
                with open(file_path, 'r', encoding='utf-8') as infile:
                    reader = csv.reader(infile)
                    for row in reader:
                        writer.writerow(row)
        
        return f"Merged file is ready: {output_file}"
    except Exception as e:
        return f"Error during merging: {str(e)}"


            
@mcp.tool()
async def write_to_csv_tool(content: str):
    """
    Write the given content to a CSV file in the working directory.
    Args:
        content (str): The content to write to the CSV file. Content format per line: category,count,original comment 1|original comment 2|...
    """
    # Define the output file path
    output_file = os.path.join(WORKING_PATH, FINAL_RESULT_FILE)
    
    # Parse the content into rows
    rows = parse_csv_content(content)
    
    # Write to CSV
    write_csv_data(rows, output_file)
    
    return f"Content written to {output_file}"

@mcp.tool()
async def working_dir_cleanup_tool_intermediate():
    """
    Clean up the working directory by deleting all files with _cleaned.csv suffix.
    """
    # Find all files with _cleaned.csv suffix
    cleaned_files = find_files_by_pattern("*_intermediate.csv", WORKING_PATH)

    # Delete the files
    deleted_count = 0
    for file_path in cleaned_files:
        try:
            os.remove(file_path)
            deleted_count += 1
        except Exception as e:
            return f"Error deleting file {file_path}: {str(e)}"
    
    return "Task completed."


@mcp.tool()
async def google_web_tool(keywords: List[str], num_results: int = 10):
    """
    Perform a Google web search with the given keywords and return top 10 result URLs.
    
    Args:
        keywords: List of search keywords
        num_results: Number of search results to return (default: 10)
        
    Returns:
        List of 10 search result URLs
    """
    try:
        # Join keywords with spaces for the search query
        query = " ".join(keywords)
        
        # Perform the search and get results
        search_results = []
        for url in search(query, num_results=10):
            search_results.append(url)
            
        return {
            "status": "success",
            "query": query,
            "results": search_results
        }
    except Exception as e:
        return f"Error performing search: {str(e)}"

@mcp.tool()
async def generate_markdown_tool(content: str, filename: str):
    """
    Write the given content to a Markdown file in the working directory with a customizable filename.
            
    Args:
        content (str): The content to write to the Markdown file.
        filename (str, optional): The name of the output file.
            
    Returns:
        str: Path to the saved Markdown file.
    """
    try:
        # Ensure the filename has .md extension
        if not filename.endswith('.md'):
            filename = f"{filename}.md"
            
        # Define the output file path
        output_file = os.path.join(WORKING_PATH, filename)
                
        # Write content to the file
        with open(output_file, 'w', encoding='utf-8') as file:
            file.write(content)
                
        return f"Content successfully written to {output_file}"
    except Exception as e:
        return f"Error writing to markdown file: {str(e)}"

@mcp.tool()
async def generate_pie_chart_tool(data: dict):
    """
    Generate a pie chart based on the provided data and save it as 'userfeedback_piechart.jpg'.

    Args:
        data (dict): A dictionary where keys are categories (str) and values are counts (int).
    
    Returns:
        str: Path to the saved pie chart image.
    """
    try:
        # Validate input data
        if not isinstance(data, dict) or not data:
            return "Error: Input data must be a non-empty dictionary with categories and counts."

        # Separate "Other" category if it exists
        other_count = data.pop("Other", None)

        # Sort the remaining categories by count in descending order
        sorted_data = sorted(data.items(), key=lambda x: x[1], reverse=True)

        # Add "Other" back as the last category if it exists
        if other_count is not None:
            sorted_data.append(("Other", other_count))

        # Extract categories and counts
        categories, counts = zip(*sorted_data)

        # Generate colors using Seaborn's 'Set2' palette
        colors = sns.color_palette('Set2', len(categories))

        # Generate the pie chart
        plt.figure(figsize=(8, 8))
        plt.pie(
            counts,
            labels=categories,
            autopct='%1.1f%%',
            startangle=90,  # Start from 12 o'clock
            colors=colors,
            counterclock=False, 
        )
        plt.title("User Feedback Distribution")

        # Save the pie chart
        output_file = os.path.join(WORKING_PATH, "userfeedback_piechart.jpg")
        plt.savefig(output_file, dpi=300)
        plt.close()

        return f"Pie chart saved at: {output_file}"
    except Exception as e:
        return f"Error generating pie chart: {str(e)}"
    
@mcp.tool()
async def call_amap_mcp_server_tool(api_key: str):
    """
    Call the AMap MCP server using the provided API key.

    Args:
        api_key (str): The API key for AMap MCP server.

    Returns:
        str: Result of the AMap MCP server call.
    """
    try:
        # Define the command and environment variables
        command = "npx"
        args = ["-y", "@amap/amap-maps-mcp-server"]
        env = os.environ.copy()
        env["AMAP_MAPS_API_KEY"] = api_key

        # Execute the command
        process = await asyncio.create_subprocess_exec(
            command, *args, env=env,
            stdout=asyncio.subprocess.PIPE,
            stderr=asyncio.subprocess.PIPE
        )
        stdout, stderr = await process.communicate()

        if process.returncode == 0:
            return f"AMap MCP server response: {stdout.decode().strip()}"
        else:
            return f"Error calling AMap MCP server: {stderr.decode().strip()}"
    except Exception as e:
        return f"Error executing AMap MCP server command: {str(e)}"

def main():
    mcp.run(transport='stdio')

if __name__ == "__main__":
    main()



